{"prompt": "Unable to build michelangelo core", "completion": "You need protobuf 2.5.0.   Documents workspace michelangelo michelangelo online-prediction   master  protoc --versionlibprotoc 2.5.0Also make sure you are connected to the VPN"}
{"prompt": "Caffe training failed with message -- KeyError: Unable to open object  Object 'data' doesn't exist ", "completion": "You might hit this error when you train a Caffe deep learning model from michelangelo.Most likely your data is not image data and the draft model has a wrong configuration so that above code path  sampling image data  got executed which is wrong.To fix it, check  skip activation data  from the draft model dialog, then re-train your model."}
{"prompt": "rename copy a michelangelo project", "completion": "You might hit this error when you train a Caffe deep learning model from michelangelo.Most likely your data is not image data and the draft model has a wrong configuration so that above code path  sampling image data  got executed which is wrong.To fix it, check  skip activation data  from the draft model dialog, then re-train your model."}
{"prompt": "Spark Driver was killed by YARN", "completion": "The problem is resolved now. At that time it was likely due to a hadoop outage"}
{"prompt": "Changing project name in Michelangelo We have a project named  etaFit  but we'd like to rename it to  ufpFit  because it's a more descriptive name of what the project is used for. Is there a way to do this  just once  from the Michelangelo side, or should I just create a new project?", "completion": "Sorry, this is not supported. You'll have to create a new project."}
{"prompt": "Unexpected token `>` when running michelangelo-web", "completion": "Check the node version in the error log:npm ERR! node v0.10.32npm ERR! npm  v2.8.2michelangelo-web now keeps the node version updated in package.json, so you will need the correct version of node to run it. You can use @uber change-node to make this easy.npm install -g @uber change-nodethen in the working directory run:cnin the working directory$ cnnode v6.10.0  from package.json engines node  already installednpm v4.0.5  from package.json engines npm  already installed"}
{"prompt": "michelangelo Spark Driver was killed by YARN", "completion": "There are many reasons the driver can be killed by Yarn -- out of memory is typically the top reason. Try reducing the model complexity and or training data volume first. If it still happens, open a ticket and  blame michelangelo-sparkfor training subteam oncall.Other reason could be Yarn cannot get any resource. Go to https:  graphite.uberinternal.com grafana2 dashboard db hadoop-queue-utilization to see your dedicated YARN resource utilization. Please note every team should run jobs using their dedicated Yarn queue. If you team doesn't have dedicated Yarn queue, plead file a ticket against Hadoop Data SRE."}
{"prompt": "What should I input for the cell next to 'forecasted time series'? In Michelangelo, I was doing a time series forecast with data source added. In setting up the model, what infor should I input in the box next to the 'forecast time series' box?Thanks,", "completion": "see staging_timeseries or sf_trips_forecast projects for example."}
{"prompt": "what's the status of XGBoost support in Michelangelo? I know Michelangelo supports training XGBoost trees, but it was in beta earlier. Is this feature still in beta? Is it ready to use for training partitioned models?For full context, I work on ETAFit and we currently have around 100 GBDT partitioned models trained using Spark ML Lib. I'd like to migrate to XGBoost to mainly take advantage of faster trainings as we scale to 200+ models. Is there anything I need to be aware of before considering this from our side?", "completion": "see staging_timeseries or sf_trips_forecast projects for example."}
{"prompt": "Is there a way to enter  pass_through  features to Michelangelo training job?", "completion": "see staging_timeseries or sf_trips_forecast projects for example."}
{"prompt": "Batch delete predictions and data files In the old UI, there used to be a way to batch delete predictions and data files but the feature seems to be missing in the new one. Is there an efficient way of batch deleting old data instead of removing them one by one?", "completion": "There is a way to do via API. For example,curl -H  X-Auth-Params-Email:   -X DELETE  http:  localhost:14785 v1 projects myproject datasets?start_date=2016-01-01end_date=2017-07-24 will delete data for project myproject from 2016-01-01 to 2017-07-24 usingemail xyz.There is a feature request to support this in new UX."}
{"prompt": "Querying a Michelangelo model with more features needed There is a quick question about querying ML model in Michelangelo: can we send more features in the query than the model needed? Will the prediction throw an error? The reason I asked this is maybe our model will use more features in future, but now it ony needs a subset of features. Thanks!", "completion": "It will be fine. The new features will simply be ignored."}
{"prompt": "How can I know which prediction service group my ML model has been deployed I have a ML model deployed in Michelangelo. But which service group has this model been deployed? The Michelangelo deployment UI has no such information. Thanks!", "completion": "By default, we deploy to group1.See https:  engdocs.uberinternal.com michelangelo user-guides realtime-predict-service.html before sending traffic.See https:  engdocs.uberinternal.com michelangelo user-guides onboard-near-realtime-features.html and https:  engdocs.uberinternal.com michelangelo user-guides contributetofeaturestore.html if you plan to use feature-store for online serving."}
{"prompt": "Unable to download data from a trained model on Michelangelo I tried running this in Python:import pandas as pddf = pd.read_csv 'http:  localhost:14785 api v1 projects eats_restaurant_retaining_user_prob models 2017-05-31-20-54-38-459-UTC download?format=training_data_csvsampling_fraction=0.17', compression='gzip'  and got an error:  HTTP Error 401: Unauthorized ", "completion": "By default, we deploy to group1.See https:  engdocs.uberinternal.com michelangelo user-guides realtime-predict-service.html before sending traffic.See https:  engdocs.uberinternal.com michelangelo user-guides onboard-near-realtime-features.html and https:  engdocs.uberinternal.com michelangelo user-guides contributetofeaturestore.html if you plan to use feature-store for online serving."}
{"prompt": "Logistic regression with factors", "completion": "By default, we deploy to group1.See https:  engdocs.uberinternal.com michelangelo user-guides realtime-predict-service.html before sending traffic.See https:  engdocs.uberinternal.com michelangelo user-guides onboard-near-realtime-features.html and https:  engdocs.uberinternal.com michelangelo user-guides contributetofeaturestore.html if you plan to use feature-store for online serving."}
{"prompt": "Clicking 'Populate Basis Feature' with no response  data source success  Hey there,In Michelangelo, I've successfully added and backfilled a sql data source. When creating a time series model, I received no response by clicking the 'Populate Basis Features' button  see below .Is that caused by wrong choice of time in training time period?Thank you!", "completion": "Yes, populate Basis Features only works if you have data for the dates you select above. We are currently working to make this feature a little better.In the meantime, can you share with us a link to your project? It will help us determine if there is anything that is preventing this from working properly.Thanks!"}
{"prompt": "Is there any way to pass spark parameters to MichelAngelo jobs I'm trying to pass some spark parameters to our MichelAngelo prediction jobs, like:spark.dynamicAllocation.enabled=truespark.shuffle.service.enabled=truespark.dynamicAllocation.maxExecutors=50  or how many ever executors you want Is it supported by MichelAngelo?Thanks.", "completion": "Yes we support it. Go to the settings page for a data source and click advanced settings. You can enter the settings for all the individual job types like prediction, training etc.. Ideally this setting should be on project level, I'm submitting a ticket to move it there and make it less confusing."}
{"prompt": "How to call to michelangelo-gateway from adhoc machines?", "completion": "Yes we support it. Go to the settings page for a data source and click advanced settings. You can enter the settings for all the individual job types like prediction, training etc.. Ideally this setting should be on project level, I'm submitting a ticket to move it there and make it less confusing."}
{"prompt": "Unable to run predictions on a deployed model in Michelangelo", "completion": "Maneesh, looks like you need to re-train the model and make sure the global fallback is enabled. Once you retrain, you can re-deploy it and run the predictions again."}
{"prompt": "Predict probability in binary classification project In Michelangelo's binary classification project, how do I set up output section to get the probability output?", "completion": "You can call the @prediction scope followed by the class label. For example, for P true , you would say @prediction:true."}
{"prompt": "Model performance page can't load", "completion": "This was being caused by some missing metrics data. We have deployed a fix, so you should see your model's performance now."}
{"prompt": "What is the SLA for Michelangelo Stack questions? How long will it take for a Michelangelo team member to respond to my question?", "completion": "The Michelangelo team will provide an initial response within 24 hours."}
{"prompt": "loaded models vs partially loaded models", "completion": "The Michelangelo team will provide an initial response within 24 hours."}
{"prompt": "Kafka topic to one of the data source in Michelangelo", "completion": "We recommend to use Hive table as data source. Soon Hive table will be the major supported data source by Michelangelo."}
{"prompt": "Michelangelo Data Source owner In Michelangelo, while giving the data source there are some options to choose from. Eg. HDFS. For my use case, we wanted to push data to Michelangelo so that we can build models on that? So, my question is who owns this data store? Is it Michelangelo team who owns them and we need to push the data to it or is it owned by us?Basically, do we need to create a new data store and maintain that and in Michelangelo, just give it as a source? Or it would be maintained by Michelangelo?", "completion": "You own your data, including quota and retention policy etc.. You just need to register your data as data source so Michelangelo knows where to grab your data."}
{"prompt": "DSL validation help! - Train error: The training data only contains samples from one class label I am using this for my response:if nVal  ltv   <= 0.0   0  else if nVal  ltv   < 10.0   1  else  2 However I get this below error while training the model:The training data only contains samples from one class labelI checked my source data, it has ltv values ranging from -100 to +270. So it has to be something wrong with the above DSL statement.Looking for help to validate my DSL!", "completion": "Looks like your data in DCA is corrupted. I can do that well in SJC.make sure you run your query in DCA, and see whether that works.https:  querybuilder-dca1.uberinternal.com"}
{"prompt": "How can I check the status of the prediction job in Michelangelo", "completion": "for SJC1,go to http:  hadoopmaster10-sjc1:8088 cluster schedulertype in your project name in the right search box."}
{"prompt": "Why is my confusion matrix empty?", "completion": "This is an open bug being tracked here. We're working on it - https:  code.uberinternal.com T1287003"}
{"prompt": "HDFS Quota in Michelangelo - how to bypass or solve? I have only 3 models and limited amount of published results. Why it's so early to hit HDFS limit and what should I do?", "completion": "This banner is for all users to purge unneeded models and data. You can ignore since you only have 3 models and limited amount of published results."}
{"prompt": "Data after transformation is empty!", "completion": "Mohan - please also update the response field to be string type."}
{"prompt": "Real time prediction service vs DB read", "completion": "Mohan - please also update the response field to be string type."}
{"prompt": "Where is the option to change deployment group?", "completion": "Mohan - please also update the response field to be string type."}
{"prompt": "Michelangelo publish error: We need at least 1 model deployed to start a prediction job, but no model is deployed", "completion": "Mohan - please also update the response field to be string type."}
{"prompt": "Is a really naive model supported in Michelangelo? Is it supported in Michelangelo to get a really naive model asy = x + b, y as response variable, x as feature, all I want to get is `b, with the coefficient on x is fixed as 1.I know this is such a naive way to get a constant modifier, but would like to know if it's possible to do it.", "completion": "Mohan - please also update the response field to be string type."}
{"prompt": "What does Set   do?", "completion": "Set   is used with asCat when converting a numerical value to a categorical value. You can see the source code here: https:  code.uberinternal.com diffusion DAMIC browse master core src main scala com uber michelangelo featureEng Functions.scala;e38bee0fa2526a422dc7b0bb87ded121fc108399$51-55"}
{"prompt": "Download training data from Michelangelo project", "completion": "Set   is used with asCat when converting a numerical value to a categorical value. You can see the source code here: https:  code.uberinternal.com diffusion DAMIC browse master core src main scala com uber michelangelo featureEng Functions.scala;e38bee0fa2526a422dc7b0bb87ded121fc108399$51-55"}
{"prompt": "How to backfill Michelangelo Hive data store in 1 query block?", "completion": "Set   is used with asCat when converting a numerical value to a categorical value. You can see the source code here: https:  code.uberinternal.com diffusion DAMIC browse master core src main scala com uber michelangelo featureEng Functions.scala;e38bee0fa2526a422dc7b0bb87ded121fc108399$51-55"}
{"prompt": "Getting  java.text.ParseException: Unparseable number:  nan  ", "completion": "I looked at your query result in QB and see column  cash_ratio_gb_L14D  has value 'nan' for two records. See https:  code.uberinternal.com P88415. You may want to fix this and do backfill again.Also, Michelangelo suggests using static hive table for the training datasource now. For instructions please see https:  docs.google.com document d 1S6r_wDIYSREpqLyUU-p84-cScu8uc0j2HdiUI3s5VQA edit?ts=5a0b78f8#"}
{"prompt": "michelangelo error message while using .csv data i'm building a michelangelo model thru a .csv file. Getting this error message but not sure what causes it and what's the fix? Thanks if anyone could help!https:  stack.uberinternal.com images a 02af304c-1607-43a4-bd17-8c7ace7a6476.png", "completion": "I looked at your query result in QB and see column  cash_ratio_gb_L14D  has value 'nan' for two records. See https:  code.uberinternal.com P88415. You may want to fix this and do backfill again.Also, Michelangelo suggests using static hive table for the training datasource now. For instructions please see https:  docs.google.com document d 1S6r_wDIYSREpqLyUU-p84-cScu8uc0j2HdiUI3s5VQA edit?ts=5a0b78f8#"}
{"prompt": "Can't download training data from Michelangelo to check why my model training fails", "completion": "I looked at your query result in QB and see column  cash_ratio_gb_L14D  has value 'nan' for two records. See https:  code.uberinternal.com P88415. You may want to fix this and do backfill again.Also, Michelangelo suggests using static hive table for the training datasource now. For instructions please see https:  docs.google.com document d 1S6r_wDIYSREpqLyUU-p84-cScu8uc0j2HdiUI3s5VQA edit?ts=5a0b78f8#"}
{"prompt": "How can I do anomaly detection in Michelangelo? Does Michelangelo support one class support vector machines? My use case is that I will be pre-training a CNN, and then will use the CNN as a feature extractor and then use a one-class svm to classify the extracted features for a single class.", "completion": "I looked at your query result in QB and see column  cash_ratio_gb_L14D  has value 'nan' for two records. See https:  code.uberinternal.com P88415. You may want to fix this and do backfill again.Also, Michelangelo suggests using static hive table for the training datasource now. For instructions please see https:  docs.google.com document d 1S6r_wDIYSREpqLyUU-p84-cScu8uc0j2HdiUI3s5VQA edit?ts=5a0b78f8#"}
{"prompt": "Multi-head predictions with XGBoost? Can I use the Michelangelo XGBoost framework to train a model that makes what would be called  multi-head predictions  in neural network parlance?Example: say I have input features X and label spaces Y, U, and V. Y, U, and V are all vectors of length 10, corresponding to separate 10-class classification problems. Ultimately I'd like one model that predicts p Y | X , p U | X  and p V | X . However, at train time, for each X, I only observe the true label for one of  Y, U, V .I know this sort of training is possible with neural nets  e.g. a single model with a shared trunk of parameters to process X and then multiple heads with unshared parameters to model Y, U, and V , but can I model this with a single XGBoost as well? Or is the only possibility to train separate models for Y, U, and V on the subsets of the data where those variables are observed?", "completion": "Unfortunately XGBoost only support 1 float as label right now. For multi-objective, the best way is to train separate models for each case.You can also propose the multi-objective classification regression on Open Source community.https:  github.com dmlc xgboost issuesThanks,Yun Ni"}
{"prompt": "ma Client Version is Below 0.5.23 and Wont Update I'm in ATG and I can't update the ma tool beyond version 0.5.23. What should I do?", "completion": "Uber Prime has its own pypi mirror and repository. There are Uber-specific packages in there that are not externally published. To get access to this internal repo, you need a pip.conf file with the secret.To get a pip.conf file with the secret:Access the secret keys:git clone :uber-developermkdir -p  .pipcp uber-developer pip.conf  .pip .Install the latest michelangelo-python-client:pip install -U michelangelo-python-clientVerify that you are using the latest version of the client:ma --version"}
{"prompt": "How do I install Cerberus on my ATG Linux or Mac machine? How do I install Cerberus on my ATG Linux or Mac machine? ma tool keeps asking me to install Cerberus.", "completion": "Cerberus is a utility that provides Uber laptop access to production hosts. This tool lives in our internal brew tapset  part of homebrew for Mac packages .To install Cerberus for Linux, see ma cerberus Installation Instructions for ATG.To install Cerberus for Mac:git clone :homebrew-alt  usr local Homebrew Library Taps uber homebrew-alt  brew install cerberusFor more details, go to https:  code.uberinternal.com w projects code_management uber-homebrew-alt ."}
{"prompt": "Prediction take much longer time after switching to Hive table as data source I realised that my model prediction takes much longer time after switching to Hive table as data source. Any idea why this happens?", "completion": "Cerberus is a utility that provides Uber laptop access to production hosts. This tool lives in our internal brew tapset  part of homebrew for Mac packages .To install Cerberus for Linux, see ma cerberus Installation Instructions for ATG.To install Cerberus for Mac:git clone :homebrew-alt  usr local Homebrew Library Taps uber homebrew-alt  brew install cerberusFor more details, go to https:  code.uberinternal.com w projects code_management uber-homebrew-alt ."}
{"prompt": "Michelangelo job failed without being able to report error", "completion": "Because you put ; in advanced settings:https:  michelangelo.uberinternal.com rider_home_prediction settings"}
{"prompt": "Not able to save Michelangelo project settings When I try to edit Spark settings here, and click Save, and go back to my project settings, I see that they are not being saved. What is going on?", "completion": "This was a bug where empty configs would not overwrite existing settings. It has been fixed now."}
{"prompt": "How do I set up the SLA for new projects now that the SQL pipeline is disabled?", "completion": "The Upstream SLA  Hours  setting has been moved to project view under ADVANCED SPARK SETTINGS."}
{"prompt": "Michelangelo feature store all-active status", "completion": "The feature-store will generate the same pipeline in both DCs. For active-active, please make sure pipelines in all DCs are active and run without issue. For Cassandra dispersal, we rely on Piper master DC setting to determine which DC will disperse data.Please also make sure AthenaX jobs  for near-realtime feature computation  are active-active compliance as well. Depending on your use case, it may mean processing events from local Kafka aggregator and make sure the same uuids are not getting written to Cassandra from both DCs."}
{"prompt": "How do I train and use real-time prediction service with multiple feature groups? We want to deploy a model to Michelangelo real-time prediction service. Each prediction requires three kind of features: user_features, time_features and geo_features.When doing real-time prediction, the upstream service will pass in user_uuid as the uuid of the user_features, time_of_trip as the uuid of the time_features and geohash_6 as the uuid of the geo_features. After gather these features, we can use the model to do prediction.From the Michelangelo doc, it seems that:We need to use Palette to disperse the three tables in cassandra.The questions are:Are there any examples of a real-time prediction model that uses features from multiple feature tables?How should we config in Michelangelo when we train the models, so that it will know which is the key uuid to use when doing real-time prediction?Thanks!", "completion": "The feature-store will generate the same pipeline in both DCs. For active-active, please make sure pipelines in all DCs are active and run without issue. For Cassandra dispersal, we rely on Piper master DC setting to determine which DC will disperse data.Please also make sure AthenaX jobs  for near-realtime feature computation  are active-active compliance as well. Depending on your use case, it may mean processing events from local Kafka aggregator and make sure the same uuids are not getting written to Cassandra from both DCs."}
{"prompt": "How do I handle Michelangelo error: Forbidden: Uber Auth headers are not set", "completion": "The feature-store will generate the same pipeline in both DCs. For active-active, please make sure pipelines in all DCs are active and run without issue. For Cassandra dispersal, we rely on Piper master DC setting to determine which DC will disperse data.Please also make sure AthenaX jobs  for near-realtime feature computation  are active-active compliance as well. Depending on your use case, it may mean processing events from local Kafka aggregator and make sure the same uuids are not getting written to Cassandra from both DCs."}
{"prompt": "How can I monitor the success rate of Michelangelo model?", "completion": "We've a dashboard. You select corresponding prediction-group and project."}
{"prompt": "What can be done to optimize the training speed of k-means using michelangelo?", "completion": "yj.chen, I took a quick look at the Hive table  fraud.rider_location  you used.:$ curl http:  localhost:14167 janus api v1 databases fraud tables rider_location schema  schema :[  fieldName : trip_id , fieldType : string  ,  fieldName : rider_lat , fieldType : float  ,  fieldName : rider_lng , fieldType : float  ,  fieldName : occurred_at , fieldType : bigint  ] It's not partitioned by 'datestr' and does not even contain a 'datestr' field so we're reading in the entire table instead of just one day's data."}
{"prompt": "Michelangelo: datestr is missing for palette features", "completion": "yj.chen, I took a quick look at the Hive table  fraud.rider_location  you used.:$ curl http:  localhost:14167 janus api v1 databases fraud tables rider_location schema  schema :[  fieldName : trip_id , fieldType : string  ,  fieldName : rider_lat , fieldType : float  ,  fieldName : rider_lng , fieldType : float  ,  fieldName : occurred_at , fieldType : bigint  ] It's not partitioned by 'datestr' and does not even contain a 'datestr' field so we're reading in the entire table instead of just one day's data."}
{"prompt": "Running tensorflow in opus-deep-learning on local machine or jenkins machine for build and unit testing ", "completion": "yj.chen, I took a quick look at the Hive table  fraud.rider_location  you used.:$ curl http:  localhost:14167 janus api v1 databases fraud tables rider_location schema  schema :[  fieldName : trip_id , fieldType : string  ,  fieldName : rider_lat , fieldType : float  ,  fieldName : rider_lng , fieldType : float  ,  fieldName : occurred_at , fieldType : bigint  ] It's not partitioned by 'datestr' and does not even contain a 'datestr' field so we're reading in the entire table instead of just one day's data."}
{"prompt": "Why am I getting a  Feature not found  error trying to pull data from a hive table?", "completion": "In your DSL, please remove spaces between @basis and feature name.We are investigating populate basis feature issue."}
{"prompt": "Cannot call gen_sample_tcurl.py when testing realtime models", "completion": "we change how data is stored, hence the tool is no longer supported. To test, you can mock the sample query with your features. Something like --body '  request :   projectId :  vs_marketplace_econ_mvp ,  basisFeatures : [  stringValue :  0036508d-8655-4e6b-bb1c-47b8eecd76a7 ,  key :  @basis:basis_driver_uuid  ,   stringValue :  2017-10-23 ,  key :  @basis:basis_datestr  ,   stringValue :  0036508d-8655-4e6b-bb1c-47b8eecd76a7 ,  key :  @basis:driver_uuid  ,   doubleValue : 0.0,  key :  @basis:earning_before_cash_and_vehicle_l7d  ,   stringValue :  2017-10-23 ,  key :  @basis:dtPartition  ],  modelId :  2017-11-08-19-28-36-185-UTC   ' Please replace request body with your project, modelId, and features."}
{"prompt": "I cannot access hive table generation by Michelangelo via Presto Once I change the data source to hive table and run the prediction from the new data source, 1  the prediction outcome now stores in a new table instead of the old one. 2  the new table is only queryable through Hive not Presto. Is it possible to make the new prediction tables available on Presto?Thanks,Yun", "completion": "we change how data is stored, hence the tool is no longer supported. To test, you can mock the sample query with your features. Something like --body '  request :   projectId :  vs_marketplace_econ_mvp ,  basisFeatures : [  stringValue :  0036508d-8655-4e6b-bb1c-47b8eecd76a7 ,  key :  @basis:basis_driver_uuid  ,   stringValue :  2017-10-23 ,  key :  @basis:basis_datestr  ,   stringValue :  0036508d-8655-4e6b-bb1c-47b8eecd76a7 ,  key :  @basis:driver_uuid  ,   doubleValue : 0.0,  key :  @basis:earning_before_cash_and_vehicle_l7d  ,   stringValue :  2017-10-23 ,  key :  @basis:dtPartition  ],  modelId :  2017-11-08-19-28-36-185-UTC   ' Please replace request body with your project, modelId, and features."}
{"prompt": "What are Michelangelo's latency SLAs and scale limits? Rider payments team plan to start two realtime prediction projects  payment profile prediction before trip request, personalized payment options during rider signup . We have some questions here:What is the general latency for Michelangelo realtime prediction service?Is it allowed we call Michelangelo at eyeball scale? What is the latency in that case?Any other things we need to be aware of before we start calling Michelangelo?", "completion": "What is the general latency for Michelangelo realtime predictionservice?I think this depends on the specifics of your model type, whether your model needs access to the feature store etc. If your model doesn't need access to the feature store, then the latency is <100 ms. If your model does need access to the feature store, there's a 80-100 ms latency overhead. You can read more in our docs.Is it allowed we call Michelangelo at eyeball scale? What is thelatency in that case?Yes - michelangelo is serving predictions for uETA at eyeball scale. You can see details here.Any other things we need to be aware of before we start callingMichelangelo?Please make a ticket for Michelangelo Online Serving with details  project details, estimated traffic, any sharding requiremnents, etc  so that a group can be provisioned and configured for you. There's lots of more context in our engdocs."}
{"prompt": "Error while publishing", "completion": "What is the general latency for Michelangelo realtime predictionservice?I think this depends on the specifics of your model type, whether your model needs access to the feature store etc. If your model doesn't need access to the feature store, then the latency is <100 ms. If your model does need access to the feature store, there's a 80-100 ms latency overhead. You can read more in our docs.Is it allowed we call Michelangelo at eyeball scale? What is thelatency in that case?Yes - michelangelo is serving predictions for uETA at eyeball scale. You can see details here.Any other things we need to be aware of before we start callingMichelangelo?Please make a ticket for Michelangelo Online Serving with details  project details, estimated traffic, any sharding requiremnents, etc  so that a group can be provisioned and configured for you. There's lots of more context in our engdocs."}
{"prompt": "How to use free text as features in Michelangelo I have to do text classification for my project and I have free text for each example, I want to know how to use that as a feature in Michelangelo and also is there any kind of preprocessing is supported on text features?", "completion": "What is the general latency for Michelangelo realtime predictionservice?I think this depends on the specifics of your model type, whether your model needs access to the feature store etc. If your model doesn't need access to the feature store, then the latency is <100 ms. If your model does need access to the feature store, there's a 80-100 ms latency overhead. You can read more in our docs.Is it allowed we call Michelangelo at eyeball scale? What is thelatency in that case?Yes - michelangelo is serving predictions for uETA at eyeball scale. You can see details here.Any other things we need to be aware of before we start callingMichelangelo?Please make a ticket for Michelangelo Online Serving with details  project details, estimated traffic, any sharding requiremnents, etc  so that a group can be provisioned and configured for you. There's lots of more context in our engdocs."}
{"prompt": "What are Michelangelo's SLAs? I want to learn what the SLAs are and how well Michelangelo is meeting them.", "completion": "See the Michelangelo SLA Dashboard"}
{"prompt": "How can I check if a double isinfinity in Michelangelo DSL? Does Michelangelo DSL support for infinity check for double value?For example, if i have 5 0 and want to replace with 1.", "completion": "https:  code.uberinternal.com diffusion DAMIC browse master core src main scala com uber michelangelo featureEng Functions.scala;6bb0875ecf17ce8ecbca3e208f74e70cc9027af7$316nFill by default will fall back on both NaN and infinity.if you really want to things very precise, you can do in the scala wayfor example:if  nVal  foo  .isNaN   ...   else  ...  orif  nVal  bar  .issInfinity  ...   else  ... "}
{"prompt": "What is the prediction filter in Michelangelo? There are two different filters, Training filter and Prediction Filter as seen here. The names indicate that Prediction Filter is a filter on the data that the model is applied on, but we have some examples where that is disproved.", "completion": "https:  code.uberinternal.com diffusion DAMIC browse master core src main scala com uber michelangelo featureEng Functions.scala;6bb0875ecf17ce8ecbca3e208f74e70cc9027af7$316nFill by default will fall back on both NaN and infinity.if you really want to things very precise, you can do in the scala wayfor example:if  nVal  foo  .isNaN   ...   else  ...  orif  nVal  bar  .issInfinity  ...   else  ... "}
{"prompt": "Where can I learn more about publishing michelangelo predictions to kafka topics? The Michelangelo UI has a option to publish predictions to a Kafka topic. I had a few questions about this:Does this work?How can I onboard a topic? If I create a new topic, I'd need to know the schema of the Kafka message.Thanks!", "completion": "https:  code.uberinternal.com diffusion DAMIC browse master core src main scala com uber michelangelo featureEng Functions.scala;6bb0875ecf17ce8ecbca3e208f74e70cc9027af7$316nFill by default will fall back on both NaN and infinity.if you really want to things very precise, you can do in the scala wayfor example:if  nVal  foo  .isNaN   ...   else  ...  orif  nVal  bar  .issInfinity  ...   else  ... "}
{"prompt": "Can we switch a project from realtime to batch and then switch back?", "completion": "https:  code.uberinternal.com diffusion DAMIC browse master core src main scala com uber michelangelo featureEng Functions.scala;6bb0875ecf17ce8ecbca3e208f74e70cc9027af7$316nFill by default will fall back on both NaN and infinity.if you really want to things very precise, you can do in the scala wayfor example:if  nVal  foo  .isNaN   ...   else  ...  orif  nVal  bar  .issInfinity  ...   else  ... "}
{"prompt": "Reference example of a recent Michelangelo model Is there any example of a recent Michelangelo model that has been deployed correctly using all functionalities as they are today  so Hive Table as data source, Data Snapshot, DCA1 ? I'd love to have a link so that we can have a look at how it has been implemented deployed, as a reference.Thanks in advance!", "completion": "There are many projects that train  deploy models regularly dispatch_rider_cancels_v3, Optic_Model_v2, dispatch_driver_cancels_v3, etc."}
{"prompt": "Data Snapshot in Michelangelo What do we need to know about the new functionality of  Data Snapshot  - how is it relevant for training the model vs. the predictions?", "completion": "There are many projects that train  deploy models regularly dispatch_rider_cancels_v3, Optic_Model_v2, dispatch_driver_cancels_v3, etc."}
{"prompt": "Categorical variables in Michelangelo Me and Tara Tabatabai are currently working on implementing a Driver Churn Prediction Model in Michelangelo. We've tried this out in R first for speed, and now want to implement in Michelangelo.Our dataset contains numerous categorical variables - datestr, channel, partner_country_name, etc. Our training and validation datasets had different factor levels for some variables  e.g. different channels , which led to problems in our XGBoost predictions that were temporarily resolved in R by removing all categorical variables from both datasets. It seemed that the one hot encoding in R led to a different number of variables in the two datasets, and thus mis-matched matrices. Numeric encoding would also have been a problem because with different categories, for example a category may be coded differently in the two datasets. We saw in Michelangelo we have just these two options: one hot encoding and numeric encoding, that we don't know how to apply without the above mentioned issues. How can we handle this problem in Michelangelo without removing the variables entirely?Thanks in advance!", "completion": "In general, we support numeric and categorical features. We support string indexer string indexer and one-hot encoding for categorical features. String indexer is a variant of numeric encoding.  Please do not use uuid type features because 1  model still then  memorize  uuids and 2  it can cause memory issue.  For a specific categorical feature, we first sort it by frequency in the sample data in the decreasing order. We then apply some cutoff. For string indexer, the limit is O number of bins . For one-hot encoding, the limit is O  number of bins ^2 . For example, let's you have a feature X with values A, B, C, ..., Z, where frequency A  >= frequency B  >= ...>= frequency Z . If the number of bins in the model configuration is 5, then A, B, C, D, and E will have corresponding index value for string indexer. F thru Z will all get grouped into  overflow  index. In the case of one-hot encoding,  overflow  simply means expanded features all have values of 0.  Think binary membership encoding. The recommendation is to look at distribution of each categorical feature and set the number of bins accordingly. Please note increasing number of bins may increase training time. High number of bins may also cause OOM  out of memory  issue.Few other things. 1   A  and  a  are two different values. If they should be treated as the same categorical value, please apply DSL and cleanse your data before training.  Please refer to DSL link on the model spec to see DSL.  2  The categorical values you use in prediction must be the same as one you used in training. For example, if you train city_id with  1 ,  2 , etc. During prediction, you shouldn't change it to  SF  nor  San Francisco. "}
{"prompt": "Balancing unbalanced data in Michelangelo using Max After Bal for XGBoost We have an imbalanced dataset and had been informed that the parameter 'max after bal' was available for XGBoost on Michelangelo  similar to scale_pos_weight in R's XGBoost package , but we see now that isn't the case  specifically not for XGBoost, it is for other methods . Since XGBoost is one of the strongest ML methods, would it be possible to integrate this parameter in Michelangelo for XGBoost? Or is there another way of using 'max after bal' or similar for XGBoost in Michelangelo  we are already aware of the over- and undersampling options, that are not preferred .Thanks in advance!", "completion": "In general, we support numeric and categorical features. We support string indexer string indexer and one-hot encoding for categorical features. String indexer is a variant of numeric encoding.  Please do not use uuid type features because 1  model still then  memorize  uuids and 2  it can cause memory issue.  For a specific categorical feature, we first sort it by frequency in the sample data in the decreasing order. We then apply some cutoff. For string indexer, the limit is O number of bins . For one-hot encoding, the limit is O  number of bins ^2 . For example, let's you have a feature X with values A, B, C, ..., Z, where frequency A  >= frequency B  >= ...>= frequency Z . If the number of bins in the model configuration is 5, then A, B, C, D, and E will have corresponding index value for string indexer. F thru Z will all get grouped into  overflow  index. In the case of one-hot encoding,  overflow  simply means expanded features all have values of 0.  Think binary membership encoding. The recommendation is to look at distribution of each categorical feature and set the number of bins accordingly. Please note increasing number of bins may increase training time. High number of bins may also cause OOM  out of memory  issue.Few other things. 1   A  and  a  are two different values. If they should be treated as the same categorical value, please apply DSL and cleanse your data before training.  Please refer to DSL link on the model spec to see DSL.  2  The categorical values you use in prediction must be the same as one you used in training. For example, if you train city_id with  1 ,  2 , etc. During prediction, you shouldn't change it to  SF  nor  San Francisco. "}
{"prompt": "Michelangelo fails with unclear error", "completion": "In general, we support numeric and categorical features. We support string indexer string indexer and one-hot encoding for categorical features. String indexer is a variant of numeric encoding.  Please do not use uuid type features because 1  model still then  memorize  uuids and 2  it can cause memory issue.  For a specific categorical feature, we first sort it by frequency in the sample data in the decreasing order. We then apply some cutoff. For string indexer, the limit is O number of bins . For one-hot encoding, the limit is O  number of bins ^2 . For example, let's you have a feature X with values A, B, C, ..., Z, where frequency A  >= frequency B  >= ...>= frequency Z . If the number of bins in the model configuration is 5, then A, B, C, D, and E will have corresponding index value for string indexer. F thru Z will all get grouped into  overflow  index. In the case of one-hot encoding,  overflow  simply means expanded features all have values of 0.  Think binary membership encoding. The recommendation is to look at distribution of each categorical feature and set the number of bins accordingly. Please note increasing number of bins may increase training time. High number of bins may also cause OOM  out of memory  issue.Few other things. 1   A  and  a  are two different values. If they should be treated as the same categorical value, please apply DSL and cleanse your data before training.  Please refer to DSL link on the model spec to see DSL.  2  The categorical values you use in prediction must be the same as one you used in training. For example, if you train city_id with  1 ,  2 , etc. During prediction, you shouldn't change it to  SF  nor  San Francisco. "}
{"prompt": "POC for Setting Up a Production Environment of Realtime Prediction I am following the guide to set up a ML model for Realtime Prediction. Who should I work with in Michelangelo team for the process of  Set Up a Production Environment ? I signed up for an office hour slot in the spreadsheet, but it looks like no one monitors the sheet. Does Michelangelo team still have office hour?", "completion": "Please provide QPS and your project in a ticket. In the tag, add  MA TEAM - ONLINE    Michelangelo  and assign it to the current oncall. You can find the current oncall here"}
{"prompt": "validate error when trying to train my model template I am trying to train a simple xgboost model on Michelangelo. I set up my model template but when I click the train button, it gave me an error like the following:An error has occured while training to validate your training job. Make sure you have a working internet connection, then try again or continue to start the training job. Try AgainI am not sure if there is something going on or it is something in my model setting. Can someone from michelangelo help me take a look?Here is a link to my model:Seems that it can proceed if I click  continue anyway , but I am not too sure about it.", "completion": "UPDATE: A fix for this has now been deployed.Looks like we were able to get your model running with a few changes:Queue name was wrong in the project config  changed to fraud-tier3 Some data had nulls or NaN, so I added nFill nVal in the feature DSLWe are not sure why the validation is failing yet, but you can ignore it and go ahead with any training -- issue is being tracked here if interested.Let me know if I can help with anything else"}
{"prompt": "Can Realtime Predict Service make multiple predictions in a query", "completion": "we support batch and multi-model predictions. See thrift doc. Note that batch and multi-model predictions response time will be higher since we need to make predictions."}
{"prompt": "How can I debug  Job failed without being able to report error  errors in Michelangelo training?", "completion": "We recommend customers to use their own yarn queues and db. The reason why a job would not train due to misconfiguration of project settings is usually errors in the queue name  e.g. a queue that does not exist or format is wrong  so the job cannot be queued correctly by YARN."}
{"prompt": "populating basis features has problem", "completion": "The join-ky in the palette expression must be a  string  column in your  training  data source table."}
{"prompt": "AssertionError: basis_feature_name not necessarily in feature list", "completion": "See Feature Naming Conventions. Basically, if you have [a-z]+ sum|count  1-9  week|day , we perform automatic aggregation from the base feature  in Cassandra lookup for realtime prediction . For example, if you have completed_trip_count_8week, we require you have completed_trip_count_1day.One way to get around such lint rule is to name your feature-name differently. Instead of completed_trip_count_8week, called it something likecompleted_trip_count_8wk or completed_trip_8week_count."}
{"prompt": "Disperse shared features  created by other teams  to Cassandra for realtime prediction", "completion": "There are many examples including driver trips. Do git grep on the dictionary folder. 1  Make sure the Cassandra cluster doesn't require auth password. 2  If you are writing for new entity, please make sure to create keyspace in Cassandra. 3  Note that you shouldn't disperse data to other team's Cassandra. If you are writing and reading from the palette POC cluster, please inform michelangelo team and only small volume to it. palette POC cluster has no SLA."}
{"prompt": "How can I trigger michelangelo prediction on piper job completion, and another piper job on prediction completion?", "completion": "There is michelangelo_platform tasks prediction_task.py."}
{"prompt": "Michelangelo prediction stuck in the queued state for 8+ hours My Michelangelo prediction was scheduled through piper, and it has been in the 'queued' status in 8 hours, is this normal?", "completion": "https:  michelangelo.uberinternal.com driver_dedup settings shows you are using fraud-tier3 queue.https:  grafana4.uberinternal.com dashboard db hadoop-queue-utilization?refresh=5sorgId=1var-cluster=dca1-neon-prodvar-queue=fraudvar-subqueue=fraud-tier3from=now-7dto=nowshows that queue is very busy.You will want to use your team's subqueue that is less busy or work with Hadoop Infra to increase capacity."}
{"prompt": "How can I comment on error in the eng docs?", "completion": "https:  michelangelo.uberinternal.com driver_dedup settings shows you are using fraud-tier3 queue.https:  grafana4.uberinternal.com dashboard db hadoop-queue-utilization?refresh=5sorgId=1var-cluster=dca1-neon-prodvar-queue=fraudvar-subqueue=fraud-tier3from=now-7dto=nowshows that queue is very busy.You will want to use your team's subqueue that is less busy or work with Hadoop Infra to increase capacity."}
{"prompt": "ma tool prompt for root password While using the ma tool, using ssh or notebook, the terminal prompts for the root credentials.How should one attempt to solve prompts for 's password? Have tried playing around with the VPN, proxy, re-running bootstrap and re-establishing the RSA key Thanks", "completion": "TL;DR:$ssh-add -ARe-spawn the tasks. Old training instances won't work even after adding the ssh keys.Over and above the answer https:  stack.uberinternal.com a 16041 6845, one needs to ensure that older spawns of training tasks can not be logged in. New tasks need to be created after setting the ssh.Thanks to inputs from @jeevan while fixing the issue"}
{"prompt": "michelangelon python CLI tool ssh connection refused I keep connection refused while trying to connect to IRN. It seems to try to connect in as root$ ma ssh --label sidney_test_job    Running: ssh -o StrictHostKeyChecking=no -p 31017 channel 0: open failed: connect failed: Connection refusedssh_exchange_identification: Connection closed by remote hostBut I can ssh into the box directly  under my own username $ ssh Creating directory ' home sidney'.Asset Tag: U012725Hostname: cmp-b4f45741.pit-irn-1.uberatc.netPool: MESOS-PROD02Primary Role: computeSecondary Role: Rack Position: IRN2-M6-U21Status: Allocated:RUNNINGIf you need assistance, visit #infra-support on Slack.Enjoy!But if I ssh into directly then I will be outside of the docker environment", "completion": "TL;DR:$ssh-add -ARe-spawn the tasks. Old training instances won't work even after adding the ssh keys.Over and above the answer https:  stack.uberinternal.com a 16041 6845, one needs to ensure that older spawns of training tasks can not be logged in. New tasks need to be created after setting the ssh.Thanks to inputs from @jeevan while fixing the issue"}
{"prompt": "Seeing HTTP errors when using MA tool", "completion": "TL;DR:$ssh-add -ARe-spawn the tasks. Old training instances won't work even after adding the ssh keys.Over and above the answer https:  stack.uberinternal.com a 16041 6845, one needs to ensure that older spawns of training tasks can not be logged in. New tasks need to be created after setting the ssh.Thanks to inputs from @jeevan while fixing the issue"}
{"prompt": "Is there a hive table for Michelangelo models? Im interested in getting aggregate data on Michelangelo models that are deployed in production. Which hive table should I query?", "completion": "TL;DR:$ssh-add -ARe-spawn the tasks. Old training instances won't work even after adding the ssh keys.Over and above the answer https:  stack.uberinternal.com a 16041 6845, one needs to ensure that older spawns of training tasks can not be logged in. New tasks need to be created after setting the ssh.Thanks to inputs from @jeevan while fixing the issue"}
{"prompt": "Problems installing Michelangelo python client I'm trying to install the Michelangelo python client following the directions here https:  engdocs.uberinternal.com michelangelo-python-client installation.htmlthe pip is giving me the error Could not find a version that satisfies the requirement michelangelo-python-client==0.4.16  from versions:  No matching distribution found for michelangelo-python-client==0.4.16 ", "completion": "TL;DR:$ssh-add -ARe-spawn the tasks. Old training instances won't work even after adding the ssh keys.Over and above the answer https:  stack.uberinternal.com a 16041 6845, one needs to ensure that older spawns of training tasks can not be logged in. New tasks need to be created after setting the ssh.Thanks to inputs from @jeevan while fixing the issue"}
{"prompt": "Should michelangelo feature palette names be quoted in model definitions? Some Michelangelo docs show palette DSL queries quoting feature names, and some do not. For example:, the model output engdoc does not show quotes:But the feature store guide does:Which is correct?", "completion": "Both formats  with or without quotes around the feature names  are acceptable. Thanks."}
{"prompt": "Michelangelo reads data from hive   hdfs Anybody has an example of Michelangelo reading from hive   hdfs?I get 'HDFS Path must be valid and for an existing location' error no matter what path I put in", "completion": "Both formats  with or without quotes around the feature names  are acceptable. Thanks."}
{"prompt": "Local hour day where client request was made Hour of day and Day of the week  both are local to where the request was made  are real-time features that we want to pass into Michelangelo. Is there a service that does this already?", "completion": "Both formats  with or without quotes around the feature names  are acceptable. Thanks."}
{"prompt": "Issue with model prediction I implemented a model FutureTrip_28D_Prediction in michelangelo last Friday. Now I am trying to do predictions for day 8 27 and day 10 24. The prediction for 8 27   25k records  completed in half hour. However, the prediction for 10 24  100M records  has run for more than 4 days and is still not completed. How long should we expect about prediction time for about 100M records?On Saturday I tried to  apply prediction with another model Rider_churn_model_V1_elise built a while ago in michelangelo with data for day Oct. 28. It's not complete yet either.Could you please advise what should be the next step to get everything working? Any inputs will be highly appreciated!", "completion": "Both formats  with or without quotes around the feature names  are acceptable. Thanks."}
{"prompt": "michelangelo data prep fails because of insufficient memory", "completion": "Both formats  with or without quotes around the feature names  are acceptable. Thanks."}
{"prompt": "Feature visualization for categorical data in Michelangelo when I try to check the visualization for the categorical feature in Michelangelo I found that the order of labels is arbitrary. This makes it very hard to visually comprehend the distribution of data. I wonder if it is possible to sort the feature label by numeric value, lexicographical order, or label frequency. Thanks!Just to clarify, here is what I mean:This plot is supposed to show the distribution of 'day-of-week' feature. Label values are randomly ordered.", "completion": "Both formats  with or without quotes around the feature names  are acceptable. Thanks."}
{"prompt": "Not able to generate prediction after model deployment", "completion": "Both formats  with or without quotes around the feature names  are acceptable. Thanks."}
{"prompt": "How to manually check michelangelo online prediction model deployment status", "completion": "Both formats  with or without quotes around the feature names  are acceptable. Thanks."}
{"prompt": "How to find the scheduler URL using ma tool? If I have the jobID, how do I find the scheduler URL?ma showall only gives me the jobID but not the scheduler URL link", "completion": "Both formats  with or without quotes around the feature names  are acceptable. Thanks."}
{"prompt": "Michelangelo Local Piper Connection Error", "completion": "Kevin changed to use TrainTask which lately changed to use thrift api as well. We need to change the following line of code:https:  code.uberinternal.com diffusion DAPIPE browse master michelangelo_platform lib rest_api.py;d058a037b36a8362d60a6fe3ce6bd5e4a19f2406$654api.set_params email=SERVICE_EMAIL, base_url= http:  192.168.65.1:14785  Opened ticket to support easy local debugging for customer scenario."}
{"prompt": "Getting test set  hold-out  scores I'd like to get a table of test set  hold-out set  scores after fitting a model with Michelangelo, for evaluating the performance in a custom way. Is there a way to do that directly, other than scheduling a new prediction task?", "completion": "one can use one-off prediction"}
{"prompt": "How can I access a trained model in Michelangelo? I'm wondering if there's a good way to access a trained model in Michelangelo? I see in the onboarding doc that the prediction is generated on schedule and published to Hive. In my use case, I want to access the trained model and do custom prediction  predict on features that are counterfactual . Is that possible with Michelangelo?", "completion": "one can use one-off prediction"}
{"prompt": "Where is Michelangelo grafana dashboard for client requests? For tchannel requests' latencies to Michelangelo gateways etc?Thanks.", "completion": "The online prediction service dashboard is titled michelangelo-prediction-service. You should be able to drill down into your specific groups to see latencies, throughput, etc.There's also a dashboard for michelangelo-gateway that lets you introspect how the gateway is doing."}
{"prompt": "Model Predictions Fail in DCA1", "completion": "That error might be transient. I rerun the prediction job for 3 23 on dca1, it succeeded."}
{"prompt": "How to debug Michelangelo training piper pipeline?", "completion": "We use this example to show debug steps.From michelangelo UI, you will see a job name: tm20180809-194937-OYUQYKML.The piper pipeline name will be: michelangelo_wf_ project_name _backfill_ datacenter _ model_id , where model_id is tm20180809-194937-OYUQYKML in this example.You can go to piper SJC or piper DCA to search and find this pipelineFrom piper UI, you can trace pipeline task log. We output important information for michelangelo job, such as  drogon  job id and spark url.If spark url is not shown on piper trace log, you can query from drogon UI. Use the job id obtained from piper trace log, and set correct cluster  from header , you will find the spark application id and url for this job.If job is already finished  so disappeared from piper UI , you can find logs from ELK and use msg_.pipeline_id to filter and get the logs."}
{"prompt": "Error creating classification model: Response variable cannot exist as an input feature I'm following this ML codelabs to create a supervised-learning binary classifier. I've uploaded my training validation dataset to Hive and am trying to create the model template. The input data is labelled using the phishing column  a binary classification . I want to train a model to predict it using all other features.Are my features set up correctly? Should I be entering something else in the 'Response' section?", "completion": "You need to remove the last line  phishing:@basis:phishing  in the  features  section."}
{"prompt": "Michelangelo model training stuck at  data transform  step. How can I find out what is wrong? This is a model that normally completes training within 4 hours. The screenshot is below. In general, what should a user do in such cases? Is there a way to check the logs? The source dataset is a  view  rather than a physical table, but the view statement is simply selecting a subset of the columns. Is using views okay for Michelangelo, or should physical tables be preferred?", "completion": "You need to remove the last line  phishing:@basis:phishing  in the  features  section."}
{"prompt": "Prediction error: Failed to register your dataframe to Hive", "completion": "You need to remove the last line  phishing:@basis:phishing  in the  features  section."}
{"prompt": "looking for reactive java client example for michelangelo prediction looking for reactive java client example for michelangelo prediction. i want to call several models in parallel using java 8's completablefuture. anyone already doing that? example code will be helpful.", "completion": "You need to remove the last line  phishing:@basis:phishing  in the  features  section."}
{"prompt": "Predictions fail with 'Failed to register your dataframe to Hive'", "completion": "The problem is coming from the input dataset.When seeing these type of errors there are usually two reasons associated with it. 1. the hdfs quota is exceeded. In that case, in the stack track you will see some exceptions about HDFS quota. When this happens. Ask hadoop infra team to get more hdfs resources2. Unbalanced dataset in hive table  what happened this time . We will introduce a new spark config spark.ext.michelangelo.num_input_partitions, users need to set this value in their project settings. Usually set this to the number of workers * 9. That will fix the skewed datasets."}
{"prompt": "What does  prediction complete  in Michelangelo mean?", "completion": "In some cases prediction success status and publish success status get messed up due to racing conditions. But generally you should be able to get your publish table in the hive database you specified. The publish table naming format is michelangelo_perm_ project_id _predictions.However I cannot find your publish table. The reason is you are using michelangelo_staging database. NEVER EVER use michelangelo_staging database. This database is for our staging integration tests and all tables will be deleted within 24 hours."}
{"prompt": "Is there any documentation for @prediction fields in Michelangelo? I took a look at the Feature scoping section of EngDocs, however the different @prediction: fields  e.g. @prediction:true  are not listed in the linked doc. Is there anywhere where I can find information about these fields?", "completion": "@prediction: is based on your models to be trained.For example if that is a binary classification, you will have @prediction:<true_label> and @prediction:<false_label>. If that is a multi case you will have @prediction:<label_name>if that is a regression model, you won't have anything like this but only @predition:predict"}
{"prompt": "Get results of Michelangelo via Querybuilder I've run many models and it's painful to click-to-see the result. Is there a query or tool to automatically get all the information from all the models I've created on Michelangelo? For example, if I have model 1 and model 2, hope to write a query somewhere to get all the results from those models.", "completion": "@prediction: is based on your models to be trained.For example if that is a binary classification, you will have @prediction:<true_label> and @prediction:<false_label>. If that is a multi case you will have @prediction:<label_name>if that is a regression model, you won't have anything like this but only @predition:predict"}
{"prompt": "Michelangelo prediction group not in peer list", "completion": "Group 37 is a sharded group which does not support shard  production , you need to specify a valid city id as the shard key.For model sharding please see: https:  engdocs.uberinternal.com michelangelo user-guides model-sharding.htmlFor one off prediction through DSW please see https:  engdocs.uberinternal.com michelangelo user-guides one-off-predictions.html"}
{"prompt": "How to modify a MLE workflow I'm looking to modify a MLE workflow: https:  mlexplorer.uberinternal.com project u4b_profile_suggestion workflow 5f5b702d-ba4e-4419-83c0-fe69d652f58fHowever seems I cannot make any change to it. Am I missing permission or?I want to add new element in  Parameters  ->  Dynamic Variables  ->  org_list .", "completion": "Only registered users can edit the workflow. I see that project owner is  You can ask him to add you in that project owner."}
{"prompt": "Problem Running Michelangelo with CSV>Hive Data", "completion": "Only registered users can edit the workflow. I see that project owner is  You can ask him to add you in that project owner."}
{"prompt": "Data after transformation is empty Error", "completion": "for your case, the problem is most likely in label DSL expression. see other trained model using other columnhttps:  michelangelo.uberinternal.com longfei_test_model models tm20180929-010602-VKTSAKUD childModels tm20180929-010602-VKTSAKUD-GMJQFZnote that i think there could be a lot of bad data like NaN."}
{"prompt": "Column @prediction:predict is absent in feature list My models that were running daily batch predictions correctly just failed this morning with error 'Column @prediction:predict is absent in feature list'.This field should be prediction output and not a feature, so it should not appear in feature set. How can we fix the issue?", "completion": "Issue caused by underlying data and gone after regeneration."}
{"prompt": "Is it fine for our online features to run once per week?", "completion": "Issue caused by underlying data and gone after regeneration."}
{"prompt": "MA model logging and metrics Our team wants to log prediction and store them in Hive. I checked the Engdoc and the default sample ratio is 10%, wondering is it possible to increase it to 100%? Where should I configure this? And how long do the data stay in Hive?Thanks.", "completion": "it is possible, however, there is an overhead performance hit associated with high sample rate. we also dual publish prediction to M3. M3 may not have capacity. What is your QPS? why you need higher sampling rate?there is no ttl associated with prediction. the raw data table retention policy may be determined later on by the hadoop infra team  data security team.if you are trying to evaluate model performance offline, you can try one-off prediction instead of sending traffic to online-prediction service."}
{"prompt": "Persist train test table Is there a way to persist predicted tables from michelangelo? currently the tables expire after 1 day or so but we need to repeatedly use them.", "completion": "it is possible, however, there is an overhead performance hit associated with high sample rate. we also dual publish prediction to M3. M3 may not have capacity. What is your QPS? why you need higher sampling rate?there is no ttl associated with prediction. the raw data table retention policy may be determined later on by the hadoop infra team  data security team.if you are trying to evaluate model performance offline, you can try one-off prediction instead of sending traffic to online-prediction service."}
{"prompt": "Can `:number` in DSL functions take value greater than 1 for online services?", "completion": "it is possible, however, there is an overhead performance hit associated with high sample rate. we also dual publish prediction to M3. M3 may not have capacity. What is your QPS? why you need higher sampling rate?there is no ttl associated with prediction. the raw data table retention policy may be determined later on by the hadoop infra team  data security team.if you are trying to evaluate model performance offline, you can try one-off prediction instead of sending traffic to online-prediction service."}
{"prompt": "Michelangelo: apply DSL UDF or use PyML to modify response variable before returning? We are working on a feature that will rely on Michelangelo to cluster items.  The front end feature requires not just the cluster ID, but some information about the items in that cluster. Is there a way to get Michelangelo to return this information? We are trying to avoid having to query on the front end. Would using PyML help?", "completion": "One can leverage published fields. For example, this model they havenVal  @prediction:true   to get classification model's prob score and percentileBucket  @prediction:true , nVal  @prediction:true  , stats  to get percentile bucket for the probability score."}
{"prompt": "Feature store access from backend service", "completion": "Think Eats team has several models using latent factors, which are stored as json blob. There are corresponding UDFs added by Eats team on how to parse and do  dot-product. Yes, it is possible to access features directly from Cassandra. However, we discourage that."}
{"prompt": "Michelangelo not allowing datasource because timestamp is unsupported datatype", "completion": "In general, we don't support complex data type such array, map, timestamp, hive date. See here for the similar question. There are Hive UDFs that can convert timestamp to long and date to string format."}
{"prompt": "403 Forbidden on running the ma command line tool", "completion": "At the moment, uploading to S3 via the ma tool  using zip or git training  requires that you run within the corp network.  Alternatively, you can obtain credentials using the aws command line tool and authenticating manually."}
{"prompt": "How to determine the timeout value for the realtime prediction service call? We are calling Michelangelo realtime prediction service. We are using batchPredict. Any suggestion on how to determine the client timeout.", "completion": "The engdoc has some onboarding information. Here has more information on oncall.To determine the timeout or load, our suggestion is to run hailstorm or yab load test to measure the latency and whether we need to increase serving capacity. For example, you can run yab load tests against a specific instance for 10-min. Use P99 or P99.95 latency as a guide.If you are using single prediction endpoint for hailstorm or yab and wantto determine how to set it for batchPredict, the heuristic is to multiplethe single prediction latency by the batch size.  Note that there is some optimization done in the prediction service.  We encourage you to run haistorm or yab test regularly since the latency numbers are influenced by capacity, load, model complexity, and traffic mix.One thing to note about batchPredict and multiModelPredict is that we'll set the response to NOT OK if one of the requests failed."}
{"prompt": "How can I use an online project to make offline batch  one-off  predictions? Reading thru this doc currently: https:  engdocs.uberinternal.com michelangelo user-guides one-off-predictions.html", "completion": "For one-off prediction, the model is not required to be deployed.For a project, it can only be a realtime or batch, but not both."}
{"prompt": "How to resolve model-not-found error in realtime prediction call? We are getting email alert about getting high number of model-not-found errors. How do we debug this?", "completion": "See a related question.Look at model view or model deployment view to see if the model in question is deployed. The typical issues are:incorrect project-id is specified. please note project-id in the request is case-sensitive. It must match your project-id.using model training id instead of model-idthere is no model deployed for the associated deployment-tag label. See a related question on how to check the model configuration file for the realtime prediction service.incorrect sk value is used. If you are routing traffic thru michelangelo-gateway, you must provide shard-key  sk  in the request header. Usually sk values is michelangelo-prediction-group:. For realtime prediction service that doesn't have virtual-shard,  is default to  production.  Check deployment section of the project view to see group-id."}
{"prompt": "Add dependency check for Michelangelo feature-gen jobs? How can I add a sensor dependency check for Michelangelo feature-gen jobs? Such check for upstream data would be important to ensure the features high quality.Similar parameter in hive etl job would be 'job_deps' or 'hive_deps'.", "completion": "See a related question.Look at model view or model deployment view to see if the model in question is deployed. The typical issues are:incorrect project-id is specified. please note project-id in the request is case-sensitive. It must match your project-id.using model training id instead of model-idthere is no model deployed for the associated deployment-tag label. See a related question on how to check the model configuration file for the realtime prediction service.incorrect sk value is used. If you are routing traffic thru michelangelo-gateway, you must provide shard-key  sk  in the request header. Usually sk values is michelangelo-prediction-group:. For realtime prediction service that doesn't have virtual-shard,  is default to  production.  Check deployment section of the project view to see group-id."}
{"prompt": "Any education information on using Michelangelo? I work on the Driver Pricing team in Marketplace and we are exploring building out an ML model to support our Destination Pricing feature, doc here. Does Michelangelo have any training available so we can familiarize ourselves with the platform?", "completion": "See a related question.Look at model view or model deployment view to see if the model in question is deployed. The typical issues are:incorrect project-id is specified. please note project-id in the request is case-sensitive. It must match your project-id.using model training id instead of model-idthere is no model deployed for the associated deployment-tag label. See a related question on how to check the model configuration file for the realtime prediction service.incorrect sk value is used. If you are routing traffic thru michelangelo-gateway, you must provide shard-key  sk  in the request header. Usually sk values is michelangelo-prediction-group:. For realtime prediction service that doesn't have virtual-shard,  is default to  production.  Check deployment section of the project view to see group-id."}
{"prompt": "Can I drop training rows with nulls? The table of training data and features that I'm feeding into my Michelangelo model has 2 rows with null values, which cause my model to fail. Is there a way to tell Michelangelo to just ignore rows with any null na data in them? Barring that, can I specify the datestr of my training data to be non-continuous  that is, leave out that specific day of data ?", "completion": "yes you can filter your training data. In the model template page, there is a FILTERING TRAINING DATA, toggle that you will be able to type your filter. The syntax is SQL. See here for an example: https:  michelangelo.uberinternal.com MA_Kaggle_NYC_Taxi_Fare_09_13 templates tm20180919-190509-BPYGSMAJFor your second question, yes you can leave out any specific day."}
{"prompt": "'Cannot resolve @prediction:true' error from model", "completion": "If you do describe on your table tmp.lorian_cb_model_post_training_datestr, you see label field is an int.If you describe the tmp.lorian_copy_cb_auto_fitting for the model that trained successfully, you see per_trip_fraud_label is a string field containing 'false' or 'true' value."}
{"prompt": "Can I export Michelangelo palette features? Can a set of palette features that are being used in a model be exported into a table or csv? I'd like to rebuild a model in Workbench for testing purposes but it uses a very large number of palette features, and finding the source table for all of them would be really time-consuming.", "completion": "The underlying Palette features are stored in the corresponding Hive table. For example, @palette:driver:trips:... is in michelangelo.driver_trips. You can find the actual DB and table in :data michelangelo-featurestore-datagen dictionary folder."}
{"prompt": "Any requirement on the training data? Are there any requirements such as data type  on hive data source for sparkML training?What thing we need to be aware of for importing CSV data into a Hive table?", "completion": "The underlying Palette features are stored in the corresponding Hive table. For example, @palette:driver:trips:... is in michelangelo.driver_trips. You can find the actual DB and table in :data michelangelo-featurestore-datagen dictionary folder."}
{"prompt": "How to detect model performance drifting? Is there a way to auto trigger training?", "completion": "The underlying Palette features are stored in the corresponding Hive table. For example, @palette:driver:trips:... is in michelangelo.driver_trips. You can find the actual DB and table in :data michelangelo-featurestore-datagen dictionary folder."}
{"prompt": "Michelanglo Piper pipeline failed since yesterday", "completion": "Piper team rolled back a change.The issue is tracked https:  code.uberinternal.com T2406023"}
{"prompt": "Table in Cassandra for My Feature", "completion": "For batch offline prediction, the features are fetched from the corresponding Hive table. From the corresponding description.json, we know rider's retention_v2 is backed by Hive table gi_models.rider_retention_v2. There could be couple of reasons. 1  The corresponding datestr partition doesn't exist. 2  Incorrect join-key is used. To figure out the issue, you can run a Hive query via querybuild. Do something likeselect * from gi_models.rider_retention_v2where datestr = 'YYYY-mm-dd'and uuid in  .... where you specify the joinkey values that you find in the basis table.If you are talking about online prediction, project setting shows the project is assigned to michelangelo-prediction-group30.Group30 is connected to cassandra-cstar-michelangelo-palette-multi-cluster and we have tasks dispersing features to it. However, piper pipeline shows we've failed for last 6 days. The reason is typically the underlying partition is empty. You may want to ping the feature-group owner to check ETL."}
{"prompt": "Failed: http calls in Piper to get currently deployed models I am trying to run the following commands to get currently deployed models under my Michelangelo project.1.Set up connection parameters# get http actionsget_http_actions = HttpActions     authorization_context=authorization_context,    http_conn_id= marketing_ds_http_michelangelo ,    method= GET  # get headersheaders =       X-Auth-Params-Email :   ,     X-Uber-Source :  michelangelo_piper  # get endpoitdeploy_endpoint =   api v1 projects  project_id  models deploy 2.Defined a get_response function  source code from RestAPI     def get_response self, url :       Make Http call and get response.       response = None    try:        response = get_http_actions.run url, headers=headers     except Exception as e:        # it can happen that the model_id is not existing in Michelangelo        # don't do anything about it        logging.info  Exception:  e , url:  u  .format e=e, u=url      if response and response.content:        return ujson.loads response.content     return None3.Lastly, run the get response function and try to get the deployed modelsdeployed_models = self.get_response url But getting the following errors:Sending 'GET' to url: http:  localhost:14785 api v1 projects R2E_Propensity models deployHTTP error: Not FoundException: 404:Not Found, url: api v1 projects R2E_Propensity models deploy", "completion": "We have deprecated the JSON + HTTP endpoint from our API, and replaced them as THRIFT + HTTP endpoint.The thrift version of this endpoint is this onehttps:  engdocs.uberinternal.com michelangelo-rest thrift michelangelo_api.html#Fn_MichelangeloAPI_getGroupedDeploymentStatusesHere is the function wrapper of that endpoint in piper-core-pipelines repo.https:  code.uberinternal.com diffusion DAPIPE browse master michelangelo_platform lib rest_api.py$300We don't recommend people directly calling the thrift + http endpoint in piper, instead you should initialize the MichelangeloApi instance and invoke functions from that instance. In that case, if we make any changes to the endpoint, we would directly update that function, and it could be transparent to our users.You could do some code search in that repo, to find examples on how to initialize that MichelangeloApi"}
{"prompt": "What does 'NullPointerException' mean in feature_gen jobs in Michelangelo feature store?", "completion": "We have deprecated the JSON + HTTP endpoint from our API, and replaced them as THRIFT + HTTP endpoint.The thrift version of this endpoint is this onehttps:  engdocs.uberinternal.com michelangelo-rest thrift michelangelo_api.html#Fn_MichelangeloAPI_getGroupedDeploymentStatusesHere is the function wrapper of that endpoint in piper-core-pipelines repo.https:  code.uberinternal.com diffusion DAPIPE browse master michelangelo_platform lib rest_api.py$300We don't recommend people directly calling the thrift + http endpoint in piper, instead you should initialize the MichelangeloApi instance and invoke functions from that instance. In that case, if we make any changes to the endpoint, we would directly update that function, and it could be transparent to our users.You could do some code search in that repo, to find examples on how to initialize that MichelangeloApi"}
{"prompt": "How to check AthenaX jobs are generating data? How do I verify my near-realtime featurestore AthenaX jobs are generating data?", "completion": "Make sure to source kafka is generating data. Use k8read to check.Consult with Athena AthenaX team on making sure your AthenaX is configured correctly and determine if the input should be from local kafka aggregator for your use case.Make sure AthenaX is running without problem.For Cassandra, make sure the uns path is correct for8 the dc.Use k8read to check kafka output and use CQL to check Cassandra.discover clusters for the topic:$ k8read -d hp-michelangelo-store_orders_5minTopic found in cluster:  kloak-sjc1aTopic found in cluster:  kloak-sjc1-agg1Topic found in cluster:  kloak-sjc1-staging1Topic found in cluster:  kloak-phx2aTopic found in cluster:  kloak-phx2-agg1Topic found in cluster:  kloak-phx2-staging1Topic found in cluster:  kloak-dca1aTopic found in cluster:  kloak-dca1-agg1read from the cluster that you try to debug:$ k8read -c kloak-phx2a -t hp-michelangelo-store_orders_5min -ts1 10m > logrestrict to phx2 athenax hosts since we are debugging phx2:$ grep phx2 log > log.phx2use CQL to check data. Note that there are kafka message uuid and featurestore uuid. Find a record and run CQL query.  ts :1550633700.002, host : athena158-phx2 , level :null, dc :null, msg_offset :2130414, uuid : 31b7d195-3d0f-411b-b6b5-1cce287c31f6 , schema_id :4, msg :  at_order_accepted__adjusted_prep_time_count_5min :0, ... ts_bucket :1550633700, uuid : 72a4a091-2e7f-4f28-937e-ef42b793af90  ...cqlsh:store> select uuid, ts_bucket from orders_realtime where uuid='72a4a091-2e7f-4f28-937e-ef42b793af90'; uuid                                 | ts_bucket--------------------------------------+------------ 72a4a091-2e7f-4f28-937e-ef42b793af90 | 1550634900 72a4a091-2e7f-4f28-937e-ef42b793af90 | 1550635200 72a4a091-2e7f-4f28-937e-ef42b793af90 | 1550635500....."}
{"prompt": "Is it possible to do Weighted Training using xgboost I am trying to implement an R model in Michelangelo and I need to add weighting to each sample for training. The model is a binary classifier using xgboost. Weighting is supported in xgboost but I don't find any reference to it in Michelangelo. Anybody knows how can I do that or if it is not available in Michelangelo, is there a work around for it?", "completion": "See notebook example for training a xgboost model and  register  to Michelangelo. xgboost supports weighting. From dev note, it seems other than DMatrix api, there is no easy way to set a column in the input table as a weight column."}
{"prompt": "How do we load test against sharded Michelangelo Online Prediction service Our team is going to roll out MA model globally  approx. 100 cities . As we're doing capacity planning, we want to understand more about how MA serving works, so that we could adjust our stress test strategy. Questions including 1  Does one virtual shard serve only one cityIf so how to balance load between large city and small city 2  What's the best approach to stress test? Shall we test both gateway and per shard?", "completion": "Please see model sharding RFC and engdoc.Here is the general approach on how to assign virtual shards, in your case city-ids, to udeploy group. A udeploy group is a physical shard in our design.We pulled the traffic for each city in the list. We asked Marketplace to providecorresponding DC.We ordered the city list from traffic volume.We assigned cities to a shard so that load is roughly the same. Thus, multiple citiesare assigned to a shard.Each shard is provisioned in all DCs. Thus the same model can be served in all DCs.When there is capacity issue, we scale the corresponding shard.To reduce mutely error during rolling SW install, for each shard we addedcorresponding backup shard. In other words, a city is assigned to twoshards. [Each shard is a deploy group.]There are many ways to determine capacity. The recommendation is torun actual traffic load against a diff DC during weekly failover test.The other way is to run yab load test against a specific host  w o going thru michelangelo-gateway . Increasing QPS till we see CPU utilization is around 100%.  Technically we can go up to 200% since we cango up to 400% during failover.  Then we multiply the QPS number bythe number of instances to get an estimation on the capacity. We usually increase yab RPS number by 100. The goal is to get an estimation, not exact number. "}
{"prompt": "How do we connect to Cassandra from local? I've a feature store table. Want to verify dispersal data is correct.", "completion": "Let's assume you want to connecting to a Cassandra cluster that doesn't require authentication.  Currently, authentication information is typically setup in [Langley][1]. We strongly advice against downloading any security token and information to local. StepsFind the host and port information. You get get this information from [Odin][2] or UNS.  0    schemadock3607-dca1    NativeTransport:10069 nativetransport:10069```- Setup tunnel to adhoc machine$ ssh -MfN -L 10069:schemadock3607-dca1:10069 adhoc20-dca1- Download apache-cassandra binary- Use bin cql$ bin cqlsh --cqlversion= 3.4.0  localhost 10069Connected to cassandra-cstar-michelangelo-palette-multi-cluster at localhost:10069.[cqlsh 5.0.1 | Cassandra 3.0.14.29 | CQL spec 3.4.0 | Native protocol v4]Use HELP for help.cqlsh> exit  [1]: https:  langley.uberinternal.com index.html#   [2]: https:  odin.uberinternal.com"}
{"prompt": "Is it possible to spread traffic from one datacenter to other datacenter for michelangelo-gateway frontcar? In traffic controller configuration, we route portion of dca1 traffic to phx2 prediction service instances in order to reduce load on Cassandra. Is there a similar approach for frontcar?Note that we only want to do it for traffic going to michelangelo-prediction-group5 and michelangelo-prediction-group11.", "completion": "yarpc frontcar peer-to-peer does not support this unfortunately. You would have to make changes in your application layer and partition traffic manually."}
{"prompt": "Cold start performance of Michelangelo online prediction", "completion": "yarpc frontcar peer-to-peer does not support this unfortunately. You would have to make changes in your application layer and partition traffic manually."}
{"prompt": "How do I reduce the online prediction result payload?", "completion": "You can pass in returnTransformedFeatures with True  boolean  value in the request. See single prediction request below:struct PredictionRequest       next id: 10  1: optional string projectId,     Model id can be either raw model id or model alias  2: optional string modelId,     note: only one of basisFeatures or binaryBasisFeatures should be used at a time  3: optional list<ValueItem> basisFeatures,  4: optional string label,  5: optional string joinKey,  6: optional bool returnTransformedFeatures,  7: optional bool testTraffic,     note: binary format features  currently, only supported by containerized models   8: optional binary binaryBasisFeatures,  9: optional EncodingType binaryBasisFeaturesEncodingType,     note: when true the request is always logged 10: optional bool sampleRequest, If you are running hailstorm or simulation, please also set testTraffic to True as well so that we won't log prediction result to Hive."}
{"prompt": "Best way to edit an alert in a moncon alert-group: MICHELANGELO FEATURE STORE PIPELINE Looking for a way to edit the pagerduty setting of an alert in this uMonitor alert-group: https:  umonitor.uberinternal.com alert-groups 6b9b6bc2-d690-4fe3-a852-87542c337771In particular, I want to update the pagerduty setting of this alert: https:  umonitor.uberinternal.com alerts 3ea20716-c423-421b-b043-eabc57a52397 editHow do I do this? Moncon documentation doesn't say much: https:  engdocs.uberinternal.com moncon getting-started getting-started-alerts.html#convert-existing-alert-group-from-umonitor", "completion": "In the repo,one can change integration key in moncon alerts.yaml."}
{"prompt": "Michelangelo spark job takes forever to run my team has a couple of michelangelo jobs that takes more than a day to run, and they took up all the resources on our yarn queue. we ended up killing these jobs. can someone help investigating this?app_ids:https:  attis.uberinternal.com spark application_1504125105308_2224534https:  attis.uberinternal.com spark application_1504125105308_2223165https:  attis.uberinternal.com spark application_1504125105308_2224531", "completion": "In the repo,one can change integration key in moncon alerts.yaml."}
{"prompt": "How can I serve a model with Michelangelo that is trained outside of the platform? Is there a way to upload a Java or Scala model that is trained outside of the Michelangelo platform and serve it the same way as a regular Michelangelo model? I know the PyML project will make this possible for Python models, and I was wondering if there is  or will be  a way to do the same for Java and or Scala?", "completion": "Update: Now I learned that it is possible to upload models trained outside of Michelangelo. See the notebooks by Guoqin Zheng below.for scala spark:https:  workbench.uberinternal.com explore knowledge localfile gzheng XGBoost%20Spark%20Example.ipynbfor pyspark:https:  workbench.uberinternal.com explore knowledge localfile gzheng XGBoost%20PySpark%20Example.ipynb"}
{"prompt": "Does Michelangelo use SigOpt for bayesian hyperparameter tuning? Does Michelangelo use SigOpt for its bayesian hyperparameter search functionality, or does Uber have its own? Does anyone have any recommendations for open source libraries or algorithms for bayesian search?", "completion": "MA's hyperparam search is based on the AI Lab's implementation of Bayesian Optimized search. Here is their repo: https:  code.uberinternal.com diffusion AIBAYQD "}
{"prompt": "Specify shard key for yab through Studio", "completion": "MA's hyperparam search is based on the AI Lab's implementation of Bayesian Optimized search. Here is their repo: https:  code.uberinternal.com diffusion AIBAYQD "}
{"prompt": "Dummy Michelangelo Model to get Data from Cassandra Through Feature Palette As a workaround for the lack of integration of pyML with Feature Palette, can I create a dummy Michelangelo model that simply returns the features from feature palette that I am interested? Does anyone have such a dummy model? I can then call that model API within my PyML prediction function to get the real time data for prediction purposes.", "completion": "MA's hyperparam search is based on the AI Lab's implementation of Bayesian Optimized search. Here is their repo: https:  code.uberinternal.com diffusion AIBAYQD "}
{"prompt": "How to cap floor numeric features? We've several numeric features for our models. Some feature values are noisy. Since currently Michelangelo doesn't support outlier data removal, is there a way to remove ensure the numeric values are fall within a range?", "completion": "One can add a customized transformer for removing  outlier  from the dataframe. However, it is not clear what is the corresponding semantic in the online setting. Do we just throw an exception? Default to null value?Because we compute column stats before applying DSL, one can leverage colStatStdDev and colStatMean. See DSL doc. For example something likesurge: if  nVal @basis:surge <colStatMean @basis:surge -3*colStatStdDev @basis:surge   colStatMean @basis:surge -3*colStatStdDev @basis:surge  else nVal @basis:surge We are also thinking about more flexible training workflow with data quality validation and model performance assertions. See here."}
{"prompt": "Is there an adhoc Hive database I can use with Michelangelo? Is there an adhoc Hive database for Michelangelo that I can write some sample CSV data to? My team's database is full right now and I am getting this error:Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 108 in stage 2.0 failed 4 times, most recent failure: Lost task 108.3 in stage 2.0  TID 2198, hadoopworker956-dca1.prod.uber.internal : org.apache.hadoop.hdfs.protocol.NSQuotaExceededException: The NameSpace quota  directories and files  of directory  user hive warehouse hollywood.db is exceeded: quota=10000 file count=10001I saw the solution here was to simply delete some files, but I can't really do that right now. I'm following the CSV data ingestion tutorial to get up and running with Michelangelo.Any help is greatly appreciated!", "completion": "One can add a customized transformer for removing  outlier  from the dataframe. However, it is not clear what is the corresponding semantic in the online setting. Do we just throw an exception? Default to null value?Because we compute column stats before applying DSL, one can leverage colStatStdDev and colStatMean. See DSL doc. For example something likesurge: if  nVal @basis:surge <colStatMean @basis:surge -3*colStatStdDev @basis:surge   colStatMean @basis:surge -3*colStatStdDev @basis:surge  else nVal @basis:surge We are also thinking about more flexible training workflow with data quality validation and model performance assertions. See here."}
{"prompt": "How to use numeric values for categorical features?", "completion": "Here are some related postings:Support large categorical featuresCategorical features in MichelangeloUnseen valueFirst, please ensure data associated with those fields are stored as short, int, long, or bigint  Hive  data type, not double nor float. Otherwise, it is possible value 18  int  be converted to 18.0  double  and become  18.0  when sVal DSL is applied. This rule also applied to partition keys.Second, please don't use the same feature for numeric and categorical features in your model.Third, please pass those features as string value when calling online prediction service. Both  doubleValue : 18,  key :  @palette:trip:request_v2:country_id:trip_uuid  and  doubleValue : 18.0,  key :  @palette:trip:request_v2:country_id:trip_uuid  will be viewed as 18.0  double  and converted to  18.0  during batchStringIndexing step. This is not the behavior that you want for categorical feature. The solution is to pass value with stringValue.  stringValue :  38 ,  key :  @palette:trip:request_v2:country_id:trip_uuid  "}
{"prompt": "How can I import a large CSV into Hive? Want to upload a large  > 100 Mb  CSV into Hive for Michelangelo training.", "completion": "As of April 15, 2019, Kirby supports customized partition.Yes, I think that we can handle both use cases. We have a meta field named  kirby_datetime_utc . 1. If your dataset does not contain this field, we automatically add this field to your table with data being the start time of the job.2. If your dataset contains a timestamp field, you can rename it to  kirby_datetime_utc , then we will not add an extra field, but use the data from the dataset for this field.Note that currently, we do not partition the table. However, you can still use the  kirby_datetime_utc  field in your queries. Partition would only affect the performance of your queries,  i.e., full scans vs scans of some partitions . It makes sense to partition the table, when the table is big. We plan to support static partitioning on date using  kirby_datetime_utc . Partition on custom columns could be difficult.Best,SihanOn Mon, Apr 15, 2019 at 11:05 AM Jon Cao <> wrote:Thanks for the feedbacks, Joseph. I believe that both of the your use cases can be covered by current design. Sihan will elaborate more on them. On Sat, Apr 13, 2019 at 3:43 PM Joseph Wang <> wrote:There are two typical cases.1  data without datestr field. however, when training we need to have detestr field.2  date with detestr field. when user upload csv we put data into corresponding detestr partitions.There is also a use case of multiple partitions. However, the usage is extremely low.One example is to partition by workflow ad-campaign and then corresponding detester.On Fri, Apr 12, 2019 at 2:19 PM Sihan Li <> wrote:Hi Joseph,Currently, our table is not partitioned, but we do plan to make our table partitioned. As mentioned by Jianyong, it would help us better understand your needs if you can clarify a bit on your use case. Thanks!Best,SihanOn Fri, Apr 12, 2019 at 11:00 AM Jianyong Zhang <> wrote:+Sihan Li On Fri, Apr 12, 2019 at 10:59 AM Jianyong Zhang <> wrote:Sorry a correction. We add a timestamp column to help query data, but we are not using it as partition key.If there is a strong demand to support custom partition, for example user's csv file already contains datestr, or city_id and want to use it as partition key, we can consider adding it in our next release.It'd be great if Joseph if you can write down what your team need in a bit more detail."}
{"prompt": "How to get real-time prediction results from Michelangelo after an online model is deployed", "completion": "Engdoc for realtime prediction service can be found here. Model monitoring can be found here. See here for model deployment tag lab. The thrift definition of the prediction request can be found in here. For simplicity, let's focus on single prediction request.struct PredictionRequest    1: optional string projectId,   <-- project-id associated with the model. note that case sensitive.  2: optional string modelId,     <-- full model-id  3: optional list<ValueItem> basisFeatures, <-- list of features used in your model  4: optional string label,       <-- deployment label, note that you cannot use label and modelId at the same time  5: optional string joinKey,     <-- join key uuid that associated with the request that can be used to identified the request and join back to other table   6: optional bool returnTransformedFeatures, <-- whether to return transformed feature values in the response. Suggest set to False to reduce response payload.  7: optional bool testTraffic,  <-- set this to True if this is not production traffic. For example, coming from simulation, hailstorm, or blackbox.  8: optional binary binaryBasisFeatures, <-- apache arrow encoded request. note that this only works for python ML  9: optional EncodingType binaryBasisFeaturesEncodingType,     note: when true the request is always logged  10: optional bool sampleRequest, <-- set to True if you always want to log this prediction response to Kafka and then to Hive. Note that logging has some performance penality Let's take this model as example. The deployment section for the project has enabled realtime prediction and hasgroup-1in online container. Thus the corresponding service will be michelangelo-prediction-group1. The corresponding yab command will be something likeyab michelangelo-prediction-group1 PredictionService::predict --rps 100 --max-duration 300s --peer 127.0.0.1:6424 --thrift predictionservice.thrift --body '  request :   projectId :  vs_marketplace_econ_mvp ,  basisFeatures : [  stringValue :  0036508d-8655-4e6b-bb1c-47b8eecd76a7 ,  key :  @basis:basis_driver_uuid  ,   stringValue :  2017-10-23 ,  key :  @basis:basis_datestr  ,   stringValue :  0036508d-8655-4e6b-bb1c-47b8eecd76a7 ,  key :  @basis:driver_uuid  ,   doubleValue : 0.0,  key :  @basis:earning_before_cash_and_vehicle_l7d  ,   stringValue :  2017-10-23 ,  key :  @basis:dtPartition  ],  modelId :  2017-11-08-19-28-36-185-UTC   'The corresponding response will have something like    body :       result :         prediction :           doubleValue : 8.92900471968395,         key :  predict        ,       publishResult : [                    doubleValue : 8.92900471968395,           key :  earnings_prediction          ,                    key :  driver_uuid ,           stringValue :  0036508d-8655-4e6b-bb1c-47b8eecd76a7                ],       result : [                    doubleValue : 8.92900471968395,           key :  predict                ],       transformedFeatures : [                    doubleValue : 0,           key :  avg_fare_1week          ,        ....Note that in prediction we have predict with double value. This is because this model is a regression model. If it is a classification model, the prediction predict value will be the class; the associated prob can be found in the result section. For example, this is a MarketPlace dispatch model prediction result.      prediction :           key :  predict ,         stringValue :  true        ,       publishResult : [                    key :  vehicle_view_id ,           stringValue :  14415          ,                    key :  predict ,           stringValue :  true                ],       result : [                    doubleValue : 0.6062631312615228,           key :  true          ,                    key :  predict ,           stringValue :  true          ,                    doubleValue : 0.39373686873847724,           key :  false                ],Note that in their model, the classes are  true  and  false.  Note that you can get the corresponding class' prob in the result section.publishResult contains the results that you added to published fields of the model. transformedFeatures is the post-DSL feature values used in your model.One can also go thru michelangelo-gateway. For michelangelo-gateway, you need to provide shard-key  sk , which usually is :production. For the above example, sk will be  michelangelo-prediction-group1:production. If the prediction service group has model sharding, it will ask you to provide at least one virtual sharding key during the model deployment request. In such case, sk will be :. For example,  michelangelo-porediction-group38:city_id_1. "}
{"prompt": "Michelangelo prediction runs on SJC but not on DCA.  ERROR: java.io.FileNotFoundException: File does not exist ", "completion": "Engdoc for realtime prediction service can be found here. Model monitoring can be found here. See here for model deployment tag lab. The thrift definition of the prediction request can be found in here. For simplicity, let's focus on single prediction request.struct PredictionRequest    1: optional string projectId,   <-- project-id associated with the model. note that case sensitive.  2: optional string modelId,     <-- full model-id  3: optional list<ValueItem> basisFeatures, <-- list of features used in your model  4: optional string label,       <-- deployment label, note that you cannot use label and modelId at the same time  5: optional string joinKey,     <-- join key uuid that associated with the request that can be used to identified the request and join back to other table   6: optional bool returnTransformedFeatures, <-- whether to return transformed feature values in the response. Suggest set to False to reduce response payload.  7: optional bool testTraffic,  <-- set this to True if this is not production traffic. For example, coming from simulation, hailstorm, or blackbox.  8: optional binary binaryBasisFeatures, <-- apache arrow encoded request. note that this only works for python ML  9: optional EncodingType binaryBasisFeaturesEncodingType,     note: when true the request is always logged  10: optional bool sampleRequest, <-- set to True if you always want to log this prediction response to Kafka and then to Hive. Note that logging has some performance penality Let's take this model as example. The deployment section for the project has enabled realtime prediction and hasgroup-1in online container. Thus the corresponding service will be michelangelo-prediction-group1. The corresponding yab command will be something likeyab michelangelo-prediction-group1 PredictionService::predict --rps 100 --max-duration 300s --peer 127.0.0.1:6424 --thrift predictionservice.thrift --body '  request :   projectId :  vs_marketplace_econ_mvp ,  basisFeatures : [  stringValue :  0036508d-8655-4e6b-bb1c-47b8eecd76a7 ,  key :  @basis:basis_driver_uuid  ,   stringValue :  2017-10-23 ,  key :  @basis:basis_datestr  ,   stringValue :  0036508d-8655-4e6b-bb1c-47b8eecd76a7 ,  key :  @basis:driver_uuid  ,   doubleValue : 0.0,  key :  @basis:earning_before_cash_and_vehicle_l7d  ,   stringValue :  2017-10-23 ,  key :  @basis:dtPartition  ],  modelId :  2017-11-08-19-28-36-185-UTC   'The corresponding response will have something like    body :       result :         prediction :           doubleValue : 8.92900471968395,         key :  predict        ,       publishResult : [                    doubleValue : 8.92900471968395,           key :  earnings_prediction          ,                    key :  driver_uuid ,           stringValue :  0036508d-8655-4e6b-bb1c-47b8eecd76a7                ],       result : [                    doubleValue : 8.92900471968395,           key :  predict                ],       transformedFeatures : [                    doubleValue : 0,           key :  avg_fare_1week          ,        ....Note that in prediction we have predict with double value. This is because this model is a regression model. If it is a classification model, the prediction predict value will be the class; the associated prob can be found in the result section. For example, this is a MarketPlace dispatch model prediction result.      prediction :           key :  predict ,         stringValue :  true        ,       publishResult : [                    key :  vehicle_view_id ,           stringValue :  14415          ,                    key :  predict ,           stringValue :  true                ],       result : [                    doubleValue : 0.6062631312615228,           key :  true          ,                    key :  predict ,           stringValue :  true          ,                    doubleValue : 0.39373686873847724,           key :  false                ],Note that in their model, the classes are  true  and  false.  Note that you can get the corresponding class' prob in the result section.publishResult contains the results that you added to published fields of the model. transformedFeatures is the post-DSL feature values used in your model.One can also go thru michelangelo-gateway. For michelangelo-gateway, you need to provide shard-key  sk , which usually is :production. For the above example, sk will be  michelangelo-prediction-group1:production. If the prediction service group has model sharding, it will ask you to provide at least one virtual sharding key during the model deployment request. In such case, sk will be :. For example,  michelangelo-porediction-group38:city_id_1. "}
{"prompt": "Populating Basis Features:  error: type mismatch  I'm attempting to build a simple test model for my data in SJC1  non-secure I initially got an error when I attempted to train:Column @basis:thsa_000a is absent in feature listI interpreted this as a null for a feature value and added nFill to try and patch over it. I then got the error below - which makes no sense since I'm nFill-ing with a Double value and there's no reason for a string to pop up?Compilation Errorerror: type mismatch; found   : String required: Double             thsa_019bc  ->  nFill sVal  @basis:thsa_019bc  , 0.0  ,", "completion": "Engdoc for realtime prediction service can be found here. Model monitoring can be found here. See here for model deployment tag lab. The thrift definition of the prediction request can be found in here. For simplicity, let's focus on single prediction request.struct PredictionRequest    1: optional string projectId,   <-- project-id associated with the model. note that case sensitive.  2: optional string modelId,     <-- full model-id  3: optional list<ValueItem> basisFeatures, <-- list of features used in your model  4: optional string label,       <-- deployment label, note that you cannot use label and modelId at the same time  5: optional string joinKey,     <-- join key uuid that associated with the request that can be used to identified the request and join back to other table   6: optional bool returnTransformedFeatures, <-- whether to return transformed feature values in the response. Suggest set to False to reduce response payload.  7: optional bool testTraffic,  <-- set this to True if this is not production traffic. For example, coming from simulation, hailstorm, or blackbox.  8: optional binary binaryBasisFeatures, <-- apache arrow encoded request. note that this only works for python ML  9: optional EncodingType binaryBasisFeaturesEncodingType,     note: when true the request is always logged  10: optional bool sampleRequest, <-- set to True if you always want to log this prediction response to Kafka and then to Hive. Note that logging has some performance penality Let's take this model as example. The deployment section for the project has enabled realtime prediction and hasgroup-1in online container. Thus the corresponding service will be michelangelo-prediction-group1. The corresponding yab command will be something likeyab michelangelo-prediction-group1 PredictionService::predict --rps 100 --max-duration 300s --peer 127.0.0.1:6424 --thrift predictionservice.thrift --body '  request :   projectId :  vs_marketplace_econ_mvp ,  basisFeatures : [  stringValue :  0036508d-8655-4e6b-bb1c-47b8eecd76a7 ,  key :  @basis:basis_driver_uuid  ,   stringValue :  2017-10-23 ,  key :  @basis:basis_datestr  ,   stringValue :  0036508d-8655-4e6b-bb1c-47b8eecd76a7 ,  key :  @basis:driver_uuid  ,   doubleValue : 0.0,  key :  @basis:earning_before_cash_and_vehicle_l7d  ,   stringValue :  2017-10-23 ,  key :  @basis:dtPartition  ],  modelId :  2017-11-08-19-28-36-185-UTC   'The corresponding response will have something like    body :       result :         prediction :           doubleValue : 8.92900471968395,         key :  predict        ,       publishResult : [                    doubleValue : 8.92900471968395,           key :  earnings_prediction          ,                    key :  driver_uuid ,           stringValue :  0036508d-8655-4e6b-bb1c-47b8eecd76a7                ],       result : [                    doubleValue : 8.92900471968395,           key :  predict                ],       transformedFeatures : [                    doubleValue : 0,           key :  avg_fare_1week          ,        ....Note that in prediction we have predict with double value. This is because this model is a regression model. If it is a classification model, the prediction predict value will be the class; the associated prob can be found in the result section. For example, this is a MarketPlace dispatch model prediction result.      prediction :           key :  predict ,         stringValue :  true        ,       publishResult : [                    key :  vehicle_view_id ,           stringValue :  14415          ,                    key :  predict ,           stringValue :  true                ],       result : [                    doubleValue : 0.6062631312615228,           key :  true          ,                    key :  predict ,           stringValue :  true          ,                    doubleValue : 0.39373686873847724,           key :  false                ],Note that in their model, the classes are  true  and  false.  Note that you can get the corresponding class' prob in the result section.publishResult contains the results that you added to published fields of the model. transformedFeatures is the post-DSL feature values used in your model.One can also go thru michelangelo-gateway. For michelangelo-gateway, you need to provide shard-key  sk , which usually is :production. For the above example, sk will be  michelangelo-prediction-group1:production. If the prediction service group has model sharding, it will ask you to provide at least one virtual sharding key during the model deployment request. In such case, sk will be :. For example,  michelangelo-porediction-group38:city_id_1. "}
{"prompt": "Michelangelo Training Error: Cannot resolve [XX column name] given input columns  Resolved ", "completion": "Engdoc for realtime prediction service can be found here. Model monitoring can be found here. See here for model deployment tag lab. The thrift definition of the prediction request can be found in here. For simplicity, let's focus on single prediction request.struct PredictionRequest    1: optional string projectId,   <-- project-id associated with the model. note that case sensitive.  2: optional string modelId,     <-- full model-id  3: optional list<ValueItem> basisFeatures, <-- list of features used in your model  4: optional string label,       <-- deployment label, note that you cannot use label and modelId at the same time  5: optional string joinKey,     <-- join key uuid that associated with the request that can be used to identified the request and join back to other table   6: optional bool returnTransformedFeatures, <-- whether to return transformed feature values in the response. Suggest set to False to reduce response payload.  7: optional bool testTraffic,  <-- set this to True if this is not production traffic. For example, coming from simulation, hailstorm, or blackbox.  8: optional binary binaryBasisFeatures, <-- apache arrow encoded request. note that this only works for python ML  9: optional EncodingType binaryBasisFeaturesEncodingType,     note: when true the request is always logged  10: optional bool sampleRequest, <-- set to True if you always want to log this prediction response to Kafka and then to Hive. Note that logging has some performance penality Let's take this model as example. The deployment section for the project has enabled realtime prediction and hasgroup-1in online container. Thus the corresponding service will be michelangelo-prediction-group1. The corresponding yab command will be something likeyab michelangelo-prediction-group1 PredictionService::predict --rps 100 --max-duration 300s --peer 127.0.0.1:6424 --thrift predictionservice.thrift --body '  request :   projectId :  vs_marketplace_econ_mvp ,  basisFeatures : [  stringValue :  0036508d-8655-4e6b-bb1c-47b8eecd76a7 ,  key :  @basis:basis_driver_uuid  ,   stringValue :  2017-10-23 ,  key :  @basis:basis_datestr  ,   stringValue :  0036508d-8655-4e6b-bb1c-47b8eecd76a7 ,  key :  @basis:driver_uuid  ,   doubleValue : 0.0,  key :  @basis:earning_before_cash_and_vehicle_l7d  ,   stringValue :  2017-10-23 ,  key :  @basis:dtPartition  ],  modelId :  2017-11-08-19-28-36-185-UTC   'The corresponding response will have something like    body :       result :         prediction :           doubleValue : 8.92900471968395,         key :  predict        ,       publishResult : [                    doubleValue : 8.92900471968395,           key :  earnings_prediction          ,                    key :  driver_uuid ,           stringValue :  0036508d-8655-4e6b-bb1c-47b8eecd76a7                ],       result : [                    doubleValue : 8.92900471968395,           key :  predict                ],       transformedFeatures : [                    doubleValue : 0,           key :  avg_fare_1week          ,        ....Note that in prediction we have predict with double value. This is because this model is a regression model. If it is a classification model, the prediction predict value will be the class; the associated prob can be found in the result section. For example, this is a MarketPlace dispatch model prediction result.      prediction :           key :  predict ,         stringValue :  true        ,       publishResult : [                    key :  vehicle_view_id ,           stringValue :  14415          ,                    key :  predict ,           stringValue :  true                ],       result : [                    doubleValue : 0.6062631312615228,           key :  true          ,                    key :  predict ,           stringValue :  true          ,                    doubleValue : 0.39373686873847724,           key :  false                ],Note that in their model, the classes are  true  and  false.  Note that you can get the corresponding class' prob in the result section.publishResult contains the results that you added to published fields of the model. transformedFeatures is the post-DSL feature values used in your model.One can also go thru michelangelo-gateway. For michelangelo-gateway, you need to provide shard-key  sk , which usually is :production. For the above example, sk will be  michelangelo-prediction-group1:production. If the prediction service group has model sharding, it will ask you to provide at least one virtual sharding key during the model deployment request. In such case, sk will be :. For example,  michelangelo-porediction-group38:city_id_1. "}
{"prompt": "Can't Migrate SQL Pipeline Model due to access issues - please assist!", "completion": "Engdoc for realtime prediction service can be found here. Model monitoring can be found here. See here for model deployment tag lab. The thrift definition of the prediction request can be found in here. For simplicity, let's focus on single prediction request.struct PredictionRequest    1: optional string projectId,   <-- project-id associated with the model. note that case sensitive.  2: optional string modelId,     <-- full model-id  3: optional list<ValueItem> basisFeatures, <-- list of features used in your model  4: optional string label,       <-- deployment label, note that you cannot use label and modelId at the same time  5: optional string joinKey,     <-- join key uuid that associated with the request that can be used to identified the request and join back to other table   6: optional bool returnTransformedFeatures, <-- whether to return transformed feature values in the response. Suggest set to False to reduce response payload.  7: optional bool testTraffic,  <-- set this to True if this is not production traffic. For example, coming from simulation, hailstorm, or blackbox.  8: optional binary binaryBasisFeatures, <-- apache arrow encoded request. note that this only works for python ML  9: optional EncodingType binaryBasisFeaturesEncodingType,     note: when true the request is always logged  10: optional bool sampleRequest, <-- set to True if you always want to log this prediction response to Kafka and then to Hive. Note that logging has some performance penality Let's take this model as example. The deployment section for the project has enabled realtime prediction and hasgroup-1in online container. Thus the corresponding service will be michelangelo-prediction-group1. The corresponding yab command will be something likeyab michelangelo-prediction-group1 PredictionService::predict --rps 100 --max-duration 300s --peer 127.0.0.1:6424 --thrift predictionservice.thrift --body '  request :   projectId :  vs_marketplace_econ_mvp ,  basisFeatures : [  stringValue :  0036508d-8655-4e6b-bb1c-47b8eecd76a7 ,  key :  @basis:basis_driver_uuid  ,   stringValue :  2017-10-23 ,  key :  @basis:basis_datestr  ,   stringValue :  0036508d-8655-4e6b-bb1c-47b8eecd76a7 ,  key :  @basis:driver_uuid  ,   doubleValue : 0.0,  key :  @basis:earning_before_cash_and_vehicle_l7d  ,   stringValue :  2017-10-23 ,  key :  @basis:dtPartition  ],  modelId :  2017-11-08-19-28-36-185-UTC   'The corresponding response will have something like    body :       result :         prediction :           doubleValue : 8.92900471968395,         key :  predict        ,       publishResult : [                    doubleValue : 8.92900471968395,           key :  earnings_prediction          ,                    key :  driver_uuid ,           stringValue :  0036508d-8655-4e6b-bb1c-47b8eecd76a7                ],       result : [                    doubleValue : 8.92900471968395,           key :  predict                ],       transformedFeatures : [                    doubleValue : 0,           key :  avg_fare_1week          ,        ....Note that in prediction we have predict with double value. This is because this model is a regression model. If it is a classification model, the prediction predict value will be the class; the associated prob can be found in the result section. For example, this is a MarketPlace dispatch model prediction result.      prediction :           key :  predict ,         stringValue :  true        ,       publishResult : [                    key :  vehicle_view_id ,           stringValue :  14415          ,                    key :  predict ,           stringValue :  true                ],       result : [                    doubleValue : 0.6062631312615228,           key :  true          ,                    key :  predict ,           stringValue :  true          ,                    doubleValue : 0.39373686873847724,           key :  false                ],Note that in their model, the classes are  true  and  false.  Note that you can get the corresponding class' prob in the result section.publishResult contains the results that you added to published fields of the model. transformedFeatures is the post-DSL feature values used in your model.One can also go thru michelangelo-gateway. For michelangelo-gateway, you need to provide shard-key  sk , which usually is :production. For the above example, sk will be  michelangelo-prediction-group1:production. If the prediction service group has model sharding, it will ask you to provide at least one virtual sharding key during the model deployment request. In such case, sk will be :. For example,  michelangelo-porediction-group38:city_id_1. "}
{"prompt": "Michelangelo: The model not able to pick up feature in Hive table", "completion": "Engdoc for realtime prediction service can be found here. Model monitoring can be found here. See here for model deployment tag lab. The thrift definition of the prediction request can be found in here. For simplicity, let's focus on single prediction request.struct PredictionRequest    1: optional string projectId,   <-- project-id associated with the model. note that case sensitive.  2: optional string modelId,     <-- full model-id  3: optional list<ValueItem> basisFeatures, <-- list of features used in your model  4: optional string label,       <-- deployment label, note that you cannot use label and modelId at the same time  5: optional string joinKey,     <-- join key uuid that associated with the request that can be used to identified the request and join back to other table   6: optional bool returnTransformedFeatures, <-- whether to return transformed feature values in the response. Suggest set to False to reduce response payload.  7: optional bool testTraffic,  <-- set this to True if this is not production traffic. For example, coming from simulation, hailstorm, or blackbox.  8: optional binary binaryBasisFeatures, <-- apache arrow encoded request. note that this only works for python ML  9: optional EncodingType binaryBasisFeaturesEncodingType,     note: when true the request is always logged  10: optional bool sampleRequest, <-- set to True if you always want to log this prediction response to Kafka and then to Hive. Note that logging has some performance penality Let's take this model as example. The deployment section for the project has enabled realtime prediction and hasgroup-1in online container. Thus the corresponding service will be michelangelo-prediction-group1. The corresponding yab command will be something likeyab michelangelo-prediction-group1 PredictionService::predict --rps 100 --max-duration 300s --peer 127.0.0.1:6424 --thrift predictionservice.thrift --body '  request :   projectId :  vs_marketplace_econ_mvp ,  basisFeatures : [  stringValue :  0036508d-8655-4e6b-bb1c-47b8eecd76a7 ,  key :  @basis:basis_driver_uuid  ,   stringValue :  2017-10-23 ,  key :  @basis:basis_datestr  ,   stringValue :  0036508d-8655-4e6b-bb1c-47b8eecd76a7 ,  key :  @basis:driver_uuid  ,   doubleValue : 0.0,  key :  @basis:earning_before_cash_and_vehicle_l7d  ,   stringValue :  2017-10-23 ,  key :  @basis:dtPartition  ],  modelId :  2017-11-08-19-28-36-185-UTC   'The corresponding response will have something like    body :       result :         prediction :           doubleValue : 8.92900471968395,         key :  predict        ,       publishResult : [                    doubleValue : 8.92900471968395,           key :  earnings_prediction          ,                    key :  driver_uuid ,           stringValue :  0036508d-8655-4e6b-bb1c-47b8eecd76a7                ],       result : [                    doubleValue : 8.92900471968395,           key :  predict                ],       transformedFeatures : [                    doubleValue : 0,           key :  avg_fare_1week          ,        ....Note that in prediction we have predict with double value. This is because this model is a regression model. If it is a classification model, the prediction predict value will be the class; the associated prob can be found in the result section. For example, this is a MarketPlace dispatch model prediction result.      prediction :           key :  predict ,         stringValue :  true        ,       publishResult : [                    key :  vehicle_view_id ,           stringValue :  14415          ,                    key :  predict ,           stringValue :  true                ],       result : [                    doubleValue : 0.6062631312615228,           key :  true          ,                    key :  predict ,           stringValue :  true          ,                    doubleValue : 0.39373686873847724,           key :  false                ],Note that in their model, the classes are  true  and  false.  Note that you can get the corresponding class' prob in the result section.publishResult contains the results that you added to published fields of the model. transformedFeatures is the post-DSL feature values used in your model.One can also go thru michelangelo-gateway. For michelangelo-gateway, you need to provide shard-key  sk , which usually is :production. For the above example, sk will be  michelangelo-prediction-group1:production. If the prediction service group has model sharding, it will ask you to provide at least one virtual sharding key during the model deployment request. In such case, sk will be :. For example,  michelangelo-porediction-group38:city_id_1. "}
{"prompt": "How to do feature normalization in Michelangelo? I read that model tends to behave better and achieve better performance if features are normalized. How do we do feature normalization in Michelangelo?", "completion": "Engdoc for realtime prediction service can be found here. Model monitoring can be found here. See here for model deployment tag lab. The thrift definition of the prediction request can be found in here. For simplicity, let's focus on single prediction request.struct PredictionRequest    1: optional string projectId,   <-- project-id associated with the model. note that case sensitive.  2: optional string modelId,     <-- full model-id  3: optional list<ValueItem> basisFeatures, <-- list of features used in your model  4: optional string label,       <-- deployment label, note that you cannot use label and modelId at the same time  5: optional string joinKey,     <-- join key uuid that associated with the request that can be used to identified the request and join back to other table   6: optional bool returnTransformedFeatures, <-- whether to return transformed feature values in the response. Suggest set to False to reduce response payload.  7: optional bool testTraffic,  <-- set this to True if this is not production traffic. For example, coming from simulation, hailstorm, or blackbox.  8: optional binary binaryBasisFeatures, <-- apache arrow encoded request. note that this only works for python ML  9: optional EncodingType binaryBasisFeaturesEncodingType,     note: when true the request is always logged  10: optional bool sampleRequest, <-- set to True if you always want to log this prediction response to Kafka and then to Hive. Note that logging has some performance penality Let's take this model as example. The deployment section for the project has enabled realtime prediction and hasgroup-1in online container. Thus the corresponding service will be michelangelo-prediction-group1. The corresponding yab command will be something likeyab michelangelo-prediction-group1 PredictionService::predict --rps 100 --max-duration 300s --peer 127.0.0.1:6424 --thrift predictionservice.thrift --body '  request :   projectId :  vs_marketplace_econ_mvp ,  basisFeatures : [  stringValue :  0036508d-8655-4e6b-bb1c-47b8eecd76a7 ,  key :  @basis:basis_driver_uuid  ,   stringValue :  2017-10-23 ,  key :  @basis:basis_datestr  ,   stringValue :  0036508d-8655-4e6b-bb1c-47b8eecd76a7 ,  key :  @basis:driver_uuid  ,   doubleValue : 0.0,  key :  @basis:earning_before_cash_and_vehicle_l7d  ,   stringValue :  2017-10-23 ,  key :  @basis:dtPartition  ],  modelId :  2017-11-08-19-28-36-185-UTC   'The corresponding response will have something like    body :       result :         prediction :           doubleValue : 8.92900471968395,         key :  predict        ,       publishResult : [                    doubleValue : 8.92900471968395,           key :  earnings_prediction          ,                    key :  driver_uuid ,           stringValue :  0036508d-8655-4e6b-bb1c-47b8eecd76a7                ],       result : [                    doubleValue : 8.92900471968395,           key :  predict                ],       transformedFeatures : [                    doubleValue : 0,           key :  avg_fare_1week          ,        ....Note that in prediction we have predict with double value. This is because this model is a regression model. If it is a classification model, the prediction predict value will be the class; the associated prob can be found in the result section. For example, this is a MarketPlace dispatch model prediction result.      prediction :           key :  predict ,         stringValue :  true        ,       publishResult : [                    key :  vehicle_view_id ,           stringValue :  14415          ,                    key :  predict ,           stringValue :  true                ],       result : [                    doubleValue : 0.6062631312615228,           key :  true          ,                    key :  predict ,           stringValue :  true          ,                    doubleValue : 0.39373686873847724,           key :  false                ],Note that in their model, the classes are  true  and  false.  Note that you can get the corresponding class' prob in the result section.publishResult contains the results that you added to published fields of the model. transformedFeatures is the post-DSL feature values used in your model.One can also go thru michelangelo-gateway. For michelangelo-gateway, you need to provide shard-key  sk , which usually is :production. For the above example, sk will be  michelangelo-prediction-group1:production. If the prediction service group has model sharding, it will ask you to provide at least one virtual sharding key during the model deployment request. In such case, sk will be :. For example,  michelangelo-porediction-group38:city_id_1. "}
{"prompt": "Michelangelo Feature Palette Training Data is Mostly Empty", "completion": "The final answer to this is that the upstream table apparently contains a lot of non 84 day active riders which then are not matched with the feature palette table. The root cause is somewhere in the upstream table that was supposed to guarantee only 84 day active riders. Here is the query that proves the point. https:  querybuilder-ea.uberinternal.com r ip1QXjFHN"}
{"prompt": "Can't load predictive dispatch model UI for new partition models", "completion": "The final answer to this is that the upstream table apparently contains a lot of non 84 day active riders which then are not matched with the feature palette table. The root cause is somewhere in the upstream table that was supposed to guarantee only 84 day active riders. Here is the query that proves the point. https:  querybuilder-ea.uberinternal.com r ip1QXjFHN"}
{"prompt": "404 when looking up hosts for my Palette Cassandra cluster Following the instructions here.You can find a list of hosts associated with your cluster in each data center via UNS. For example, to find a list of hosts in PHX2 for cstar-michelangelo, you can curl http:  localhost:15936 clusters cstar-michelangelo datacenters phx2.All the variations I've tried on that endpoint have yielded 404s.hadoopsecgw01-dca1: $ curl  http:  localhost:15936 clusters cstar-michelangelo-palette-multi datacenters dca1 404 page not foundAny ideas?", "completion": "The Cassandra has moved to odin system. We'll update the engdoc.To find a list of hosts associated with a cluster, go tohttps:  odin.uberinternal.com info storage::technology:cassandraand type in the cluster name. For example, if you type in cstar-michelangelo, for Eats cluster, you gethttps:  odin.uberinternal.com info cassandra::instance:cstar-michelangeloThen you can select specific dc to get hosts associated with that datacenter."}
{"prompt": "How to get data in hdrone.michelangelo_prediction", "completion": "The Cassandra has moved to odin system. We'll update the engdoc.To find a list of hosts associated with a cluster, go tohttps:  odin.uberinternal.com info storage::technology:cassandraand type in the cluster name. For example, if you type in cstar-michelangelo, for Eats cluster, you gethttps:  odin.uberinternal.com info cassandra::instance:cstar-michelangeloThen you can select specific dc to get hosts associated with that datacenter."}
{"prompt": "How can I get model performance from a trained model? I'd like to fetch AUC RMSE for the model trained in Michelangelo for automatic performance monitoring purpose. Is there a way I can get that information from Michelangelo programmatically?", "completion": "The Cassandra has moved to odin system. We'll update the engdoc.To find a list of hosts associated with a cluster, go tohttps:  odin.uberinternal.com info storage::technology:cassandraand type in the cluster name. For example, if you type in cstar-michelangelo, for Eats cluster, you gethttps:  odin.uberinternal.com info cassandra::instance:cstar-michelangeloThen you can select specific dc to get hosts associated with that datacenter."}
{"prompt": "Is it possible to leverage palette in label? I see Michelangelo has various rider  driver features in featurestore. If we want to leverage those features to predict another feature in featurestore, how do we do this?", "completion": "The Cassandra has moved to odin system. We'll update the engdoc.To find a list of hosts associated with a cluster, go tohttps:  odin.uberinternal.com info storage::technology:cassandraand type in the cluster name. For example, if you type in cstar-michelangelo, for Eats cluster, you gethttps:  odin.uberinternal.com info cassandra::instance:cstar-michelangeloThen you can select specific dc to get hosts associated with that datacenter."}
{"prompt": "Interaction Term Modeling", "completion": "The Cassandra has moved to odin system. We'll update the engdoc.To find a list of hosts associated with a cluster, go tohttps:  odin.uberinternal.com info storage::technology:cassandraand type in the cluster name. For example, if you type in cstar-michelangelo, for Eats cluster, you gethttps:  odin.uberinternal.com info cassandra::instance:cstar-michelangeloThen you can select specific dc to get hosts associated with that datacenter."}
{"prompt": "Michelangelo DSL for parsing non-canonical datetime Is there a way to leverage existing time date related DSL for datetime field that doesn't have the required datetime format?", "completion": "See here for example.pickup_hour_of_day: getHourOfDay sVal new java.text.SimpleDateFormat  yyyy-MM-dd'T'HH:mm:ss.SSSXXX   .format  new java.text.SimpleDateFormat  yyyy-MM-dd HH:mm:ss z   .parse sVal @basis:pickup_datetime    "}
{"prompt": "Error saving data source in Michelangelo", "completion": "See here for example.pickup_hour_of_day: getHourOfDay sVal new java.text.SimpleDateFormat  yyyy-MM-dd'T'HH:mm:ss.SSSXXX   .format  new java.text.SimpleDateFormat  yyyy-MM-dd HH:mm:ss z   .parse sVal @basis:pickup_datetime    "}
{"prompt": "Why do training jobs fail with error  Sum of weights cannot be zero ?", "completion": "See here for example.pickup_hour_of_day: getHourOfDay sVal new java.text.SimpleDateFormat  yyyy-MM-dd'T'HH:mm:ss.SSSXXX   .format  new java.text.SimpleDateFormat  yyyy-MM-dd HH:mm:ss z   .parse sVal @basis:pickup_datetime    "}
{"prompt": "Unable to download Cerberus ATG Following the instructions on https:  engdocs.uberinternal.com michelangelo user-guides dl atg-install-cerberus.html#atg-install-cerberus, I get an error when trying to execute the curl command  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current                                 Dload  Upload   Total   Spent    Left  Speed  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl:  7  Failed to receive SOCKS5 connect request ack.Any suggestions on how to proceed?", "completion": "This issue was caused because SJC was decommisioned, removing the host  madlj01-sjc1  that was hosting the ussh binary.We've updated the docs; the ussh binary is available for down here. Once downloaded, the binary can be set like this:sudo cp <downloaded cerberus binary>  usr bin cerberussudo chmod a+x  usr bin cerberus"}
{"prompt": "Where I can find information related to FeatureStore? Where can I find more information about Michelangelo FeatureStore?", "completion": "This issue was caused because SJC was decommisioned, removing the host  madlj01-sjc1  that was hosting the ussh binary.We've updated the docs; the ussh binary is available for down here. Once downloaded, the binary can be set like this:sudo cp <downloaded cerberus binary>  usr bin cerberussudo chmod a+x  usr bin cerberus"}
{"prompt": "Does Michelangelo feature monitoring cover all features used in a model or only Palette features? I want to make sure that turning on feature monitoring will result in M3 stats for all features used by my model, including the features that are currently dispersed via uFlow.", "completion": "See here for model monitoring. On the high level, there are three types discussed in the engdoc.Model performance monitoringP50 value comparison for numeric features to realtime prediction service and the same date training data. This is to ensure training and prediction have the same distribution.P50 value comparison for numeric features between training data. This is to detect training data drift.See here for feature store monitoring. There are integration done with Trust and Databook. We are working with Data Knowledge team to leverage DSS. This will reduce stats computation.For the realtime prediction service, we are working with Athena AthenaX team on monitoring. This will allow team to monitor basis features, derived features, published fields, and prediction scores. In the first phase, we will just update realtime monitoring engdoc with examples. In the 2nd phase,we want to auto create Athena AthenaX jobs to emit M3 when derived feature values exceed max min or has outlier."}
{"prompt": "How to use '>' DSL to create boolean column I try to create a boolean column  or int column  based on one of my basis feature like following:eyeball_eta_gt_7m: nFill nVal  @basis:eyeball_eta   > 7*60, 0 But have following error:Compilation Errorerror: type mismatch;found   : Booleanrequired: Double eyeball_eta_gt_7m  ->  nFill nVal  @basis:eyeball_eta   > 7*60, 0  ,What's the correct way to create a boolean or int feature column with '>'?", "completion": "See here for model monitoring. On the high level, there are three types discussed in the engdoc.Model performance monitoringP50 value comparison for numeric features to realtime prediction service and the same date training data. This is to ensure training and prediction have the same distribution.P50 value comparison for numeric features between training data. This is to detect training data drift.See here for feature store monitoring. There are integration done with Trust and Databook. We are working with Data Knowledge team to leverage DSS. This will reduce stats computation.For the realtime prediction service, we are working with Athena AthenaX team on monitoring. This will allow team to monitor basis features, derived features, published fields, and prediction scores. In the first phase, we will just update realtime monitoring engdoc with examples. In the 2nd phase,we want to auto create Athena AthenaX jobs to emit M3 when derived feature values exceed max min or has outlier."}
{"prompt": "What Hive datatypes are supported in FeatureStore? What types do we support in Michelangelo FeatureStore? Is decimal like Decimal 9, 2  supported?", "completion": "See here for model monitoring. On the high level, there are three types discussed in the engdoc.Model performance monitoringP50 value comparison for numeric features to realtime prediction service and the same date training data. This is to ensure training and prediction have the same distribution.P50 value comparison for numeric features between training data. This is to detect training data drift.See here for feature store monitoring. There are integration done with Trust and Databook. We are working with Data Knowledge team to leverage DSS. This will reduce stats computation.For the realtime prediction service, we are working with Athena AthenaX team on monitoring. This will allow team to monitor basis features, derived features, published fields, and prediction scores. In the first phase, we will just update realtime monitoring engdoc with examples. In the 2nd phase,we want to auto create Athena AthenaX jobs to emit M3 when derived feature values exceed max min or has outlier."}
{"prompt": "How to populate input columns not in basis features for Michelangelo one-off prediction? Is there a way to populate columns not in basis feature but in the input table for Michelangelo one-off prediction?For example in my Michelangelo model, it takes rider_uuid, promo_amount as basis feature. But in the input table for one-off prediction job, we have one additional column promo_id, which is not used as basis feature, but we still want to associate this promo_id to the prediction. Is there any easy way to populate it?The other alternative would be joining it back to prediction input table, which might be slow.", "completion": "See here for model monitoring. On the high level, there are three types discussed in the engdoc.Model performance monitoringP50 value comparison for numeric features to realtime prediction service and the same date training data. This is to ensure training and prediction have the same distribution.P50 value comparison for numeric features between training data. This is to detect training data drift.See here for feature store monitoring. There are integration done with Trust and Databook. We are working with Data Knowledge team to leverage DSS. This will reduce stats computation.For the realtime prediction service, we are working with Athena AthenaX team on monitoring. This will allow team to monitor basis features, derived features, published fields, and prediction scores. In the first phase, we will just update realtime monitoring engdoc with examples. In the 2nd phase,we want to auto create Athena AthenaX jobs to emit M3 when derived feature values exceed max min or has outlier."}
{"prompt": "How do we check for overfitting? How do we know if we've overfitted or under-fitted a model? Any suggestion on what we can do when we've an overfit or underfit?", "completion": "See here for model monitoring. On the high level, there are three types discussed in the engdoc.Model performance monitoringP50 value comparison for numeric features to realtime prediction service and the same date training data. This is to ensure training and prediction have the same distribution.P50 value comparison for numeric features between training data. This is to detect training data drift.See here for feature store monitoring. There are integration done with Trust and Databook. We are working with Data Knowledge team to leverage DSS. This will reduce stats computation.For the realtime prediction service, we are working with Athena AthenaX team on monitoring. This will allow team to monitor basis features, derived features, published fields, and prediction scores. In the first phase, we will just update realtime monitoring engdoc with examples. In the 2nd phase,we want to auto create Athena AthenaX jobs to emit M3 when derived feature values exceed max min or has outlier."}
{"prompt": "FeatureStore user group email? how do we receive announcement related to FeatureStore? Is there a user-group we can post questions?", "completion": "See here for model monitoring. On the high level, there are three types discussed in the engdoc.Model performance monitoringP50 value comparison for numeric features to realtime prediction service and the same date training data. This is to ensure training and prediction have the same distribution.P50 value comparison for numeric features between training data. This is to detect training data drift.See here for feature store monitoring. There are integration done with Trust and Databook. We are working with Data Knowledge team to leverage DSS. This will reduce stats computation.For the realtime prediction service, we are working with Athena AthenaX team on monitoring. This will allow team to monitor basis features, derived features, published fields, and prediction scores. In the first phase, we will just update realtime monitoring engdoc with examples. In the 2nd phase,we want to auto create Athena AthenaX jobs to emit M3 when derived feature values exceed max min or has outlier."}
{"prompt": "Delete a batch of models in Michelangelo Is there any way to delete a batch of models in Michelangelo? Currently we could select multiple models in the UI, but when we choose delete, it will only delete the first model you choose.", "completion": "See here for model monitoring. On the high level, there are three types discussed in the engdoc.Model performance monitoringP50 value comparison for numeric features to realtime prediction service and the same date training data. This is to ensure training and prediction have the same distribution.P50 value comparison for numeric features between training data. This is to detect training data drift.See here for feature store monitoring. There are integration done with Trust and Databook. We are working with Data Knowledge team to leverage DSS. This will reduce stats computation.For the realtime prediction service, we are working with Athena AthenaX team on monitoring. This will allow team to monitor basis features, derived features, published fields, and prediction scores. In the first phase, we will just update realtime monitoring engdoc with examples. In the 2nd phase,we want to auto create Athena AthenaX jobs to emit M3 when derived feature values exceed max min or has outlier."}
{"prompt": "michelangelo.exception.BackendException: 403 Forbidden", "completion": "Adding myself to the corresponding ma project resolved my problem."}
{"prompt": "Michelangelo writes one-off prediction to the same output table partitioned by both city and datestr As suggested here we can do one-off prediction on Michelangelo to a specified table. My questions would be:How should we create a Hive table to store the prediction output? What exact schema should we use for this table if we don't want a temp table?Can we have this table partitioned by both city and datestr so we could have multiple jobs running and writing into this same table for different cities and datestrs?", "completion": "Adding myself to the corresponding ma project resolved my problem."}
{"prompt": "pass columns from feature table to train test table In model templates, how can i pass columns like 'trip_id' from feature table to michelangelo output train test table  since i need to use them as join keys later ? Currently the only way i can have them in those tables generated was by indicating using those columns as training features, which is not what's intended.", "completion": "Adding myself to the corresponding ma project resolved my problem."}
{"prompt": "Training job got stuck at trainOperator_RUNNING", "completion": "Adding myself to the corresponding ma project resolved my problem."}
{"prompt": "Is there to force feature-gen or dispersal task for FeatureStore to only enable in a specific DC? We have upstream data issue in DCA1. We'll like the dispersal job to only run in SJC1. Is this possible?", "completion": "Adding myself to the corresponding ma project resolved my problem."}
{"prompt": "How to temporarily disable auto alerts for palette pipelines?", "completion": "Adding myself to the corresponding ma project resolved my problem."}
{"prompt": "Explain the Regression Model Diagnostic Plots I couldnt find any documentation on these MA plots. I believe the first one is simply the distribution of actual vs. predicted and this just tells if there is any systematic errors that the model is not capturing. The Absolute Errors plot  and Error Chart is a lot more confusing. What does the x-axis mean? Is this the percentile of the label? If so is the error cumulative?", "completion": "Adding myself to the corresponding ma project resolved my problem."}
{"prompt": "Possible to train in PHX? I was experimenting with the DLJobConfig package following the guide here https:  engdocs.uberinternal.com michelangelo user-guides dl quickstart-lambdadl.html?highlight=dljobconfig. In the example, it specifies zone='dca1-prod02' when initializing DLJobConfig. Is it possible to try it in phx2? I tried some zone name, but get an invalid zone name error.", "completion": "Michelangelo supports zones where gpus are. Once GPUs are available in phx2, we can support a zone for phx2 as well."}
{"prompt": "Do we have non-linear  numeric feature  transformations in Spark as in deeplearning?", "completion": "There are many non-linear action functions that one can indirectly implemented using existing Michelangelo DSL. For example, binary step can be implemented asbinary_step_f1: if  nFill nVal f1 , 0  < 0   1.0  else  0.0 Note that for tree algorithms are basically approximating a target function using piece-wise linear functions. Some of the regularization approaches such as dropout cannot be implemented as Spark transformer.We will add some non-linear numeric udfs."}
{"prompt": " Must provide a project id  error in Michelangelo with project id configured", "completion": "There are many non-linear action functions that one can indirectly implemented using existing Michelangelo DSL. For example, binary step can be implemented asbinary_step_f1: if  nFill nVal f1 , 0  < 0   1.0  else  0.0 Note that for tree algorithms are basically approximating a target function using piece-wise linear functions. Some of the regularization approaches such as dropout cannot be implemented as Spark transformer.We will add some non-linear numeric udfs."}
{"prompt": "Batch Prediction with PySpark in MA possible?", "completion": "For such model, scheduling batch prediction wouldn't be different. There should be an API for one to schedule batch prediction job. There is a Piper operator in michelangelo_platform tasks for it as well.For one-off offline prediction, please refer to engdoc.If non sparkML TF model, such as pure TF or PyTorch model, we are still working on online offline prediction. The POC should be available in early H2 2019. Contact online team or deeplearning team for more information."}
{"prompt": "How to use Cerberus in ma docker I have a custom docker created by the command ma train tf docker for model training. In my training program, I want to query data on hive using queryrunner. The issue is the container doesn't have connections to other services through http port. I tried to tunnel to a production server but get permission denied. What is the proper way to have a connection to the service that I need? Is there a way to use cerberus?", "completion": "Most likely your version of the queryrunner-client is out of date and needs to be upgraded.  Using version 1.5.5, the following code  taken from docs here  should be able to execute successfully without Cerberus:from queryrunner_client import Client, start_adhocstart_adhoc    # for galileoqr = Client user_email=userid + '@uber.com' print qr.list_datasources   query = 'select city_id, city_name from dim_city order by city_id asc limit 5;'cursor = qr.execute 'warehouse', query print cursor.execution_uuid Note that to do this interactively you'll need to update the  root .pip pip.conf file to have your the contents of your local  .pip pip.conf file, then run pip install --upgrade queryrunner-client.  The preferred way to ugprade would be to create a new custom Docker image and install it there."}
{"prompt": "Connection to <node> closed by remote host when using michelangelo opus", "completion": "Most likely your version of the queryrunner-client is out of date and needs to be upgraded.  Using version 1.5.5, the following code  taken from docs here  should be able to execute successfully without Cerberus:from queryrunner_client import Client, start_adhocstart_adhoc    # for galileoqr = Client user_email=userid + '@uber.com' print qr.list_datasources   query = 'select city_id, city_name from dim_city order by city_id asc limit 5;'cursor = qr.execute 'warehouse', query print cursor.execution_uuid Note that to do this interactively you'll need to update the  root .pip pip.conf file to have your the contents of your local  .pip pip.conf file, then run pip install --upgrade queryrunner-client.  The preferred way to ugprade would be to create a new custom Docker image and install it there."}
{"prompt": "Import error when using michelangelo python client", "completion": "The problem stemmed from the combination of two things:Installing michelangelo-python-client and michelangelo-pyspark-sdk together in the same environment.A latent bug in michelangelo-python-client where we had an incorrect import that failed when both libraries were installed in the same environment.We fixed the bug in michelangelo-python-client in D3182601. Versions of michelangelo-python-client including and after 0.6.75 should work just fine when installed along side michelangelo-pyspark-sdk."}
{"prompt": "I am building a Michelangelo Model using .csv file for a database. I keep getting an error I am building a Michelangelo Model using .csv file for a database. I keep getting an error which prevents me going forward", "completion": "The problem stemmed from the combination of two things:Installing michelangelo-python-client and michelangelo-pyspark-sdk together in the same environment.A latent bug in michelangelo-python-client where we had an incorrect import that failed when both libraries were installed in the same environment.We fixed the bug in michelangelo-python-client in D3182601. Versions of michelangelo-python-client including and after 0.6.75 should work just fine when installed along side michelangelo-pyspark-sdk."}
{"prompt": "Is Logloss calculation pre or post calibration in Michelangelo UI?", "completion": "It looks like it is the log loss is immediately after fit and pre-calibration."}
{"prompt": "xGboost training reliability issue? I tried to train a xGBoost model. However, training often failed without good explanation of failures. Is there anything that I can check?", "completion": "Make sure there are no null values. You can use nFill for numericfeatures and sFill for categorical features.Large cardinality categorical features can be problematic. Try to see if you can train a model without categorical features.Try training with a smaller dataset. If successful, then gradually expanding training date range.Try training a less complex model.  x+1  depth tree canpossibly run 2X longer than x depth tree.Try getting a bigger Yarn Peloton memory container.  You need to ask Yarn and Pelotonteams about this. "}
{"prompt": "Onelogin issue prevent model creation I could not create models in Michelangelo because some of the onelogin issues", "completion": "Make sure there are no null values. You can use nFill for numericfeatures and sFill for categorical features.Large cardinality categorical features can be problematic. Try to see if you can train a model without categorical features.Try training with a smaller dataset. If successful, then gradually expanding training date range.Try training a less complex model.  x+1  depth tree canpossibly run 2X longer than x depth tree.Try getting a bigger Yarn Peloton memory container.  You need to ask Yarn and Pelotonteams about this. "}
{"prompt": "Piper error:  400: Unsupported Virtual Shards ", "completion": "model sharding is a feature that Michelangelo supports, for more information you can refer to https:  engdocs.uberinternal.com michelangelo user-guides model-sharding.html?highlight=shardingFor your issue, you are trying to deploy the model to a shard a1c693f6-1f54-44e9-bcb0-a6373439e5e1 that's unknown to us. Can you ask our oncall for adding this new shard?"}
{"prompt": "Ensure predictions are always positive can i do this to ensure that my predictions are always positive ?", "completion": "Solution is to add the following in the Published Fields for your modelif @prediction:predict < 0   0  else  @prediction:predict "}
{"prompt": "Michelangelo: Error message when updating the data source", "completion": "Solution is to add the following in the Published Fields for your modelif @prediction:predict < 0   0  else  @prediction:predict "}
{"prompt": "How do I find hotspot in FeatureStore Cassandra? It seems we've a hotspot in our Cassandra table lookup. How do I find the partitions that are causing the problem.", "completion": "You can use nodetool toppartitions command. Currently, we are not allowed to ssh into Cassandra node.You download apache-cassandra.You ask CaaS team to enable JMX for your cluster.You find the problematic node s  from the Cassandra dashboard.You query Grail to find port.You then run nodetool command.. nodetool -h schemadock3695-dca1 -p 25601 toppartitions carousel source_history 1000WRITES Sampler:  Cardinality: 0  256 capacity   Top 10 partitions:    Nothing recorded during sampling period...READS Sampler:  Cardinality: 2  256 capacity   Top 10 partitions:    Partition                                Count       + -    storefront                               21668         0    e9a480d1-e504-5eae-b92b-d8b4ae291e54         4         0    ce72124d-a6b3-548b-9b18-8a2e1b76e676         3         0    09db7796-dce2-564a-b188-da1eb29447dd         2         0    f44ab959-9682-5b7a-95e0-33c5470f72f7         1         0    e1319827-2ae6-5a9a-8be3-b23b078b5cd5         1         0    2cefe08c-ce3f-5a1a-adf3-af4098894e95         1         0"}
{"prompt": "Michelangelo online serving optimization", "completion": "You can use nodetool toppartitions command. Currently, we are not allowed to ssh into Cassandra node.You download apache-cassandra.You ask CaaS team to enable JMX for your cluster.You find the problematic node s  from the Cassandra dashboard.You query Grail to find port.You then run nodetool command.. nodetool -h schemadock3695-dca1 -p 25601 toppartitions carousel source_history 1000WRITES Sampler:  Cardinality: 0  256 capacity   Top 10 partitions:    Nothing recorded during sampling period...READS Sampler:  Cardinality: 2  256 capacity   Top 10 partitions:    Partition                                Count       + -    storefront                               21668         0    e9a480d1-e504-5eae-b92b-d8b4ae291e54         4         0    ce72124d-a6b3-548b-9b18-8a2e1b76e676         3         0    09db7796-dce2-564a-b188-da1eb29447dd         2         0    f44ab959-9682-5b7a-95e0-33c5470f72f7         1         0    e1319827-2ae6-5a9a-8be3-b23b078b5cd5         1         0    2cefe08c-ce3f-5a1a-adf3-af4098894e95         1         0"}
{"prompt": "getHourOfDay doesn't work in michelangelo feature computation", "completion": "You can use nodetool toppartitions command. Currently, we are not allowed to ssh into Cassandra node.You download apache-cassandra.You ask CaaS team to enable JMX for your cluster.You find the problematic node s  from the Cassandra dashboard.You query Grail to find port.You then run nodetool command.. nodetool -h schemadock3695-dca1 -p 25601 toppartitions carousel source_history 1000WRITES Sampler:  Cardinality: 0  256 capacity   Top 10 partitions:    Nothing recorded during sampling period...READS Sampler:  Cardinality: 2  256 capacity   Top 10 partitions:    Partition                                Count       + -    storefront                               21668         0    e9a480d1-e504-5eae-b92b-d8b4ae291e54         4         0    ce72124d-a6b3-548b-9b18-8a2e1b76e676         3         0    09db7796-dce2-564a-b188-da1eb29447dd         2         0    f44ab959-9682-5b7a-95e0-33c5470f72f7         1         0    e1319827-2ae6-5a9a-8be3-b23b078b5cd5         1         0    2cefe08c-ce3f-5a1a-adf3-af4098894e95         1         0"}
{"prompt": "Is there a way to only retain top categorical values in a feature and use 'Other' for remaining values?", "completion": "You can use nodetool toppartitions command. Currently, we are not allowed to ssh into Cassandra node.You download apache-cassandra.You ask CaaS team to enable JMX for your cluster.You find the problematic node s  from the Cassandra dashboard.You query Grail to find port.You then run nodetool command.. nodetool -h schemadock3695-dca1 -p 25601 toppartitions carousel source_history 1000WRITES Sampler:  Cardinality: 0  256 capacity   Top 10 partitions:    Nothing recorded during sampling period...READS Sampler:  Cardinality: 2  256 capacity   Top 10 partitions:    Partition                                Count       + -    storefront                               21668         0    e9a480d1-e504-5eae-b92b-d8b4ae291e54         4         0    ce72124d-a6b3-548b-9b18-8a2e1b76e676         3         0    09db7796-dce2-564a-b188-da1eb29447dd         2         0    f44ab959-9682-5b7a-95e0-33c5470f72f7         1         0    e1319827-2ae6-5a9a-8be3-b23b078b5cd5         1         0    2cefe08c-ce3f-5a1a-adf3-af4098894e95         1         0"}
{"prompt": "Failing during training", "completion": "Opened https:  code.uberinternal.com T4007343. Please add project and model links."}
{"prompt": "Custom spark parameters don't appear to be set in Michelangelo prediction job I've set the Spark parameters here. Specifically, I've set spark.executor.instances=400. The prediction job's Spark UI show spark.executor.instances=50. Why are the parameters not being set and how can I set them correctly?", "completion": "Opened https:  code.uberinternal.com T4007343. Please add project and model links."}
{"prompt": "Partition Key Limitation I recently ran a training job and got the following error:The maximum allowed number of partitioned models is 200, while the number of partitioned models scheduled for training is 475. Please consider reducing the number of partitions by adding a training filter on the partition key columns of the training dataset.However there are more than 200 cities that Uber operate in. I wonder what would be the strategy to train models for each city?Also, I wonder if this 200 limitation is applied to all layers of partition? Or would we host more than 200 partitions by having a multi-layer partition structure?e.g. Mega-region -> region -> subregion -> cityin this way, nodes on each layer has less than 200 sub-nodes.thanks.", "completion": "Opened https:  code.uberinternal.com T4007343. Please add project and model links."}
{"prompt": "Request to michelangelo fails due to unsupported characters", "completion": "Golang doesn't have a nice support for PyML's Arrow encoding yet. The simplest way to support unicode would be just encoding unicode strings with base64 and then decoding them at the model level upon receiving.We can look into golang client support of arrow encoding to make this even more simpler  the same way it works for python ."}
{"prompt": "michelangelo one-off prediction error", "completion": "Golang doesn't have a nice support for PyML's Arrow encoding yet. The simplest way to support unicode would be just encoding unicode strings with base64 and then decoding them at the model level upon receiving.We can look into golang client support of arrow encoding to make this even more simpler  the same way it works for python ."}
{"prompt": "Publishing predictions fails", "completion": "Golang doesn't have a nice support for PyML's Arrow encoding yet. The simplest way to support unicode would be just encoding unicode strings with base64 and then decoding them at the model level upon receiving.We can look into golang client support of arrow encoding to make this even more simpler  the same way it works for python ."}
{"prompt": "Create table from one table to another table with datestr column? Michelangelo training dataset requires datestr partition column. My Hive table doesn't have datestr. How do I create another table from the existing table?", "completion": "One approach is to create datestr column with fixed value. Something likeCREATE TABLE mydb.t2 ASSELECT  *,   '2019-08-24' as datestrFROM   mydb.t;Afterward, you register another dataset. For above example, mydb.t2. In the model training draft, specify 2019-08-24 to 2019-08-24 for training range."}
{"prompt": "MA one-off prediction job got shut down after long running time I was trying to run MA one-off prediction job through MLE on piper but it got shut down after running for 1.5 hours. Any idea why? And this seems to only happen in PHX2 but not DCA.", "completion": "One approach is to create datestr column with fixed value. Something likeCREATE TABLE mydb.t2 ASSELECT  *,   '2019-08-24' as datestrFROM   mydb.t;Afterward, you register another dataset. For above example, mydb.t2. In the model training draft, specify 2019-08-24 to 2019-08-24 for training range."}
{"prompt": "Array-like feature columns for Michelangelo E2E DL in PySpark", "completion": "One approach is to create datestr column with fixed value. Something likeCREATE TABLE mydb.t2 ASSELECT  *,   '2019-08-24' as datestrFROM   mydb.t;Afterward, you register another dataset. For above example, mydb.t2. In the model training draft, specify 2019-08-24 to 2019-08-24 for training range."}
{"prompt": "Prediction job running for more than 1 day The prediction job is here has been running for more than one day. Looking at prior executions, it has taken typically 1-5 hours, outside of one instance on 2017-09-16 where it took 2 days.What is causing this job to run for a long time?", "completion": "One approach is to create datestr column with fixed value. Something likeCREATE TABLE mydb.t2 ASSELECT  *,   '2019-08-24' as datestrFROM   mydb.t;Afterward, you register another dataset. For above example, mydb.t2. In the model training draft, specify 2019-08-24 to 2019-08-24 for training range."}
{"prompt": "How do we specify OR or AND condition in the classification response field Can we add or to a Responseif  sFill sVal @basis:profile_type ,  NA   ==  Personal  or  ...     true   else   false  do we have in the feature store rider email address?", "completion": "One approach is to create datestr column with fixed value. Something likeCREATE TABLE mydb.t2 ASSELECT  *,   '2019-08-24' as datestrFROM   mydb.t;Afterward, you register another dataset. For above example, mydb.t2. In the model training draft, specify 2019-08-24 to 2019-08-24 for training range."}
{"prompt": "Does michelangelo support automatic model training on a configured cadence?", "completion": "One approach is to create datestr column with fixed value. Something likeCREATE TABLE mydb.t2 ASSELECT  *,   '2019-08-24' as datestrFROM   mydb.t;Afterward, you register another dataset. For above example, mydb.t2. In the model training draft, specify 2019-08-24 to 2019-08-24 for training range."}
{"prompt": "How is Michelangelo 'Standardization' Implemented? In Michelangelo Linear Regression, we can specify to use Standardization or not. What's the implementation of this feature? As we also provide colStatStdDev, colStatMean and zScore in DSL. Is it the same to use zScore x, colStatMean x , colStatStdDev x  ?", "completion": "One approach is to create datestr column with fixed value. Something likeCREATE TABLE mydb.t2 ASSELECT  *,   '2019-08-24' as datestrFROM   mydb.t;Afterward, you register another dataset. For above example, mydb.t2. In the model training draft, specify 2019-08-24 to 2019-08-24 for training range."}
{"prompt": "Unseen 'response' feature in trained model I have trained a model on MA here and it's weird that we have this 'response' feature showing but it's not in the model template. Any idea what's this? The model performance is also off.", "completion": "One approach is to create datestr column with fixed value. Something likeCREATE TABLE mydb.t2 ASSELECT  *,   '2019-08-24' as datestrFROM   mydb.t;Afterward, you register another dataset. For above example, mydb.t2. In the model training draft, specify 2019-08-24 to 2019-08-24 for training range."}
{"prompt": "Does Michelangelo DSL have a string concatenation operator I am trying to synthesize features, ideally with string concatenation. However I didn't find one and here is what I am currently doing.day_of_week_X_hour_of_day: nFill if   sFill sVal  @basis:ti_workflowcreatedat_local_day_of_week  ,  NA   ==  Monday    nFill 100 + nVal  @basis:ti_workflowcreatedat_local_hour_of_day  , -1.0   else  if   sFill sVal  @basis:ti_workflowcreatedat_local_day_of_week  ,  NA   ==  Tuesday    nFill 200 + nVal  @basis:ti_workflowcreatedat_local_hour_of_day  , -1.0   else  if   sFill sVal  @basis:ti_workflowcreatedat_local_day_of_week  ,  NA   ==  Wednesday    nFill 300 + nVal  @basis:ti_workflowcreatedat_local_hour_of_day  , -1.0   else  if   sFill sVal  @basis:ti_workflowcreatedat_local_day_of_week  ,  NA   ==  Thursday    nFill 400 + nVal  @basis:ti_workflowcreatedat_local_hour_of_day  , -1.0   else  if   sFill sVal  @basis:ti_workflowcreatedat_local_day_of_week  ,  NA   ==  Friday    nFill 500 + nVal  @basis:ti_workflowcreatedat_local_hour_of_day  , -1.0   else  if   sFill sVal  @basis:ti_workflowcreatedat_local_day_of_week  ,  NA   ==  Saturday    nFill 600 + nVal  @basis:ti_workflowcreatedat_local_hour_of_day  , -1.0   else  nFill 700 + nVal  @basis:ti_workflowcreatedat_local_hour_of_day  , -1.0       , -1.0 But this is limited and can not do a more generic crossing.Thanks!", "completion": "One approach is to create datestr column with fixed value. Something likeCREATE TABLE mydb.t2 ASSELECT  *,   '2019-08-24' as datestrFROM   mydb.t;Afterward, you register another dataset. For above example, mydb.t2. In the model training draft, specify 2019-08-24 to 2019-08-24 for training range."}
{"prompt": "does Michelangelo support customize quantile regression loss for XGboost? Does Michelangelo support any customized loss function for XGboost ? is there any example on how to do it?More specifically the subscription team is interested in building a quantile regression using XGboost using the quantile deviation loss functions  a example here    , what are some options to implement this loss function in MA? Thank you", "completion": "One approach is to create datestr column with fixed value. Something likeCREATE TABLE mydb.t2 ASSELECT  *,   '2019-08-24' as datestrFROM   mydb.t;Afterward, you register another dataset. For above example, mydb.t2. In the model training draft, specify 2019-08-24 to 2019-08-24 for training range."}
{"prompt": "Where I can find model configuration file for realtime prediction service? I want to check what models and deployment-tags labels for my project. Where I can find such information?", "completion": "One approach is to create datestr column with fixed value. Something likeCREATE TABLE mydb.t2 ASSELECT  *,   '2019-08-24' as datestrFROM   mydb.t;Afterward, you register another dataset. For above example, mydb.t2. In the model training draft, specify 2019-08-24 to 2019-08-24 for training range."}
{"prompt": "How can I keep running LambdaDL training job on remote GPU instances running after closing my laptop? If I train a DL model through DLJobContext on workbench, what's the best way to get the results back after the laptop closes?Will the connection will be kept active, and return the results to the notebook later upon completion?", "completion": "One approach is to create datestr column with fixed value. Something likeCREATE TABLE mydb.t2 ASSELECT  *,   '2019-08-24' as datestrFROM   mydb.t;Afterward, you register another dataset. For above example, mydb.t2. In the model training draft, specify 2019-08-24 to 2019-08-24 for training range."}
{"prompt": "How do I find size of my deployed Michelangelo model", "completion": "One approach is to create datestr column with fixed value. Something likeCREATE TABLE mydb.t2 ASSELECT  *,   '2019-08-24' as datestrFROM   mydb.t;Afterward, you register another dataset. For above example, mydb.t2. In the model training draft, specify 2019-08-24 to 2019-08-24 for training range."}
{"prompt": "Attempt to deploy PyML model to non-PyML online-prediction-service group", "completion": "pyML and certain DL models require launching nested container that hosts the model. Nested container support is only enabled for certain Michelangelo prediction services.Please contact oncall to change your project deployment setting. Note that there are certain restrictions for online pyML. See Michelangelo engdoc for information."}
{"prompt": "Michelangelo Prediction Service Palette Cassandra lookups in Jaeger I'm analyzing a Jaeger trace for Michelangelo feature store lookups. I don't see any Palette lookups in michelangelo-prediction-group5 trace. Does this mean there are no Palette Cassandra  lookups happening there? Or is it that palette feature store lookups are not connected to Jaeger trace.https:  jaeger-phx3.uberinternal.com trace c0c12eebe19a77a0", "completion": "The palette feature store lookups are not traced as of today. So you cannot determine from the trace whether it did or did not perform a cassandra lookup."}
{"prompt": "How can we get the latest deployed model by a deployment tag programmatically We will have a service which calls PredictionService::predict to get some predication. The model we use will be re-trained regularly e.g weekly or fortnightly . After training, the new model will be deployed then it got a new model id.How can we get the new model id programmatically if we have a deployment tag. Are there any RPC call that we can fetch the latest model id from?", "completion": "The palette feature store lookups are not traced as of today. So you cannot determine from the trace whether it did or did not perform a cassandra lookup."}
{"prompt": "Error in downloading prediction output as csv file", "completion": "The palette feature store lookups are not traced as of today. So you cannot determine from the trace whether it did or did not perform a cassandra lookup."}
{"prompt": "Access To Michelangelo Service we have a Michelangelo service running and we would like to be able to query access it from a GoFx backend service. Are there any libraries or examples on how to do this? We have been looking around and unsuccessful. Thank you for your help, Kaleidoscope team", "completion": "Please checkout https:  eng.uberinternal.com docs michelangelo user-guides realtime-predict-service.html for how to integrate with our realtime prediction service.https:  sourcegraph.uberinternal.com search?q=michelangelo-gateway+lang:go+ has some Golang examples for call the service."}
{"prompt": "Why doesn't my model show performance, vis and features after completing training? I've trained a couple of models on my data. They show as complete, but when I try to view the performance, visualization, and features pane the loading hangs forever.", "completion": "Please checkout https:  eng.uberinternal.com docs michelangelo user-guides realtime-predict-service.html for how to integrate with our realtime prediction service.https:  sourcegraph.uberinternal.com search?q=michelangelo-gateway+lang:go+ has some Golang examples for call the service."}
{"prompt": "michelangelo data prep very slow I'm backfilling data for a new Michelangelo project and the data prep is taking extremely long  the first day of two weeks has already taken nearly 3 hours . Is there any way to see if there's anything going wrong?Also, I have plenty of capacity in my YARN queue, but it seems to me that you can't backfill multiple days simultaneously?", "completion": "Please checkout https:  eng.uberinternal.com docs michelangelo user-guides realtime-predict-service.html for how to integrate with our realtime prediction service.https:  sourcegraph.uberinternal.com search?q=michelangelo-gateway+lang:go+ has some Golang examples for call the service."}
{"prompt": "What's the List<Map> looks like in Michelangelo BYOM predict interface Just want to understand the predict interface in Michelangelo BYOM. The predict interface takes a List<Map<String, Object>>, is the palette aliasName will be sent as a key in the List or a portion of the the aliasName will be sent?for example:  @palette:trip:arnold_features:comment:incident_uuid  will be this the key or just the   comment ?", "completion": "Please checkout https:  eng.uberinternal.com docs michelangelo user-guides realtime-predict-service.html for how to integrate with our realtime prediction service.https:  sourcegraph.uberinternal.com search?q=michelangelo-gateway+lang:go+ has some Golang examples for call the service."}
{"prompt": "How can I mark a hive table column as categorical? I'm trying to add https:  toolshed.uberinternal.com big-table-explorer hive u4b.auto_audit as a data source Michelangelo said it contained unsupported data types.Can I mark some columns as categorical when adding a hive table as data source? Additionally, can I ignore some of the columns?Thanks,Bian", "completion": "Please checkout https:  eng.uberinternal.com docs michelangelo user-guides realtime-predict-service.html for how to integrate with our realtime prediction service.https:  sourcegraph.uberinternal.com search?q=michelangelo-gateway+lang:go+ has some Golang examples for call the service."}
{"prompt": "Undefined Error when Creating a new model", "completion": "Please checkout https:  eng.uberinternal.com docs michelangelo user-guides realtime-predict-service.html for how to integrate with our realtime prediction service.https:  sourcegraph.uberinternal.com search?q=michelangelo-gateway+lang:go+ has some Golang examples for call the service."}
{"prompt": "Michelangelo databackfill error", "completion": "Please checkout https:  eng.uberinternal.com docs michelangelo user-guides realtime-predict-service.html for how to integrate with our realtime prediction service.https:  sourcegraph.uberinternal.com search?q=michelangelo-gateway+lang:go+ has some Golang examples for call the service."}
{"prompt": " The stats for the given feature is either missing or is empty.  error during model training", "completion": "Please checkout https:  eng.uberinternal.com docs michelangelo user-guides realtime-predict-service.html for how to integrate with our realtime prediction service.https:  sourcegraph.uberinternal.com search?q=michelangelo-gateway+lang:go+ has some Golang examples for call the service."}
{"prompt": "API method to retrieve Michelangelo model ID? I am trying to schedule a Michelangelo training job from MLExplorer, afterwards I have a DSW notebook to retrieve the model ID from the regularly run MA training job. It could have multiple models, and I need the recent model Id. What would be the API to do that? The given input would be project id, model template id.", "completion": "Please checkout https:  eng.uberinternal.com docs michelangelo user-guides realtime-predict-service.html for how to integrate with our realtime prediction service.https:  sourcegraph.uberinternal.com search?q=michelangelo-gateway+lang:go+ has some Golang examples for call the service."}
{"prompt": "How can I change the scheduled Michelangelo data backfill and prediction time? Currently in Michelangelo, data backfill time is scheduled at 12pm UTC and prediction time is scheduled at 12:20pm UTC by default. Is there a way to edit this time?", "completion": "Please checkout https:  eng.uberinternal.com docs michelangelo user-guides realtime-predict-service.html for how to integrate with our realtime prediction service.https:  sourcegraph.uberinternal.com search?q=michelangelo-gateway+lang:go+ has some Golang examples for call the service."}
{"prompt": "What is the correct format for Michelangelo's monotonicity constraints parameter? I'm training a pair of GBT models  example  and I want each to have a guarantee that their predictions are monotonic w r t a particular feature  our decision variable . I specified the column from the feature list within the default parenthesized list but this is apparently not the appropriate format expected by Michelangelo as my sim failed. What is the right way to specify this?", "completion": "To specify the monotonicity of a feature relative to the predicted response, you provide an n-tuple with each entry denoting the monotonic constraint of a feature relative to the predicted response. The order is determined by the order you specify your features in the model template.Assuming your training data X has two columns features, and by specifying the parameter values  1,-1  we are telling XGBoost to impose an increasing constraint on the first predictor and a decreasing constraint on the second.Some other examples: 1,0 : An increasing constraint on the first predictor and no constraint on the second. 0,-1 : No constraint on the first predictor and a decreasing constraint on the second.Also, we will auto-fill 0s  no constraints  if you specified a tuple that has a size smaller than your feature list. For example, if your training data has 3 features and you specified the parameter values  1  for an increasing constraint on the first predictor, we will assume there is no constraint on the second and third predictors and auto-update the parameter value to  1,0,0 ."}
{"prompt": "Michelangelo Training error: ClassNotFoundException: org.tartarus.snowball.ext.PorterStemmer", "completion": "To specify the monotonicity of a feature relative to the predicted response, you provide an n-tuple with each entry denoting the monotonic constraint of a feature relative to the predicted response. The order is determined by the order you specify your features in the model template.Assuming your training data X has two columns features, and by specifying the parameter values  1,-1  we are telling XGBoost to impose an increasing constraint on the first predictor and a decreasing constraint on the second.Some other examples: 1,0 : An increasing constraint on the first predictor and no constraint on the second. 0,-1 : No constraint on the first predictor and a decreasing constraint on the second.Also, we will auto-fill 0s  no constraints  if you specified a tuple that has a size smaller than your feature list. For example, if your training data has 3 features and you specified the parameter values  1  for an increasing constraint on the first predictor, we will assume there is no constraint on the second and third predictors and auto-update the parameter value to  1,0,0 ."}
{"prompt": "Project must have an RFC with expected latency and QPS", "completion": "To specify the monotonicity of a feature relative to the predicted response, you provide an n-tuple with each entry denoting the monotonic constraint of a feature relative to the predicted response. The order is determined by the order you specify your features in the model template.Assuming your training data X has two columns features, and by specifying the parameter values  1,-1  we are telling XGBoost to impose an increasing constraint on the first predictor and a decreasing constraint on the second.Some other examples: 1,0 : An increasing constraint on the first predictor and no constraint on the second. 0,-1 : No constraint on the first predictor and a decreasing constraint on the second.Also, we will auto-fill 0s  no constraints  if you specified a tuple that has a size smaller than your feature list. For example, if your training data has 3 features and you specified the parameter values  1  for an increasing constraint on the first predictor, we will assume there is no constraint on the second and third predictors and auto-update the parameter value to  1,0,0 ."}
{"prompt": "Job failed without being able to report error my job failed without any detailed error message,  the job id is:  tm20180929-203050-SNVIVFHR ,  see screenshot below.Nothing shown under piper either: https:  piper.uberinternal.com ?search=michelangelo_wf_eats_graph_learning_backfill_DCA1_tm20180929-203050-SNVIVFHRowner=everyoneshow_backfills=False,any way I can do troubleshooting on this ?", "completion": "To specify the monotonicity of a feature relative to the predicted response, you provide an n-tuple with each entry denoting the monotonic constraint of a feature relative to the predicted response. The order is determined by the order you specify your features in the model template.Assuming your training data X has two columns features, and by specifying the parameter values  1,-1  we are telling XGBoost to impose an increasing constraint on the first predictor and a decreasing constraint on the second.Some other examples: 1,0 : An increasing constraint on the first predictor and no constraint on the second. 0,-1 : No constraint on the first predictor and a decreasing constraint on the second.Also, we will auto-fill 0s  no constraints  if you specified a tuple that has a size smaller than your feature list. For example, if your training data has 3 features and you specified the parameter values  1  for an increasing constraint on the first predictor, we will assume there is no constraint on the second and third predictors and auto-update the parameter value to  1,0,0 ."}
{"prompt": "Michelangelo gallery_util returning 403 We use gallery_util to download model content as followsmodel_content = gallery_util.download_model_blob_content PROJECT_ID, model.tmId, model.modelId, aws_access_key='' Internally, it looks like this uses S3 presigned URLs to obtain content. However, S3 returns 403:40832 2020-01-18 10:20:02,174 - urllib3.connectionpool - DEBUG - Starting new HTTP connection  1 : uber-michelangelo.s3.amazonaws.com:8040832 2020-01-18 10:20:02,678 - urllib3.connectionpool - DEBUG - http:  uber-michelangelo.s3.amazonaws.com:80  GET  projects MLMS_marketplace_forecasting trained_models tm20200106-184647-YFICOBNG-BTATUD tm20200106-184647-YFICOBNG-BTATUD.model?X-Amz-Algorithm=AWS4-HMAC-SHA256X-Amz-Credential=AKIAIUMC5NQNJAF47G7A%2F20200117%2Fus-east-1%2Fs3%2Faws4_requestX-Amz-Date=20200117T232001ZX-Amz-Expires=3600X-Amz-SignedHeaders=hostresponse-content-type=binary%2Foctet-streamX-Amz-Signature=7d0f46d315453118c5f911308709be0ff85e6b1ff2c089fb5ac915f6b255c602 HTTP 1.1  403 None", "completion": "To specify the monotonicity of a feature relative to the predicted response, you provide an n-tuple with each entry denoting the monotonic constraint of a feature relative to the predicted response. The order is determined by the order you specify your features in the model template.Assuming your training data X has two columns features, and by specifying the parameter values  1,-1  we are telling XGBoost to impose an increasing constraint on the first predictor and a decreasing constraint on the second.Some other examples: 1,0 : An increasing constraint on the first predictor and no constraint on the second. 0,-1 : No constraint on the first predictor and a decreasing constraint on the second.Also, we will auto-fill 0s  no constraints  if you specified a tuple that has a size smaller than your feature list. For example, if your training data has 3 features and you specified the parameter values  1  for an increasing constraint on the first predictor, we will assume there is no constraint on the second and third predictors and auto-update the parameter value to  1,0,0 ."}
{"prompt": "How to get access to Michelangelo if I'm a consultant? I need to use Michelangelo to do labeling work for ATG. What permission request do I need to submit?", "completion": "From permission manager, you need to request to be added to michelangelo-ext."}
{"prompt": "Why does michelangelo include a prediction|indexed_XYZ column for some basis features in the one-off prediction table? We have a michelangelo regression model  XGBoost .In the one-off prediction table, we see there are columns for our basis and derived features  basis|abc and derived|xyz , as we might expect.We also see how columns called prediction|indexed_XYZ where XYZ are some subset of our basis features.The data type of these columns is also not consistent with the original type  e.g. we always see float values where we might expect strings .What is the purpose of the prediction|indexed_XYZ columns?", "completion": "From permission manager, you need to request to be added to michelangelo-ext."}
{"prompt": "support large categorical features?", "completion": "From permission manager, you need to request to be added to michelangelo-ext."}
{"prompt": "How to get latest trained models from Michelangelo is there a way to get the latest trained models from Michelangelo for my project?", "completion": "From permission manager, you need to request to be added to michelangelo-ext."}
{"prompt": "Michelangelo training job failed due to out of memory errors Here is the error. I am using Hive data source and the training set has about 500M rows. Why does this error occur and how can I fix it?", "completion": "From permission manager, you need to request to be added to michelangelo-ext."}
{"prompt": "How do we determine the best model from AutoTune? I've run several training jobs with AutoTune. How do I determine the best model? Is there an API?", "completion": "Note that currently Michelangelo doesn't support validation dataset when evaluating models. Thus, one needs to be careful when comparing model accuracy across models. See T4256531. There are several ways to work around this.Use holdout customized  in training filter  or split key to ensure where the training and test datasets are fixed. If you are using split key, please make sure the corresponding column doesn't have null nor empty value. Ideally, the column should be boolean or integer. Please don't string values such as uuid, driver_uuid, trip_uuid, etc since it may cause OOM problem during sorting.Use backtesting and evaluation framework to perform offline analysis.Note that if you are using HotStart, the best model within a given run may not be the best. If your data distribution changes frequently, HotStart may not provide the right optimization as well  given the underlying assumption is the distribution is roughly the same .We've showed that under certain situations that running AutoTune with smaller randomized dataset and full dataset will reach the same optimal hyper-parameters. See here for more information.See example notebook for determining the models with highest training AUC, test AUC, and smallest  training AUC - test AUC . Note that if training AUC >> test AUC, you have a overfitted model.  You may want to try adding regularization, reduce model complexity, and or training with more data. See here for how to deal with bias and variance.  Note that the notebook uses Gallery API, which store model performance with 2-decimal points."}
{"prompt": "cannot deploy pyml model in the experimental pool; user-virtual-shard-not-supported", "completion": "We recently have bad code deploy, which causes dynamic virtual shard deployment failures. We have fixed that issue, and deployed to production.If you retry your deployment, it should be able to succeed.Your project is set up as group29, which is a dynamic sharding group."}
{"prompt": "How to implement complex derived features on uFlow and or Michelangelo?", "completion": "We recently have bad code deploy, which causes dynamic virtual shard deployment failures. We have fixed that issue, and deployed to production.If you retry your deployment, it should be able to succeed.Your project is set up as group29, which is a dynamic sharding group."}
{"prompt": "How to create partitioned model for online prediction on Michelangelo What should I do if I want to use the same model template and train different models for different cities  partition by city_id ?Should I prepare the data source as before  only partition data by datestr  and then include city_id as the column. Then in the model template setup, add the city_id as the partition in CREATE PARTITIONS section?Thanks!", "completion": "We recently have bad code deploy, which causes dynamic virtual shard deployment failures. We have fixed that issue, and deployed to production.If you retry your deployment, it should be able to succeed.Your project is set up as group29, which is a dynamic sharding group."}
{"prompt": "Date shift between train and predict for feature palette in Michelangelo batch prediction I tried to use feature palette for my batch prediction project and want to understand the way we do date shift with DSL in feature palette.Assume we provide a training data table with datestr as the label date  every Sunday , and the latest feature we can use is 14 days ago  due to constraints in reality . Then we would use following DSL:nFill nVal  @palette:rider:bonding_v2:log_lifetime_trips:rider_uuid:14  ,0 The question is how would this apply to prediction job? If we prepare prediction table using predict date as datestr  not label date in training table, basically predict_date = date_sub label_date, 14  , then we would use 14 days even before the predict date, instead of using the latest available feature.I guess the solution is to make datestr definition consistent across training table and prediction table  either both using label date or prediction date .Am I right here? Any other easy way to solve this issue?Thanks!", "completion": "We recently have bad code deploy, which causes dynamic virtual shard deployment failures. We have fixed that issue, and deployed to production.If you retry your deployment, it should be able to succeed.Your project is set up as group29, which is a dynamic sharding group."}
{"prompt": "Getting asset not found when adding new data source", "completion": "Michelangelo recently changed from ublame to uown and the team name in the project setting may be incorrect."}
{"prompt": "HDFSError - Failed to obtain user group information when trying to access secure hdfs cluster from MA hosts", "completion": "Inside the docker, you can directly use some hdfs python client, such as pydoop.hdfs. It handles delegation token for you once the token is installed. Please let me know if it works for you."}
{"prompt": "Michelangelo spark job failed with error message: container is running beyond physical memory limits", "completion": "Inside the docker, you can directly use some hdfs python client, such as pydoop.hdfs. It handles delegation token for you once the token is installed. Please let me know if it works for you."}
{"prompt": "Michelangelo data table missing in hive presto  Partition does not exist  When trying to pull my results from Presto on querybuilder, I get this error message. The time shown in the error  2017 10 10  is from a previously published model that was deleted.How can I get muy current published model to show in this table?", "completion": "Inside the docker, you can directly use some hdfs python client, such as pydoop.hdfs. It handles delegation token for you once the token is installed. Please let me know if it works for you."}
{"prompt": "Access to Michelangelo and Wiki", "completion": "Inside the docker, you can directly use some hdfs python client, such as pydoop.hdfs. It handles delegation token for you once the token is installed. Please let me know if it works for you."}
{"prompt": "Incompatible serialVersionUUID when using MichelangeloPySpark XGBoostRegressor", "completion": "Inside the docker, you can directly use some hdfs python client, such as pydoop.hdfs. It handles delegation token for you once the token is installed. Please let me know if it works for you."}
{"prompt": "NameSpace quota exceeding in Spark job I'm running a spark job in Michelangelo and it's failing as it exceeds a NameSpace quota.  This happens often and is not my NameSpace. What actions can I take to reliably avoid this issue?https:  shs-dca1.uberinternal.com history application_1583947361118_4199287 1 jobs job ?id=1", "completion": "Inside the docker, you can directly use some hdfs python client, such as pydoop.hdfs. It handles delegation token for you once the token is installed. Please let me know if it works for you."}
{"prompt": "Few questions about Palette for storing retrieving inferences", "completion": "Inside the docker, you can directly use some hdfs python client, such as pydoop.hdfs. It handles delegation token for you once the token is installed. Please let me know if it works for you."}
{"prompt": "getting error for one-off prediction job when running in a secured cluster get the following error:job = michelangelo.malib.spark_predict_run  executors=1, executor_cores=1, model_ids= tm20200114-185450-UGPTHLNF-LEWTJQ , datacenter= PHX2 , project= rfp_internal_cost , src_hive= freight_ml.top_account_lane_forecast_input_table , spark_queue= freight_ml , **jobs_config BackendException: 500 Internal Server Error - http:  127.0.0.1:5436  Failed to start prediction job on spark.error for service  michelangelo-deeplearning-jobs  and procedure  MichelangeloDeeplearningJobs::startSparkPrediction : Create request failed: Secure job missing Rpc-Header-X-Auth-Params-HDFS-DT header", "completion": "Note: Please be sure that you are using a recent michelangelo-python-client version to ensure that all support for secure cluster use is available.  The most recent version of MPC as of today is 0.6.124."}
{"prompt": "training data feature statistics", "completion": "Note: Please be sure that you are using a recent michelangelo-python-client version to ensure that all support for secure cluster use is available.  The most recent version of MPC as of today is 0.6.124."}
{"prompt": "How to use getFeatures in Palette? any reference implementation or example for getting feature from palette service via Palette::getFeatures?", "completion": "Note: Please be sure that you are using a recent michelangelo-python-client version to ensure that all support for secure cluster use is available.  The most recent version of MPC as of today is 0.6.124."}
{"prompt": "java.lang.StackOverflowError during model training: data transform", "completion": "Note: Please be sure that you are using a recent michelangelo-python-client version to ensure that all support for secure cluster use is available.  The most recent version of MPC as of today is 0.6.124."}
{"prompt": "Michelangelo Training sampling The datasource that I am using is heavily weighted towards 1-2 partitions  out of 4 , such those partitions have 90% of the data. So after max row count is applied, there is not enough training examples for the smaller partitions.Is there a way in Michelangelo to cap training examples per partition so that each partition has the same number of training examples?", "completion": "Note: Please be sure that you are using a recent michelangelo-python-client version to ensure that all support for secure cluster use is available.  The most recent version of MPC as of today is 0.6.124."}
{"prompt": "Seeing no peers available error when calling prediction service We are intermittently seeing the following error message in our call to Michelangelo:sharder peer list had no peers available for: michelangelo-prediction-group29:SVProof#tm20191021-212103-GFEGKZEI-CZFRKFModel has been deployed and these error are intermittent. What is the right way to go debugging them?", "completion": "this is because michelangelo-prediction-group29, which is used by pyml staging has 1 instance in each DC for each physical shard. currently there are two shards where DCA instances are down.Compute team is working on meso issue. Once it is resolved, we will restart those down instances."}
{"prompt": "#michelangelo always failed to split test and training data", "completion": "this is because michelangelo-prediction-group29, which is used by pyml staging has 1 instance in each DC for each physical shard. currently there are two shards where DCA instances are down.Compute team is working on meso issue. Once it is resolved, we will restart those down instances."}
{"prompt": "Michelangelo PyML Error within the container -  Response serialization error: expected bytes, int found  I get the following error within the PyML docker container while making the thrift predictionService call -Response serialization error: expected bytes, int foundWhat went wrong?", "completion": "Most likely, the problem is that the output pandas dataframe returned from the predict function of PyML class does not have string column names. It by default takes integer column names, which leads to interference with serialization. So, add proper string names to the columns returned."}
{"prompt": "Michelangelo Pyspark Model Pipeline Error - XGBoostModel Training Failed  java.lang.RuntimeException: you can only specify missing value as 0.0 ", "completion": "When using VectorAssembler in PySpark Pipeline with sparse features, you have to specify how XgBoost Model should handle missing values. In the XgBoost model params, add missing=0.0 explicitly.Source - https:  xgboost.readthedocs.io en latest jvm xgboost4j_spark_tutorial.html#dealing-with-missing-values"}
{"prompt": "Can michalengelo python API query which model is in deployed? I didn't see it in the docs, but can the michelangelo python client query which model in a project has been deployed?", "completion": "When using VectorAssembler in PySpark Pipeline with sparse features, you have to specify how XgBoost Model should handle missing values. In the XgBoost model params, add missing=0.0 explicitly.Source - https:  xgboost.readthedocs.io en latest jvm xgboost4j_spark_tutorial.html#dealing-with-missing-values"}
{"prompt": "How do I use Queryrunner in an Opus GPU or Michelangelo session? How can  I use Queryrunner in an Opus GPU or Michelangelo session.", "completion": "Answer from DSW teamUpgrade queryrunner > 1.3.2 for Python 2; queryrunner = 0.9.5-rc13 for Python3qr = Client user_email='',             qr_port=80,              qr_host='queryrunnerclient.dca1',              query_result_host='queryresult.dca1',              query_result_port=80 If you run into 403 forbidden URL error, please add the following line before you call query runner:start_adhoc_tracer 'workbench', config= 'tags':  'dsw_job_id': 'test'   Choose a different dsw_job_id for a different notebook"}
{"prompt": "Is it possible to switch data centers in a PySpark session with DSW? How can I switch data centers in a PySpark session with DSW", "completion": "Answer from DSW teamDSW currently does not have a feature for switching data centers in a PySpark session. However, you can try this workaround:Edit  .local share jupyter kernels pyspark kernel.json to use the desired data center  change sjc1 to dca1, or vice versa .Open a new kernel to pick it up the change."}
{"prompt": "Publish results failed - how to 'drop the older Hive table'?", "completion": "Answer from DSW teamDSW currently does not have a feature for switching data centers in a PySpark session. However, you can try this workaround:Edit  .local share jupyter kernels pyspark kernel.json to use the desired data center  change sjc1 to dca1, or vice versa .Open a new kernel to pick it up the change."}
{"prompt": "What is the syntax for training and test filters on Michelangelo? When  Train Test Split Strategy  is specified as  holdout-custom , is there a doc on the correct syntax for the training and test filters there?For example, if we have  datestr  and  city_id  as the basis features, is the following syntax correct? @basis:datestr >= '2018-04-14'  AND  @basis:city_id IN  27,134,20,40,24,190  ", "completion": "Answer from DSW teamDSW currently does not have a feature for switching data centers in a PySpark session. However, you can try this workaround:Edit  .local share jupyter kernels pyspark kernel.json to use the desired data center  change sjc1 to dca1, or vice versa .Open a new kernel to pick it up the change."}
{"prompt": "Michelangelo custom holdout does not recognize column When I try to use hold-out-custom for Train Test Split Strategy, the column that I use for the train and test filters is not recognized. here is the model.You can see that temporal_train_test is not recognized, even though it's one of the basis input columns. I have tried the following syntax for Training Filter and Test Filter:temporal_train_test = 'train'@basis:temporal_train_test = 'train' @basis:temporal_train_test  = 'train'Any help would be appreciated. Thanks!", "completion": "Answer from DSW teamDSW currently does not have a feature for switching data centers in a PySpark session. However, you can try this workaround:Edit  .local share jupyter kernels pyspark kernel.json to use the desired data center  change sjc1 to dca1, or vice versa .Open a new kernel to pick it up the change."}
{"prompt": "What would be the most practical ways to use near realtime features outside michelangelo Michelangelo makes it very easy to use the near realtime features  NRF , good job guys! However, I would like to do some analysis using workbench, and wonder what would be the easiest way to use NRF. Say for example, I have a table with column A the restaurant uuid, and column B prediction timestamp, I would like to get the restaurant average of preparation time in the last 10 minutes. Here is what I would do on Michelangelo:prep_time_last_10min: nFill nVal  @palette:store:orders_realtime:at_prep_finished__from_order_accepted_to_prep_finished_count_10min:rs_uuid:order_created_at_epoch_seconds  ,0.0 Thanks in advance!", "completion": "One way is to load the underlying hive table into your notebook directly. I saw there is a table michelangelo.store_orders_realtime in hive. In your notebook,from pyspark.sql import HiveContexthc = HiveContext sc table_name =  michelangelo.store_orders_realtime df = hc.table table_name df.printSchema  "}
{"prompt": "Failure to import pydoop.hdfs on a sparkmagic notebook Following the instructions given in https:  engdocs.uberinternal.com michelangelo user-guides michelangelo-pyspark.html, I created a sparkmagic notebook. Before creating the notebook, I installed pydoop on terminal using install_package_python2.sh pydoop and it was successfully installed.After creating a sparkmagic notebook and creating the session, when I try to import pydoop.hdfs I get this error:No module named pydoop.hdfsTraceback  most recent call last :ImportError: No module named pydoop.hdfs", "completion": "Packages installed in this way are available on the DSW machine, but not on the remote machines... but the remote machines are where the import is happening!So you need to follow these instructions to bundle up the packages you want, then add them to the  Python Files  section of the configuration.You can also make it easier to save this configuration by executing it from your notebook with the %%configure magic."}
{"prompt": "Michelangelo prediction failed with error  org.apache.spark.SparkException: Job aborted. ", "completion": "Packages installed in this way are available on the DSW machine, but not on the remote machines... but the remote machines are where the import is happening!So you need to follow these instructions to bundle up the packages you want, then add them to the  Python Files  section of the configuration.You can also make it easier to save this configuration by executing it from your notebook with the %%configure magic."}
{"prompt": "Training data not matched in partitioned model I have one model here and it's partitioned based on city_id. After training, I download the data from the DOWNLOAD TRAINING DATA button and compare it with the Hive data source used to train the model. The data is not matched between these 2 sources.My table is on rider level  rider_id as the primary key . Comparing the query from original Hive source and query from trained model data downloaded, for the same rider_id, all features and score response  are different.I also include the screen shot for the data comparison, _x is from original source, and _y is from data downloaded.I don't have such issue when model is not partitioned. Any idea what happens here?", "completion": "Packages installed in this way are available on the DSW machine, but not on the remote machines... but the remote machines are where the import is happening!So you need to follow these instructions to bundle up the packages you want, then add them to the  Python Files  section of the configuration.You can also make it easier to save this configuration by executing it from your notebook with the %%configure magic."}
{"prompt": "how do we weight recent data more in xgboost? I see this post mentioned we can use xgboost weighted functionality if there is a column. How do we weight recent data more if we don't have such column?", "completion": "If you have a epoch time column, you can do something liketimedecay:  nFill nVal @basis:timestamp , 1579766400  - 1579766400  2592000.0If you want to weight using stepwise date function, you can do something liketimedecay: getDateDecayWeight sVal @basis:datestr ,  2020-06-04 ,  2020-06-20  where 2020-06-04 and 2020-06-20 are training date range.We are working on a diff so that you can do something liketimedecay: getISODateDecayWeight utcToLocalWithLatLon sVal  @basis:prediction_ts  , nVal  @basis:requestedbegin_lat  , nVal  @basis:requestedbegin_lng   , 1589353200, 1593068400 where 1589353200 and 1593068400 are the the corresponding epochs for start and end of training date range."}
{"prompt": "Michelangelo joinKey in PredictionRequest not written to Hive We are passing in a joinKey to Michelangelo but I found that for single model prediction requests, this key doesn't get published to Kafka HIVE. However, calling MultiModelPredict successfully logs the field.It looks like the publisher takes the join key from the prediction's Observation, which isn't set for the single model endpoint. Was this an intentional decision? It would be helpful to be able to join all prediction requests with our own tables rather than just multi model batch requests.", "completion": "joinKey is simply for the purpose of logging, and it should be logged for the single prediction endpoint. We will make a fix to start logging it in single prediction endpoint.joinKey: [optional] the value corresponding to the column joining yourfeature query and target query. You specified this when setting upyour data pipeline. Sending joinKey causes a sample of yourpredictions to be logged for model performance monitoring.Update: the corresponding issue is fixed and deployed to production"}
{"prompt": "How to debug thrift error to PredictionService", "completion": "You service name is wrong, the service name should 'michelangelo-gateway'.Also please the shard key in prediction option like the following examplehttps:  sourcegraph.uberinternal.com code.uber.internal rds  - blob gateway michelangelo michelangelo.go#L90"}
{"prompt": "How can I run a trained Keras model with Spark and Scala? I have a trained Keras model hosted in HDFS.I know how to run it with PySpark and DSW but it would be better for us to run it on Drogon with Scala", "completion": "You service name is wrong, the service name should 'michelangelo-gateway'.Also please the shard key in prediction option like the following examplehttps:  sourcegraph.uberinternal.com code.uber.internal rds  - blob gateway michelangelo michelangelo.go#L90"}
{"prompt": "Specify sample weight in Michelangelo training job Is there any ways to specify the training sample weight in Michelangelo models? For example in Xgboost, they provide such API to pass in sample weight.", "completion": "You service name is wrong, the service name should 'michelangelo-gateway'.Also please the shard key in prediction option like the following examplehttps:  sourcegraph.uberinternal.com code.uber.internal rds  - blob gateway michelangelo michelangelo.go#L90"}
{"prompt": "MA training job failed with server too busy", "completion": "You service name is wrong, the service name should 'michelangelo-gateway'.Also please the shard key in prediction option like the following examplehttps:  sourcegraph.uberinternal.com code.uber.internal rds  - blob gateway michelangelo michelangelo.go#L90"}
{"prompt": "How to clone a specific hive table partition into a new table? I want to copy a table's specific partition into a new table but with different partition. Is the an easy way to do this?", "completion": "First you  clone  the table:CREATE TABLE michelangelo.dispatch_rider_cancel_lite LIKE intelligent_dispatch.dispatch_rider_cancel_v3_daily_v1;Insert-select a given partitionINSERT OVERWRITE TABLE michelangelo.dispatch_rider_cancel_lite PARTITION datestr SELECT * FROM intelligent_dispatch.dispatch_rider_cancel_v3_daily_v1WHERE datestr = '2020-08-16';Rename you partitionALTER TABLE michelangelo.dispatch_rider_cancel_lite PARTITION  datestr='2020-08-16'  RENAME TO PARTITION  datestr='2018-06-26' ;"}
{"prompt": "How do I enforce label's schema update in a Michelangelo project? I'm seeing error Model is not compatible with label schema when trying to deploy my model to an existing label. How do I enforce the change of schema on the label and deploy my model?", "completion": "First you  clone  the table:CREATE TABLE michelangelo.dispatch_rider_cancel_lite LIKE intelligent_dispatch.dispatch_rider_cancel_v3_daily_v1;Insert-select a given partitionINSERT OVERWRITE TABLE michelangelo.dispatch_rider_cancel_lite PARTITION datestr SELECT * FROM intelligent_dispatch.dispatch_rider_cancel_v3_daily_v1WHERE datestr = '2020-08-16';Rename you partitionALTER TABLE michelangelo.dispatch_rider_cancel_lite PARTITION  datestr='2020-08-16'  RENAME TO PARTITION  datestr='2018-06-26' ;"}
{"prompt": "When I try to compare two models I get an region and cluster don't match error Details:*errors.Error Error Code: INTERNAL_SERVER_ERROR, Message: region DCA and cluster phx4 prod02 in computeInfo don't match, StatusCode: 500,Stack: region DCA and cluster phx4 prod02 in computeInfo don't match Models I am trying to compare are here", "completion": "Please make sure the resource pool matches DC region  PHX or DCA  for your job.Peloton cluster phx4 prod02 is in PHX.For training job, you can override the project setting in template advanced setting. For example, . You can specify Yarn Peloton and yarn queue or Peloton cluster  pool."}
{"prompt": "Adding published fields for Michelangelo requires a retrain", "completion": "I see you are adding new palette features into published fields that are not in the DSL, which cause the model validation to fail.For this kind of case, you need to update the template and train the model again.You can see the exception stack trace documented in this tickethttps:  t3.uberinternal.com browse MA-4578"}
{"prompt": "How do I clone a Michelangelo Model and Train it for Debugging Purposes? I want to clone a model and train it to debug weirdness in the original model's output", "completion": "I see you are adding new palette features into published fields that are not in the DSL, which cause the model validation to fail.For this kind of case, you need to update the template and train the model again.You can see the exception stack trace documented in this tickethttps:  t3.uberinternal.com browse MA-4578"}
{"prompt": "How to change log configuration for peloton jobs", "completion": "I see you are adding new palette features into published fields that are not in the DSL, which cause the model validation to fail.For this kind of case, you need to update the template and train the model again.You can see the exception stack trace documented in this tickethttps:  t3.uberinternal.com browse MA-4578"}
{"prompt": "Unable to create template or train an existing model in Michelangelo", "completion": "I see you are adding new palette features into published fields that are not in the DSL, which cause the model validation to fail.For this kind of case, you need to update the template and train the model again.You can see the exception stack trace documented in this tickethttps:  t3.uberinternal.com browse MA-4578"}
{"prompt": "Michelangelo Data Source Creation:  Hive table not found  error? While creating a data source in Michelangelo, I see an error which says  Hive table not found , however, my table does exist in at least one datacenter  I created minutes ago . Why is this happening?", "completion": "Your table might be present in the datacenter, but Michelangelo relies on uMetaData to probe if a table exists or not. The uMetaData service works by a batch job with a periodicity of around 4hrs typically, hence, it should correctly identify a newly created table every 4 hours or so. Hence, try again after some time.Additionally, to check what uMetaData is giving as a result for your table, you can check out this studio call -https:  studio.uberinternal.com requests d5c1e216-feba-40bb-b7d1-213040ed2f1e"}
{"prompt": "PyML XgBoost Library  libxgboost.so  could not be loaded While creating a PyML Michelangelo model, I am getting the following XgBoost error while loading the model file to pyml folder in DSW", "completion": "This is happening because the xgboost library faces some issues while getting imported in the pyml folder. To bypass this error, do the xgboost import explicitly at the beginning of the DSW notebook, and then the notebook would run as expected without any issuesfrom xgboost import XGBClassifier, Booster"}
{"prompt": "Training with Autotune status is  Unknown , how to diagnose? I started autotune training  EATS_ETD_Prediction_Eyeball tm20201008-140945-FNJMYGAV  but it says that status is Unknown, how do I diagnose this issue?", "completion": "When running autotune, dont use # of iterations >= 40.The default of 100 doesnt work. the payload is too large for piper.Ticket to fix this: MA-5259"}
{"prompt": "While making Michelangelo batch predictions using Piper PredictionTask, I get  Job already scheduled  error While making Michelangelo batch predictions using Piper PredictionTask, I get  Job already scheduled  error -Error  'message': u'Job already scheduled: michelangelo_wf_CB_Representment_Stg1_BankerModel_backfill_PHX2_run_3bb62aa06', 'code': u'user-job-already-scheduled', 'stack': u'*errors.errorString Job already scheduled: michelangelo_wf_CB_Representment_Stg1_BankerModel_backfill_PHX2_run_3bb62aa06\ncode.uber.internal data michelangelo-api errors error_utils.go:30  0x177ffb3 \ncode.uber.internal data michelangelo-api services prediction_service.go:371  0x1cff08a \ncode.uber.internal data michelangelo-api services prediction_service.go:276  0x1cfe36a \ncode.uber.internal data michelangelo-api handlers apis prediction.go:201 .......If I What is going wrong here?", "completion": "Typically when you see this error, another prediction job might already be running for that date for your model, either by Piper or by manual tigger in the UI. To run the piper prediction task again for whatever reason, you first need to cancel the one already running.To do that, go to your michelangelo project on michelangelo UI, go to Predictions tab on the left-bottom, and manually cancel the predictions already running. Re-run the piper job and you should not see the error anymore!"}
{"prompt": "How is MES model accuracy computed? For binary classification, I know we are using AUC. However, for regression model, how is model's accuracy defined? We are using R^2, RMSE, or MAE?", "completion": "for regression models to match with binary classification accuracy,we do  1 - nrmse *100% with 1 being the best. so if nrmse is 0.589 => 1 - 0.589 should be around 0.411.from the uMonitor query, one can seenrmse_stddev_metric = fetch  service:michelangelo-rest  name:model_accuracy  data_type: test  accuracy_metric_name: nrmse_stddev  project_id:eats_netinflow_optimization  | removeAboveValue 1  | removeEmpty  | offset -1 | abs;"}
{"prompt": "How is prediction performance computed for regression models in MES?", "completion": "The MES prediction performance notebook can be found here. We computenormalized_rmse from MSE, R2,  RMSE using the following equations.stddev = math.sqrt mse max  1-r2 , 0.001  normalized_rmse = rmse    multiplier * stddev  Note that we've renamed prediction accuracy to prediction performance because we want to provide the flexibility to track model specific business KPI or metric. See here for onboarding doc. For example, for safety one may care about safety incidence rate, rather than AUC. For surge, one may care about market efficiency metric or other business metric than avg surge price."}
{"prompt": "Pip related error while running michelangelo predictions using Piper MaSparkPredictTask", "completion": "The problem was that the spark parameters I was using were overshooting the yarn limits. I was simply replicating the DSW notebook peloton parameters, while the piper task runs on Yarn which has lower resource thresholds.The following config worked for me  Initially I was using > 16 GB memory when it was erroring out 'number_executors': 25,'number_executor_cores': 1,'executor_memory': 9,'number_driver_cores': 1,'driver_memory': 9Additionally, the task trace still has some warning   error which says something about pip, but it is not a breaking issue and the task completes fine even while having itPS: The spark related error does not surface in the piper trace, and since the spark job did not even start in this case, there weren't any logs on DataCentral or Spark UICredit to @harshvardhan.s, @jins"}
{"prompt": "Retrieving logs of failed stopped Michelangelo jobs Is there a way I can retrieve those logs except from the Kubernetes page?I have 5 jobs which I just stopped and all of them have unavailable log in the Kubernetes.The jobs were started 2 days ago", "completion": "The problem was that the spark parameters I was using were overshooting the yarn limits. I was simply replicating the DSW notebook peloton parameters, while the piper task runs on Yarn which has lower resource thresholds.The following config worked for me  Initially I was using > 16 GB memory when it was erroring out 'number_executors': 25,'number_executor_cores': 1,'executor_memory': 9,'number_driver_cores': 1,'driver_memory': 9Additionally, the task trace still has some warning   error which says something about pip, but it is not a breaking issue and the task completes fine even while having itPS: The spark related error does not surface in the piper trace, and since the spark job did not even start in this case, there weren't any logs on DataCentral or Spark UICredit to @harshvardhan.s, @jins"}
{"prompt": "How to handle exception in DSL? I've a function that may throw exception. How do I prevent it to crash?", "completion": "for example, Marketplace.hexDistance   may throw exception such as  Distance not defined between the two indexes.  According to the documentation, the following conditions will cause exceptionThe indexes are not comparable  difference resolutions, etc The distance is greater than the H3 core library supportsThe H3 library does not support finding the distance between the two cells, because of pentagonal distortion.There are two approaches. You can wrap the function in the try-catch or use safeGet   which will return null if there is an exception. You will need to apply scala casting asInstanceOf[] such ashexdist_5: nFill safeGet Marketplace.hexDistance nVal @basis:requestedend_lat , nVal @basis:requestedend_lng , nVal @basis:requestedbegin_lat , nVal @basis:requestedbegin_lng , 5  .asInstanceOf[Double], 0 "}
{"prompt": "How can I set required CPU Memory with the Michelangelo tool? I would like to set the required memory and number of cpus for my michelangelo job.With ma train tf docker I don't see this option.How could I set it?", "completion": "for example, Marketplace.hexDistance   may throw exception such as  Distance not defined between the two indexes.  According to the documentation, the following conditions will cause exceptionThe indexes are not comparable  difference resolutions, etc The distance is greater than the H3 core library supportsThe H3 library does not support finding the distance between the two cells, because of pentagonal distortion.There are two approaches. You can wrap the function in the try-catch or use safeGet   which will return null if there is an exception. You will need to apply scala casting asInstanceOf[] such ashexdist_5: nFill safeGet Marketplace.hexDistance nVal @basis:requestedend_lat , nVal @basis:requestedend_lng , nVal @basis:requestedbegin_lat , nVal @basis:requestedbegin_lng , 5  .asInstanceOf[Double], 0 "}
{"prompt": "Syntax for accessing columns of hive table generated by one-off prediction job", "completion": "for example, Marketplace.hexDistance   may throw exception such as  Distance not defined between the two indexes.  According to the documentation, the following conditions will cause exceptionThe indexes are not comparable  difference resolutions, etc The distance is greater than the H3 core library supportsThe H3 library does not support finding the distance between the two cells, because of pentagonal distortion.There are two approaches. You can wrap the function in the try-catch or use safeGet   which will return null if there is an exception. You will need to apply scala casting asInstanceOf[] such ashexdist_5: nFill safeGet Marketplace.hexDistance nVal @basis:requestedend_lat , nVal @basis:requestedend_lng , nVal @basis:requestedbegin_lat , nVal @basis:requestedbegin_lng , 5  .asInstanceOf[Double], 0 "}
{"prompt": "How can I access the active probability from Michelangelo? the output variable nVal  @prediction:true   seems to be no longer working. Is there a way to output the probability of a prediction belonging to the active class in a classification model  XGBoost ?Thanks a lot,Quentin", "completion": "for example, Marketplace.hexDistance   may throw exception such as  Distance not defined between the two indexes.  According to the documentation, the following conditions will cause exceptionThe indexes are not comparable  difference resolutions, etc The distance is greater than the H3 core library supportsThe H3 library does not support finding the distance between the two cells, because of pentagonal distortion.There are two approaches. You can wrap the function in the try-catch or use safeGet   which will return null if there is an exception. You will need to apply scala casting asInstanceOf[] such ashexdist_5: nFill safeGet Marketplace.hexDistance nVal @basis:requestedend_lat , nVal @basis:requestedend_lng , nVal @basis:requestedbegin_lat , nVal @basis:requestedbegin_lng , 5  .asInstanceOf[Double], 0 "}
{"prompt": "Running tables in PHX The Data team is working on getting ready to run the whole Data stack with PHX as primary. We are currently midway through a failover drill and the Data stack is currently running in PHX. A Michelangelo customer raised this concern:one of the biggest issues CRM data operations have currently with PHX2failover and moving forward with PHX2 primary is that we rely onMichelangelo  machine learning  tables that are missing on PHX2.These Michelangelo tables are provided by Data Science teams fromdatabases like gauss and ds_marketing, some have owners and some donot.  Do you have a way to contact all Michelangelo users to mitigatethis issue?Can you please provide guidance on how to manage these tables to get users to create these tables in PHX as well as DCA?", "completion": "for example, Marketplace.hexDistance   may throw exception such as  Distance not defined between the two indexes.  According to the documentation, the following conditions will cause exceptionThe indexes are not comparable  difference resolutions, etc The distance is greater than the H3 core library supportsThe H3 library does not support finding the distance between the two cells, because of pentagonal distortion.There are two approaches. You can wrap the function in the try-catch or use safeGet   which will return null if there is an exception. You will need to apply scala casting asInstanceOf[] such ashexdist_5: nFill safeGet Marketplace.hexDistance nVal @basis:requestedend_lat , nVal @basis:requestedend_lng , nVal @basis:requestedbegin_lat , nVal @basis:requestedbegin_lng , 5  .asInstanceOf[Double], 0 "}
{"prompt": "Not missing value imputation buttons when setting up model", "completion": "for example, Marketplace.hexDistance   may throw exception such as  Distance not defined between the two indexes.  According to the documentation, the following conditions will cause exceptionThe indexes are not comparable  difference resolutions, etc The distance is greater than the H3 core library supportsThe H3 library does not support finding the distance between the two cells, because of pentagonal distortion.There are two approaches. You can wrap the function in the try-catch or use safeGet   which will return null if there is an exception. You will need to apply scala casting asInstanceOf[] such ashexdist_5: nFill safeGet Marketplace.hexDistance nVal @basis:requestedend_lat , nVal @basis:requestedend_lng , nVal @basis:requestedbegin_lat , nVal @basis:requestedbegin_lng , 5  .asInstanceOf[Double], 0 "}
{"prompt": "How to get the threshold for realtime prediction request?", "completion": "for example, Marketplace.hexDistance   may throw exception such as  Distance not defined between the two indexes.  According to the documentation, the following conditions will cause exceptionThe indexes are not comparable  difference resolutions, etc The distance is greater than the H3 core library supportsThe H3 library does not support finding the distance between the two cells, because of pentagonal distortion.There are two approaches. You can wrap the function in the try-catch or use safeGet   which will return null if there is an exception. You will need to apply scala casting asInstanceOf[] such ashexdist_5: nFill safeGet Marketplace.hexDistance nVal @basis:requestedend_lat , nVal @basis:requestedend_lng , nVal @basis:requestedbegin_lat , nVal @basis:requestedbegin_lng , 5  .asInstanceOf[Double], 0 "}
{"prompt": "Create data source error: interface conversion: interface    is nil, not string When adding a data source to Michelangelo, I am getting this error:interface conversion: interface    is nil, not string", "completion": "This is happening because `Tier` is not set on the hive table. Please claim ownership of the hive table, and set the appropriate tier in databook:https:  databook.uberinternal.com datasets hive  your.hive_table  definitionfor example:https:  databook.uberinternal.com datasets hive uber_eats.store_storefront_relative_basketsize tier"}
{"prompt": "How can I auto-retrain a partitioned Model in Spark? Is it possible to build a partitioned Model in Spark, upload it to the Michelangelo UI and have it auto-retrain?", "completion": "Answer from MLE teamMLE can support the retrain. In MLE we have a model training task which trains a model based on a template and the data sources previously configured in Michelangelo. You can set up the cadence for this auto-train workflow in the MLE UI.View the doc here: https:  engdocs.uberinternal.com michelangelo user-guides mle-guides mle-automated-training.html"}
{"prompt": "The model is not found", "completion": "Your project is an offline project so these models were not deployed for online predictions. Can you retire the models and I can help switch it to online project."}
{"prompt": "which thrift to use for realtime prediction service We service: personalized-rt-offer-engine  are trying to make tchannel requests to michelangelo realtime prediction service. When I tried to list the thrifts, I got multiple of themcode.uber.internal data michelangelo                              1 year ago      -code.uber.internal data michelangelo-api                          3 weeks ago     -code.uber.internal data michelangelo-rest                         14 hours ago    -code.uber.internal infra michelangelo-go                          2 years ago     -Questions:Which is the recommended one to use? Also would appreciate if you can share what other thrifts are for.If we are only calling the realtime prediction service to get a score, is pulling predictionservice.thrift enough? Or is it recommended to pull all the thrifts under the folder?Thanks!", "completion": "Great questions.Which is the recommended one to use? Also would appreciate if you can share what other thrifts are for.code.uber.internal data michelangelo-rest is where all the authoritative IDLs for michelangelo services are stored. That's the one you should be using.If we are only calling the realtime prediction service to get a score, is pulling predictionservice.thrift enough? Or is it recommended to pull all the thrifts under the folder?Just pulling in predictionservice.thrift should be enough - but you may also need to pull in github.com uber tchannel meta.thrift, but will probably not need to use that thrift file in your code in anyway."}
{"prompt": "Job failed without being able to report error  for example out of memory exception ", "completion": "Great questions.Which is the recommended one to use? Also would appreciate if you can share what other thrifts are for.code.uber.internal data michelangelo-rest is where all the authoritative IDLs for michelangelo services are stored. That's the one you should be using.If we are only calling the realtime prediction service to get a score, is pulling predictionservice.thrift enough? Or is it recommended to pull all the thrifts under the folder?Just pulling in predictionservice.thrift should be enough - but you may also need to pull in github.com uber tchannel meta.thrift, but will probably not need to use that thrift file in your code in anyway."}
{"prompt": "Facing repeated errors with Xgboost training in Michelangelo- dmlc::Error related to src tree updater_histmaker.cc", "completion": "Turns out that this error was being thrown due to a few 'nan' values in my training set features.This excellent doc from the Michelangelo team was very helpful in debugging the issue - https:  docs.google.com document d 1qmHgcTrpTvTL6KIpZvlk_2bvyHW2RBD1_SzTbFXxUPw edit#heading=h.p6dw7c4zztp5This debug notebook mentioned on the above doc was helpful in finding which features had the nan values - https:  docs.google.com document d 1qmHgcTrpTvTL6KIpZvlk_2bvyHW2RBD1_SzTbFXxUPw edit#heading=h.13ainm326o4xThe actual feature dsl causing the error wasltd_completed_fare: log10 1 + nFill nVal  @palette:trip:request_v2:ltd_completed_fare_v2:trip_uuid  ,0  , where is there is a negative value of the feature, the log returns a nan since it is not valid for negative real numbers."}
{"prompt": "How should a thrift file look and how it can be loaded on the given path?", "completion": "Looks like you are trying to yab from a DSW session. I am not too sure if the thrift file   idl exists on dsw session, but alternatively you can yab from an Uber gateway machine or your local machine's terminal.For gateway machine, you can log in using ssh hadoopgw01-phx2 for instance, and then run the predict command same as above with a change to the idl path  usr share uber-idl code.uber.internal For local machine, you first need to run cerberus with michelangelo-gateway service onboarded, and then run the same command above with a small change to the idl path - idl code.uber.internal "}
{"prompt": "seeing this error when bazel build   platforms uber_eats homefeed_conversion_model ... : I've been seeing this error whenbazel build   platforms uber_eats homefeed_conversion_model ... :ERROR:  private var tmp _bazel_yun.hao 8790e05145138c2d6683e30f166c548f external com_google_protobuf BUILD:378:11: C++ compilation of rule '@com_google_protobuf  :protoc_lib' failed  Exit 1 : cc_wrapper.sh failed: error executing command external local_config_cc cc_wrapper.sh -U_FORTIFY_SOURCE -fstack-protector -Wall -Wthread-safety -Wself-assign -fcolor-diagnostics -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG ...  remaining 41 argument s  skipped I did bazel clean but it didn't help.", "completion": "Looks like you are trying to yab from a DSW session. I am not too sure if the thrift file   idl exists on dsw session, but alternatively you can yab from an Uber gateway machine or your local machine's terminal.For gateway machine, you can log in using ssh hadoopgw01-phx2 for instance, and then run the predict command same as above with a change to the idl path  usr share uber-idl code.uber.internal For local machine, you first need to run cerberus with michelangelo-gateway service onboarded, and then run the same command above with a small change to the idl path - idl code.uber.internal "}
{"prompt": "The testing data table was not saved to Hive table but model training is successful I have a model trained last night, but the testing data table was not present in Hive. The model ID istm20210609-012304-UVFCAMGR-KXBVand the test data table is -- Datacenter: PHX2", "completion": "Looks like you are trying to yab from a DSW session. I am not too sure if the thrift file   idl exists on dsw session, but alternatively you can yab from an Uber gateway machine or your local machine's terminal.For gateway machine, you can log in using ssh hadoopgw01-phx2 for instance, and then run the predict command same as above with a change to the idl path  usr share uber-idl code.uber.internal For local machine, you first need to run cerberus with michelangelo-gateway service onboarded, and then run the same command above with a small change to the idl path - idl code.uber.internal "}
{"prompt": "ml-repo: ERROR: An error occurred during the fetch of repository 'pypi_deps_data_michelangelo' during builds and runs I am getting failures at multiple places during builds and runs of various projects in the new canvas ml-repo. These are usually concluded with 'executor failed running ....', and on investigating them further, all these are connected to this source error in the trace -ERROR: An error occurred during the fetch of repository 'pypi_deps_data_michelangelo' during builds and runsWhat is wrong?", "completion": "Re-running the commands multiple times solved the error for me. I think it is connected to timeouts[Update]Michelangelo Team's official build fail issue resolutions - https:  codelabs.uberinternal.com ml 201?step=6"}
{"prompt": "Error while building ml-code repo  ERROR: Failed building wheel for horovod ", "completion": "Turns out I needed to just install cmake on my machine using brew install cmake"}
{"prompt": "Michelangelo Prediction Reproducibility", "completion": "Turns out I needed to just install cmake on my machine using brew install cmake"}
{"prompt": "Is there multi-arm bandit library for generic parameter tuning? Is there multi-arm bandit library   service for generic  non-model  parameter tuning?", "completion": "Turns out I needed to just install cmake on my machine using brew install cmake"}
{"prompt": "Bucketizer encountered NaN value Getting exceptionTo handle or skip NaNs, try setting Bucketizer.handleInvalid.\n\tat org.apache.spark.ml.feature.Bucketizer$.binarySearchForBuckets Bucketizer.scala:275 \n\tat org.apache.spark.ml.feature.MichelangeloBucketizer$$anonfun$scoreInstance$1.apply MichelangeloBucketizer.scala:117 \n\tat org.apache.spark.ml.feature.MichelangeloBucketizer$$anonfun$scoreInstance$1.apply MichelangeloBucketizer.scala:114 \n\tat scala.collection.IndexedSeqOptimized$class.foreach IndexedSeqOptimized.scala:33 \n\tat scala.collection.mutable.ArrayOps$ofRef.foreach ArrayOps.scala:186 \n\tat org.apache.spark.ml.feature.MichelangeloBucketizer.scoreInstance MichelangeloBucketizer.scala:114 \n\tat org.apache.spark.ml.MATransformer$$anonfun$scoreInstances$1.apply MATransformer.scala:31 \n\tat org.apache.spark.ml.MATransformer$$anonfun$scoreInstances$1.apply MATransformer.scala:31 \n", "completion": "To set handleInvalid in Canvas,you can add a param called handle_invalid in your app_def.yaml under the bucketizers section:EG:   app_def.yamlfeature_batch_bucketizers:    - name: QuantileDiscretizer      quantile_discretizer_args:        num_buckets_shared: 200      handle_invalid: keep      input_cols:There are 3 possible options for  handleInvalid   how to handle invalid entries containing NaN values : skip, keep, error  default .- 'skip'  filter out rows with invalid values - 'error'  throw an error - 'keep'  keep invalid values in a special additional bucket . Note that in the multiple column case, the invalid handling is applied to all columns. That said for 'error' it will throw an error if any invalids are found in any column, for 'skip' it will skip rows with any invalids in any columns, etc. "}
{"prompt": "Is there a way to do realtime prediction calibration? The market dynamic or user behavior pattern may change, is it possible to recalibrate prediction scores without retraining the model?", "completion": "You will need a mechanism to keep track of states or statistics and adjust prediction scores accordingly. For examples for post prediction calibration for Eats ETD or Maps ETA, see Prediction Calibration Framework.This can be done via Flink, AthenaX, or uMetric with Flink."}
{"prompt": "How to debug failing MLE pipeline?", "completion": "Errors in the MLE pipeline often get originated from other Uber services. Unfortunately, some Uber services don't provide a good description of the error in the response when it happens, hence we only see a generic error entry in the piper logs like below_Rendezvous of RPC that terminated with:    status = StatusCode.UNKNOWN    details =  Error Code: sys-error, Message: code:unknown, StatusCode: 599, Stack: *yarpcerrors.Status code:unknownsrc code.uber.internal data michelangelo-api errors error_utils.go:16  0x157cf27 src code.uber.internal data michelangelo-api errors error_utils.go:50  0x157d1ca src code.uber.internal data michelangelo-api gateways wfo_grpc.go:61  0x21a93ad src code.uber.internal data michelangelo-api gateways wfo_grpc.go:99  0x21a992c Given that, to get a better description of the error, we should look at the stack trace and find which service call caused the error in the first place. In your example, `wfo_grpc.go:99` gives us a hint that the error is coming from WFO  Workflow Orchestration  Service, CreateAndRunSession method.Next, we open WFO logs and narrow down the search with the appropriate time range, log level, and possibly other parameters. Here are WFO ERROR logs for your case. The root cause seems to be followingCannot found alias feature_prep_spec.source.hiveTable.end_date in workflow"}
{"prompt": "How to extract trained torch model from DLInferenceTransformer? How to extract trained torch model from DLInferenceTransformer corresponding to a model like DeepEtaProduction tm20211004-214124-APZULEXU ?I want to explore the model weights of the model.", "completion": "Find the model in terrablob replacing the project and model id in the pathDownload and extract the tarExplode model instructions provided in Runbook"}
{"prompt": "Schema not Available in model template", "completion": "Find the model in terrablob replacing the project and model id in the pathDownload and extract the tarExplode model instructions provided in Runbook"}
{"prompt": "Why is Michelangelo saying  Feature Table Not Found  despite the table being in Hive?", "completion": "Find the model in terrablob replacing the project and model id in the pathDownload and extract the tarExplode model instructions provided in Runbook"}
{"prompt": "is michelangelo-gateway supported by cerberus?", "completion": "Find the model in terrablob replacing the project and model id in the pathDownload and extract the tarExplode model instructions provided in Runbook"}
{"prompt": "Getting 403 Authentication error even with latest Drogon delegation token", "completion": "Find the model in terrablob replacing the project and model id in the pathDownload and extract the tarExplode model instructions provided in Runbook"}
{"prompt": "How can I specify data center used in spark_predict job? I am testing the one-off prediction feature as described in the example notebook. My data is in SJC, but it looks like the job is running in DCA and thus I am getting an empty dataset error.What do you think is the best way to resolve this? Can I specify the data center in the job config? I didn't see a parameter for that in the docs.Thanks!", "completion": "Find the model in terrablob replacing the project and model id in the pathDownload and extract the tarExplode model instructions provided in Runbook"}
{"prompt": "Weekly MA Batch Prediction Job Failure for Unknown Cause THe job in workflow here seems to continually fail no matter how many times I retry it. One of the traces is here . When I look at the attis job, it says APplicaiton Killed by User but I didnt do so. Attis link is here . Here is the Michaelangelo project as well - link", "completion": "Find the model in terrablob replacing the project and model id in the pathDownload and extract the tarExplode model instructions provided in Runbook"}
{"prompt": "Michelangelo PredictionService::batchPredict - How to correlate a request Observation to a response PredictionResult Michelangelo's PredictionService::batchPredict accepts a list of Observations and responds with the respective PredictionResults. How do I correlate the Observation passed in the batch request to the PredictionResult in the batch response? Is the order maintained across request and response?Also, can we rely on the language-specific clients  Go, Java  to maintain the order guarantee, if applicable?", "completion": "We keep the order of responses the same as the requests for batchPredict"}
{"prompt": "cannot deploy pyml model from dsw notebook", "completion": "We keep the order of responses the same as the requests for batchPredict"}
{"prompt": "Michelangelo error - An error has occurred while training to validate your training job", "completion": "We keep the order of responses the same as the requests for batchPredict"}
{"prompt": "What is the easiest way to check a Michelangelo model is deployed by its tag  label ?", "completion": "We keep the order of responses the same as the requests for batchPredict"}
{"prompt": "What is the recommended way to pass BasisFeatures when making prediction requests? When should we use binaryBasisFeatures and when to use basisFeatures for PredictionService::predict api calls to pass the basis features to the model?My model is currently a PyML model.Couldn't find any suggestion in the docs, hence asking on Stack for wider visibility.Reference: https:  sourcegraph.uberinternal.com code.uber.internal go-code - blob idl code.uber.internal data michelangelo-rest server predictionservice.thrift#L161", "completion": "The  scope rules are the same. For basis feature x, you can pass it as x or @basis:x."}
{"prompt": "How do I export a model trained using LambdaDL? I am training a TF model using LambdaDL. I need to save the model and copy it to my local after training. Tried a bunch of stuff but can't seem to find the saved model.Job Config:job_config = ldl.DLJobConfig zone='phx4-prod02', custom_docker='uber-usi ml-code-boolq:phx2-produ-1627558741-9290d', num_workers=1, num_gpus=1 Saving model:history = classifier_model.fit x=train_ds,                               validation_data=test_ds,                               epochs=epochs save_path =   tmp snowball_bert_1epoch tf.saved_model.save classifier_model, save_path Copying to local:mactx.copy_to_local ' tmp snowball_bert_1epoch', '.' This gives me an error sayingPermission denied, please try again.: Permission denied  publickey,password,keyboard-interactive .How can I get the saved model to my local from phx4-prod2?", "completion": "The  scope rules are the same. For basis feature x, you can pass it as x or @basis:x."}
{"prompt": "yab Michelangelo P2P predication service locally without remote server or cerberus", "completion": "Thanks for the question Jiamin. We're working on a long term solution for cerberus. In the meantime, you can use our tool to start a proxy locally.Upgrade to the latest opsctl versionbrew update  brew install opsctlbrew update  brew upgrade opsctlCreate tunnelopsctl service debug tunnel -p <endpoint-name>:<local-port>This will cause a listener on localhost:<local-port> that will forward to a random remote endpoint instance. Then, your yab request should use --peer localhost:<local-port> instead of --peer-list in the example here."}
{"prompt": "Does PyML work with Python 2 Notebook in workbench? Does PyML work with Python 2 Notebook in workbench?I have to use Generic DS Python 2 for another module. I installed PyML with%%bashinstall_package_python2.sh add pyml= >=0.1.67 but got the following error when importing, see screenshot", "completion": "Python 2.X is deprecated. Please switch to use Python 3 and pyml V2."}
{"prompt": "Has anyone tried H2O autom ml models using pyml ? I am trying to train a model using h2o package inside pyml trainjobcalss", "completion": "Python 2.X is deprecated. Please switch to use Python 3 and pyml V2."}
{"prompt": "Michelangelo Training Error: Cannot resolve column name", "completion": "Python 2.X is deprecated. Please switch to use Python 3 and pyml V2."}
{"prompt": "How to debug the issue of getting different online prediction results for the same input? We are seeing different prediction results for the same input. How do I debug this?", "completion": "If you are using label deployment-tag, not the same model will be used  unless there is only one model associated with the label . If you have multiple models, change to use a specific model.If your model has palette features, Cassandra can only guarantee eventual consistency. There could be palette feature caching and dispersal issue. To eliminate these factors, pass in all palette feature values. See How to generate a sample yab request for realtime prediction service? on how to generate yab payload from sample data.If you are getting different derived feature values, check your feature DSL. [Some  embedding could be doing random projection to speed up computation.]Be aware of the precision loss, especially for DNN. See https:  docs.google.com document d 1hDnJmCj8nx1VVcI4hHJ8V8irCIM6t-bbtFEdESGt-xE edit#"}
{"prompt": "Getting Authentication Failed for sourcegraph I am trying to deploy ML model on Michelangelo by referring this document.But whenever I run the command git clone ``https:  sourcegraph.uberinternal.com code.uber.internal data sparkdockerit's asking for username and password.So I entered OneLogin but it's throwing an errorfatal: Authentication failed for 'https:  sourcegraph.uberinternal.com code.uber.internal data sparkdocker '", "completion": "Can you try this command instead for cloning the repo?git clone :data sparkdocker"}
{"prompt": "Online Score Drift from Baseline alerting and generating false positives", "completion": "Configure to use historical baseline rather than training baseline to get around the specific alert you received. reference:NRT monitoring doc"}
{"prompt": "How do I target Peloton cluster-zone phx3-prod02 for MLE retraining?", "completion": "Raajay Viswanathan  8 hours agoYou can specify the zone in the config right?Hwamin Kim:bulb:  8 hours agoYes, in the config project.yaml file, I can specify themSam Chan  8 hours agoahhh i cHwamin Kim:bulb:  4 hours agoI tried that settings, but got an failure on WFO side. Drogon cluster phx3 pelotonsecure not recognized. Error. Piper Jobjava.util.concurrent.CompletionException: java.lang.UnsupportedOperationException: Drogon cluster phx3 pelotonsecure not recognized.    at java.base java.util.concurrent.CompletableFuture.encodeThrowable CompletableFuture.java:314     at java.base java.util.concurrent.CompletableFuture.completeThrowable CompletableFuture.java:319     at java.base java.util.concurrent.CompletableFuture$UniCompose.tryFire CompletableFuture.java:1081     at java.base java.util.concurrent.CompletableFuture$Completion.run CompletableFuture.java:478     at java.base java.lang.Thread.run Thread.java:829 Caused by: java.lang.UnsupportedOperationException: Drogon cluster phx3 pelotonsecure not recognized.    at com.uber.michelangelo.wfo.oss.ClusterConfig.fromArguments ClusterConfig.java:150     at com.uber.michelangelo.wfo.oss.PiperSessionGateway.buildPartialPipeline PiperSessionGateway.java:403     at com.uber.michelangelo.wfo.oss.PiperSessionGateway.submit PiperSessionGateway.java:117     at com.uber.michelangelo.workflowservice.service.SessionServiceImpl.handleSession SessionServiceImpl.java:226     at java.base java.util.concurrent.CompletableFuture$UniCompose.tryFire CompletableFuture.java:1072     ... 2 common frames omittedRaajay Viswanathan  4 hours agotry with phx2. Since spark automatically maps phx2 to phx3. Did you already try this?NewHwamin Kim:bulb:  4 hours agoregion: phx and zone: phx2 config with  maps_data maps_trueta queue working fine  so far.Hwamin Kim:bulb:  4 hours agoThough it's little bit confusing, but fixed the missing queue issue. thank you so muchSam Chan  2 minutes agothanks much @raajay"}
{"prompt": "how can I add a non-production tag to this model? I've a model is only is experiment non-production state. How do I tag realtime prediction service calls as non-production?", "completion": "See predictionservice.thrift. You can set TrafficType in the request. You can also use deployment tag. See https:  engdocs.uberinternal.com michelangelo user-guides deployment-tags.html?highlight=shadowenum TrafficType      PRODUCTION = 0,    TEST = 1,    SHADOW = 2,    EXPERIMENT = 3,    HOLDOFF = 4,       Reserved for Michelangelo service internal use    AUTOSHADOW = 5 ...struct PredictionRequest       next id: 13  1: optional string projectId,     Model id can be either raw model id or model alias  2: optional string modelId,     note: only one of basisFeatures or binaryBasisFeatures should be used at a time  3: optional list<ValueItem> basisFeatures,  4: optional string label,  5: optional string joinKey,  6: optional bool returnTransformedFeatures,  7: optional bool testTraffic,     note: binary format features  currently, only supported by containerized models   8: optional binary binaryBasisFeatures,  9: optional EncodingType binaryBasisFeaturesEncodingType,     note: when true the request is always logged  10: optional bool sampleRequest,     boolean flag to include prediction explanations in prediction response     prediction explanations will be a double value attribute score for each input feature  11: optional bool includeExplanations,  12: optional TrafficType trafficType "}
{"prompt": "How to delete existing deployment tag in Michelangelo I have a deployment tag used before and now I change the model template and corresponding feature schema but still want to use the same deployment tag. Currently since the feature schema doesn't match, I cannot use the existing tag.Is there any way to get around on this? How can we remove the existing deployment tag?", "completion": "See predictionservice.thrift. You can set TrafficType in the request. You can also use deployment tag. See https:  engdocs.uberinternal.com michelangelo user-guides deployment-tags.html?highlight=shadowenum TrafficType      PRODUCTION = 0,    TEST = 1,    SHADOW = 2,    EXPERIMENT = 3,    HOLDOFF = 4,       Reserved for Michelangelo service internal use    AUTOSHADOW = 5 ...struct PredictionRequest       next id: 13  1: optional string projectId,     Model id can be either raw model id or model alias  2: optional string modelId,     note: only one of basisFeatures or binaryBasisFeatures should be used at a time  3: optional list<ValueItem> basisFeatures,  4: optional string label,  5: optional string joinKey,  6: optional bool returnTransformedFeatures,  7: optional bool testTraffic,     note: binary format features  currently, only supported by containerized models   8: optional binary binaryBasisFeatures,  9: optional EncodingType binaryBasisFeaturesEncodingType,     note: when true the request is always logged  10: optional bool sampleRequest,     boolean flag to include prediction explanations in prediction response     prediction explanations will be a double value attribute score for each input feature  11: optional bool includeExplanations,  12: optional TrafficType trafficType "}
{"prompt": "invalid literal for int   error on ml-code repo while local run of a Neural Net model ValueError: invalid literal for int   with base 10 when I run a Michelangelo ml-code  canvas  neural net app locally on my machine.For some reason, this error did not surface for me for the XgBoost model runs locally.", "completion": "A temp fix for this is to provide the memory param explicitly in the docker run command s  inside the tools local_run.sh file, by replacing all occurrences of docker run --shm-size=2gb --rm \ with docker run --memory=10gb --shm-size=2gb --rm \ , 10GB being an arbitrary number that you can experiment withFix found by @zhixuan.wang on the Risk MLE team  code change This unblocked me and helped me test various neural net architectures on my machine"}
{"prompt": "any suggestion on how to improve model accuracy? There are a lot of things one can try to improve accuracy. Is there a more systematic approach how to go about improving accuracy?", "completion": "First, ensure features are computed correctly and feature ETL pipelines are monitored and checked. Make sure the labels are correct and unbiased in your sampling.Second, make sure categorical features are treated as categorical in models. For example, city-id and country-id should be treated as categorical features even though they are numeric values.Third, plot learning curve analysis before spending time doing model iteration. See https:  code.uberinternal.com D7717291#details-tab-view and https:  michelangelo-studio.uberinternal.com file 2680c9d3-56bf-489c-97fd-34b3810d11ef  show one can improve model accuracy with more data. https:  michelangelo-studio.uberinternal.com file 21fbe67c-3cd7-42f0-8c83-f45ad1144068 shows one should increase data for high noise-to-signal bucketsFourth, go thru bias-variance analysis to see what you should try next."}
{"prompt": "Scala Build Error: 'Symbol X is missing from the classpath'", "completion": "It was missing needed dependencies which is why it was throwing this error. See the full change below.Please use . depw find --klass to find the dependency where the class is coming from. It makes it easier to find and also enables to keep the dependency list small.Please don't add extra deps which will slow down your builds.I have pushed the fix to your branch trp_001commit 5df6c97edf2c61f9e2db57753de735cd60be4504  HEAD -> trp_001 Author: Ravi Agarwal <>Date:   Tue Jun 28 22:22:20 2022 -0700    Fix depsdiff --git a safety insurance-internal-pricing BUCK b safety insurance-internal-pricing BUCKindex f6efd9884ffb..4d7345c02492 100644--- a safety insurance-internal-pricing BUCK+++ b safety insurance-internal-pricing BUCK@@ -8,59 +8,25 @@ uber_scala_library      ] ,     maven_coords =  com.uber.safety:insurance-internal-pricing:unspecified ,     provided_deps = [-           3rdparty jvm com google auto value:auto-value-annotations-1.7.jar ,            3rdparty jvm org apache spark:spark-core_2.11-2.4.3-uber-150.jar ,            3rdparty jvm org apache spark:spark-hive_2.11-2.4.3-uber-150.jar ,            3rdparty jvm org apache spark:spark-mllib_2.11-2.4.3-uber-150.jar ,            3rdparty jvm org apache spark:spark-sql_2.11-2.4.3-uber-150.jar ,-           3rdparty jvm org scala-lang:scala-compiler-2.11.12.jar ,-           3rdparty jvm org scala-lang:scala-library-2.11.12.jar ,-           3rdparty jvm org apache hadoop:hadoop-client-2.7.2.jar ,-           data michelangelo serde:src_main ,-           idl code.uber.internal data michelangelo-rest common proxy:src_main ,-           idl code.uber.internal data michelangelo-rest michelangelo_api proxy:src_main ,-           idl code.uber.internal data michelangelo-rest palette proxy:src_main ,-           data michelangelo core src main proto:proto_main ,-           data michelangelo serde src main proto:proto_main ,-           data udk:src_main ,-           data michelangelo core:src_main ,-           idl code.uber.internal data michelangelo-rest common proxy:src_main ,-           data michelangelo common:src_main ,-           data michelangelo core src main proto:proto_main ,-           data michelangelo core:src_main ,-           data michelangelo monitoring:src_main ,-           data michelangelo online-prediction src main avro:src_avro ,-           data michelangelo online-prediction src main proto:grpc_main ,-           data michelangelo online-prediction src main proto:proto_main ,-           data michelangelo online-prediction:src_main ,-           data michelangelo operators:src_main ,-           data michelangelo palette-lib src main proto:proto_main ,-           data michelangelo palette-lib testing:src_main ,-           data michelangelo palette-lib:src_main ,-           data michelangelo resources:manifest ,-           data michelangelo serde src main proto:grpc_main ,-           data michelangelo serde src main proto:proto_main ,-           data michelangelo serde src main proto:proto_main ,-           data michelangelo serde:src_main ,commit 5df6c97edf2c61f9e2db57753de735cd60be4504  HEAD -> trp_001 Author: Ravi Agarwal <>Date:   Tue Jun 28 22:22:20 2022 -0700    Fix depsdiff --git a safety insurance-internal-pricing BUCK b safety insurance-internal-pricing BUCKindex f6efd9884ffb..4d7345c02492 100644--- a safety insurance-internal-pricing BUCK+++ b safety insurance-internal-pricing BUCK@@ -8,59 +8,25 @@ uber_scala_library      ] ,     maven_coords =  com.uber.safety:insurance-internal-pricing:unspecified ,     provided_deps = [-           3rdparty jvm com google auto value:auto-value-annotations-1.7.jar ,            3rdparty jvm org apache spark:spark-core_2.11-2.4.3-uber-150.jar ,            3rdparty jvm org apache spark:spark-hive_2.11-2.4.3-uber-150.jar ,            3rdparty jvm org apache spark:spark-mllib_2.11-2.4.3-uber-150.jar ,            3rdparty jvm org apache spark:spark-sql_2.11-2.4.3-uber-150.jar ,-           3rdparty jvm org scala-lang:scala-compiler-2.11.12.jar ,-           3rdparty jvm org scala-lang:scala-library-2.11.12.jar ,-           3rdparty jvm org apache hadoop:hadoop-client-2.7.2.jar ,-           data michelangelo serde:src_main ,-           idl code.uber.internal data michelangelo-rest common proxy:src_main ,-           idl code.uber.internal data michelangelo-rest michelangelo_api proxy:src_main ,-           idl code.uber.internal data michelangelo-rest palette proxy:src_main ,-           data michelangelo core src main proto:proto_main ,-           data michelangelo serde src main proto:proto_main ,-           data udk:src_main ,-           data michelangelo core:src_main ,-           idl code.uber.internal data michelangelo-rest common proxy:src_main ,-           data michelangelo common:src_main ,-           data michelangelo core src main proto:proto_main ,-           data michelangelo core:src_main ,-           data michelangelo monitoring:src_main ,-           data michelangelo online-prediction src main avro:src_avro ,-           data michelangelo online-prediction src main proto:grpc_main ,-           data michelangelo online-prediction src main proto:proto_main ,-           data michelangelo online-prediction:src_main ,-           data michelangelo operators:src_main ,-           data michelangelo palette-lib src main proto:proto_main ,-           data michelangelo palette-lib testing:src_main ,-           data michelangelo palette-lib:src_main ,-           data michelangelo resources:manifest ,-           data michelangelo serde src main proto:grpc_main ,-           data michelangelo serde src main proto:proto_main ,-           data michelangelo serde src main proto:proto_main ,-           data michelangelo serde:src_main ,-           data michelangelo test-data:operators-test-resources ,-           data michelangelo test-data:serde-test-resources ,-           data michelangelo test-data:test-resources ,-           data michelangelo utils src main proto:grpc_main ,-           data michelangelo utils src main proto:proto_main ,-           data michelangelo utils:src_main ,-           data michelangelo workflow-definitions:src_main ,-           data michelangelo workspace:src_main ,     ],     visibility = [          PUBLIC ,     ],     deps = [            data metadata-platform umetadata-java-client:src_main ,+           data michelangelo core:src_main ,+           data michelangelo serde:src_main ,            data michelangelo utils:src_main ,            data michelangelo workspace:src_main ,+           data udk:src_main ,            idl code.uber.internal data michelangelo-rest common proxy:src_main ,            idl code.uber.internal data michelangelo-rest michelangelo_api proxy:src_main ,            idl code.uber.internal data michelangelo-rest workflow proxy:src_main ,+           idl code.uber.internal data michelangelo proxy:src_main ,            idl code.uber.internal data umetadata proxy:src_main ,     ],  Ran these commands to find the missing deps. depw find --klass com.uber.michelangelo.lib.PySparkUtil. depw find --klass com.uber.michelangelo.modeling.transformers.MichelangeloResultPacker. depw find --klass com.uber.udk.api.UDKLoggerFor the missing idl dep    idl code.uber.internal data michelangelo proxy:src_main  I had to open the project in IDE and find the corresponding missing class. From that I was able to find the library."}
{"prompt": "MLE One-off Prediction task takes a very long time to run MLE One-off Prediction task takes a very long time to run  more than 1hr for less than 1% of my input data . Is there a way I can parallelize the predictions so that it runs more quickly?", "completion": "It was missing needed dependencies which is why it was throwing this error. See the full change below.Please use . depw find --klass to find the dependency where the class is coming from. It makes it easier to find and also enables to keep the dependency list small.Please don't add extra deps which will slow down your builds.I have pushed the fix to your branch trp_001commit 5df6c97edf2c61f9e2db57753de735cd60be4504  HEAD -> trp_001 Author: Ravi Agarwal <>Date:   Tue Jun 28 22:22:20 2022 -0700    Fix depsdiff --git a safety insurance-internal-pricing BUCK b safety insurance-internal-pricing BUCKindex f6efd9884ffb..4d7345c02492 100644--- a safety insurance-internal-pricing BUCK+++ b safety insurance-internal-pricing BUCK@@ -8,59 +8,25 @@ uber_scala_library      ] ,     maven_coords =  com.uber.safety:insurance-internal-pricing:unspecified ,     provided_deps = [-           3rdparty jvm com google auto value:auto-value-annotations-1.7.jar ,            3rdparty jvm org apache spark:spark-core_2.11-2.4.3-uber-150.jar ,            3rdparty jvm org apache spark:spark-hive_2.11-2.4.3-uber-150.jar ,            3rdparty jvm org apache spark:spark-mllib_2.11-2.4.3-uber-150.jar ,            3rdparty jvm org apache spark:spark-sql_2.11-2.4.3-uber-150.jar ,-           3rdparty jvm org scala-lang:scala-compiler-2.11.12.jar ,-           3rdparty jvm org scala-lang:scala-library-2.11.12.jar ,-           3rdparty jvm org apache hadoop:hadoop-client-2.7.2.jar ,-           data michelangelo serde:src_main ,-           idl code.uber.internal data michelangelo-rest common proxy:src_main ,-           idl code.uber.internal data michelangelo-rest michelangelo_api proxy:src_main ,-           idl code.uber.internal data michelangelo-rest palette proxy:src_main ,-           data michelangelo core src main proto:proto_main ,-           data michelangelo serde src main proto:proto_main ,-           data udk:src_main ,-           data michelangelo core:src_main ,-           idl code.uber.internal data michelangelo-rest common proxy:src_main ,-           data michelangelo common:src_main ,-           data michelangelo core src main proto:proto_main ,-           data michelangelo core:src_main ,-           data michelangelo monitoring:src_main ,-           data michelangelo online-prediction src main avro:src_avro ,-           data michelangelo online-prediction src main proto:grpc_main ,-           data michelangelo online-prediction src main proto:proto_main ,-           data michelangelo online-prediction:src_main ,-           data michelangelo operators:src_main ,-           data michelangelo palette-lib src main proto:proto_main ,-           data michelangelo palette-lib testing:src_main ,-           data michelangelo palette-lib:src_main ,-           data michelangelo resources:manifest ,-           data michelangelo serde src main proto:grpc_main ,-           data michelangelo serde src main proto:proto_main ,-           data michelangelo serde src main proto:proto_main ,-           data michelangelo serde:src_main ,commit 5df6c97edf2c61f9e2db57753de735cd60be4504  HEAD -> trp_001 Author: Ravi Agarwal <>Date:   Tue Jun 28 22:22:20 2022 -0700    Fix depsdiff --git a safety insurance-internal-pricing BUCK b safety insurance-internal-pricing BUCKindex f6efd9884ffb..4d7345c02492 100644--- a safety insurance-internal-pricing BUCK+++ b safety insurance-internal-pricing BUCK@@ -8,59 +8,25 @@ uber_scala_library      ] ,     maven_coords =  com.uber.safety:insurance-internal-pricing:unspecified ,     provided_deps = [-           3rdparty jvm com google auto value:auto-value-annotations-1.7.jar ,            3rdparty jvm org apache spark:spark-core_2.11-2.4.3-uber-150.jar ,            3rdparty jvm org apache spark:spark-hive_2.11-2.4.3-uber-150.jar ,            3rdparty jvm org apache spark:spark-mllib_2.11-2.4.3-uber-150.jar ,            3rdparty jvm org apache spark:spark-sql_2.11-2.4.3-uber-150.jar ,-           3rdparty jvm org scala-lang:scala-compiler-2.11.12.jar ,-           3rdparty jvm org scala-lang:scala-library-2.11.12.jar ,-           3rdparty jvm org apache hadoop:hadoop-client-2.7.2.jar ,-           data michelangelo serde:src_main ,-           idl code.uber.internal data michelangelo-rest common proxy:src_main ,-           idl code.uber.internal data michelangelo-rest michelangelo_api proxy:src_main ,-           idl code.uber.internal data michelangelo-rest palette proxy:src_main ,-           data michelangelo core src main proto:proto_main ,-           data michelangelo serde src main proto:proto_main ,-           data udk:src_main ,-           data michelangelo core:src_main ,-           idl code.uber.internal data michelangelo-rest common proxy:src_main ,-           data michelangelo common:src_main ,-           data michelangelo core src main proto:proto_main ,-           data michelangelo core:src_main ,-           data michelangelo monitoring:src_main ,-           data michelangelo online-prediction src main avro:src_avro ,-           data michelangelo online-prediction src main proto:grpc_main ,-           data michelangelo online-prediction src main proto:proto_main ,-           data michelangelo online-prediction:src_main ,-           data michelangelo operators:src_main ,-           data michelangelo palette-lib src main proto:proto_main ,-           data michelangelo palette-lib testing:src_main ,-           data michelangelo palette-lib:src_main ,-           data michelangelo resources:manifest ,-           data michelangelo serde src main proto:grpc_main ,-           data michelangelo serde src main proto:proto_main ,-           data michelangelo serde src main proto:proto_main ,-           data michelangelo serde:src_main ,-           data michelangelo test-data:operators-test-resources ,-           data michelangelo test-data:serde-test-resources ,-           data michelangelo test-data:test-resources ,-           data michelangelo utils src main proto:grpc_main ,-           data michelangelo utils src main proto:proto_main ,-           data michelangelo utils:src_main ,-           data michelangelo workflow-definitions:src_main ,-           data michelangelo workspace:src_main ,     ],     visibility = [          PUBLIC ,     ],     deps = [            data metadata-platform umetadata-java-client:src_main ,+           data michelangelo core:src_main ,+           data michelangelo serde:src_main ,            data michelangelo utils:src_main ,            data michelangelo workspace:src_main ,+           data udk:src_main ,            idl code.uber.internal data michelangelo-rest common proxy:src_main ,            idl code.uber.internal data michelangelo-rest michelangelo_api proxy:src_main ,            idl code.uber.internal data michelangelo-rest workflow proxy:src_main ,+           idl code.uber.internal data michelangelo proxy:src_main ,            idl code.uber.internal data umetadata proxy:src_main ,     ],  Ran these commands to find the missing deps. depw find --klass com.uber.michelangelo.lib.PySparkUtil. depw find --klass com.uber.michelangelo.modeling.transformers.MichelangeloResultPacker. depw find --klass com.uber.udk.api.UDKLoggerFor the missing idl dep    idl code.uber.internal data michelangelo proxy:src_main  I had to open the project in IDE and find the corresponding missing class. From that I was able to find the library."}
{"prompt": "Question about one off prediction output table Sam Lite!q hi team, im using the MLE task Michelangelo Model Prediction One-Off  A task to predict a Michelangelo model  and it offers the option to configure where to write the output. three questions:what's the output schema, so that i can create my own output table if i choose to?is it written using an insert overwrite, and how is it partitioned?if i just use a temp table  i.e, leave this option blank , what's the TTL, partition strategy, and name of that table so i can query copy the data?", "completion": "It was missing needed dependencies which is why it was throwing this error. See the full change below.Please use . depw find --klass to find the dependency where the class is coming from. It makes it easier to find and also enables to keep the dependency list small.Please don't add extra deps which will slow down your builds.I have pushed the fix to your branch trp_001commit 5df6c97edf2c61f9e2db57753de735cd60be4504  HEAD -> trp_001 Author: Ravi Agarwal <>Date:   Tue Jun 28 22:22:20 2022 -0700    Fix depsdiff --git a safety insurance-internal-pricing BUCK b safety insurance-internal-pricing BUCKindex f6efd9884ffb..4d7345c02492 100644--- a safety insurance-internal-pricing BUCK+++ b safety insurance-internal-pricing BUCK@@ -8,59 +8,25 @@ uber_scala_library      ] ,     maven_coords =  com.uber.safety:insurance-internal-pricing:unspecified ,     provided_deps = [-           3rdparty jvm com google auto value:auto-value-annotations-1.7.jar ,            3rdparty jvm org apache spark:spark-core_2.11-2.4.3-uber-150.jar ,            3rdparty jvm org apache spark:spark-hive_2.11-2.4.3-uber-150.jar ,            3rdparty jvm org apache spark:spark-mllib_2.11-2.4.3-uber-150.jar ,            3rdparty jvm org apache spark:spark-sql_2.11-2.4.3-uber-150.jar ,-           3rdparty jvm org scala-lang:scala-compiler-2.11.12.jar ,-           3rdparty jvm org scala-lang:scala-library-2.11.12.jar ,-           3rdparty jvm org apache hadoop:hadoop-client-2.7.2.jar ,-           data michelangelo serde:src_main ,-           idl code.uber.internal data michelangelo-rest common proxy:src_main ,-           idl code.uber.internal data michelangelo-rest michelangelo_api proxy:src_main ,-           idl code.uber.internal data michelangelo-rest palette proxy:src_main ,-           data michelangelo core src main proto:proto_main ,-           data michelangelo serde src main proto:proto_main ,-           data udk:src_main ,-           data michelangelo core:src_main ,-           idl code.uber.internal data michelangelo-rest common proxy:src_main ,-           data michelangelo common:src_main ,-           data michelangelo core src main proto:proto_main ,-           data michelangelo core:src_main ,-           data michelangelo monitoring:src_main ,-           data michelangelo online-prediction src main avro:src_avro ,-           data michelangelo online-prediction src main proto:grpc_main ,-           data michelangelo online-prediction src main proto:proto_main ,-           data michelangelo online-prediction:src_main ,-           data michelangelo operators:src_main ,-           data michelangelo palette-lib src main proto:proto_main ,-           data michelangelo palette-lib testing:src_main ,-           data michelangelo palette-lib:src_main ,-           data michelangelo resources:manifest ,-           data michelangelo serde src main proto:grpc_main ,-           data michelangelo serde src main proto:proto_main ,-           data michelangelo serde src main proto:proto_main ,-           data michelangelo serde:src_main ,commit 5df6c97edf2c61f9e2db57753de735cd60be4504  HEAD -> trp_001 Author: Ravi Agarwal <>Date:   Tue Jun 28 22:22:20 2022 -0700    Fix depsdiff --git a safety insurance-internal-pricing BUCK b safety insurance-internal-pricing BUCKindex f6efd9884ffb..4d7345c02492 100644--- a safety insurance-internal-pricing BUCK+++ b safety insurance-internal-pricing BUCK@@ -8,59 +8,25 @@ uber_scala_library      ] ,     maven_coords =  com.uber.safety:insurance-internal-pricing:unspecified ,     provided_deps = [-           3rdparty jvm com google auto value:auto-value-annotations-1.7.jar ,            3rdparty jvm org apache spark:spark-core_2.11-2.4.3-uber-150.jar ,            3rdparty jvm org apache spark:spark-hive_2.11-2.4.3-uber-150.jar ,            3rdparty jvm org apache spark:spark-mllib_2.11-2.4.3-uber-150.jar ,            3rdparty jvm org apache spark:spark-sql_2.11-2.4.3-uber-150.jar ,-           3rdparty jvm org scala-lang:scala-compiler-2.11.12.jar ,-           3rdparty jvm org scala-lang:scala-library-2.11.12.jar ,-           3rdparty jvm org apache hadoop:hadoop-client-2.7.2.jar ,-           data michelangelo serde:src_main ,-           idl code.uber.internal data michelangelo-rest common proxy:src_main ,-           idl code.uber.internal data michelangelo-rest michelangelo_api proxy:src_main ,-           idl code.uber.internal data michelangelo-rest palette proxy:src_main ,-           data michelangelo core src main proto:proto_main ,-           data michelangelo serde src main proto:proto_main ,-           data udk:src_main ,-           data michelangelo core:src_main ,-           idl code.uber.internal data michelangelo-rest common proxy:src_main ,-           data michelangelo common:src_main ,-           data michelangelo core src main proto:proto_main ,-           data michelangelo core:src_main ,-           data michelangelo monitoring:src_main ,-           data michelangelo online-prediction src main avro:src_avro ,-           data michelangelo online-prediction src main proto:grpc_main ,-           data michelangelo online-prediction src main proto:proto_main ,-           data michelangelo online-prediction:src_main ,-           data michelangelo operators:src_main ,-           data michelangelo palette-lib src main proto:proto_main ,-           data michelangelo palette-lib testing:src_main ,-           data michelangelo palette-lib:src_main ,-           data michelangelo resources:manifest ,-           data michelangelo serde src main proto:grpc_main ,-           data michelangelo serde src main proto:proto_main ,-           data michelangelo serde src main proto:proto_main ,-           data michelangelo serde:src_main ,-           data michelangelo test-data:operators-test-resources ,-           data michelangelo test-data:serde-test-resources ,-           data michelangelo test-data:test-resources ,-           data michelangelo utils src main proto:grpc_main ,-           data michelangelo utils src main proto:proto_main ,-           data michelangelo utils:src_main ,-           data michelangelo workflow-definitions:src_main ,-           data michelangelo workspace:src_main ,     ],     visibility = [          PUBLIC ,     ],     deps = [            data metadata-platform umetadata-java-client:src_main ,+           data michelangelo core:src_main ,+           data michelangelo serde:src_main ,            data michelangelo utils:src_main ,            data michelangelo workspace:src_main ,+           data udk:src_main ,            idl code.uber.internal data michelangelo-rest common proxy:src_main ,            idl code.uber.internal data michelangelo-rest michelangelo_api proxy:src_main ,            idl code.uber.internal data michelangelo-rest workflow proxy:src_main ,+           idl code.uber.internal data michelangelo proxy:src_main ,            idl code.uber.internal data umetadata proxy:src_main ,     ],  Ran these commands to find the missing deps. depw find --klass com.uber.michelangelo.lib.PySparkUtil. depw find --klass com.uber.michelangelo.modeling.transformers.MichelangeloResultPacker. depw find --klass com.uber.udk.api.UDKLoggerFor the missing idl dep    idl code.uber.internal data michelangelo proxy:src_main  I had to open the project in IDE and find the corresponding missing class. From that I was able to find the library."}
{"prompt": "Can I deploy models with other deployment label? Will it have two deployment labels? Is it possible to deploy the same model  Canvas  to two different deployment tags at the same time? We've a model that is currently serving production traffic and we want to rename the tag. To ensure, smooth transition we want to ensure that both tags are working as our product code is getting deployed with the rename change.", "completion": "It was missing needed dependencies which is why it was throwing this error. See the full change below.Please use . depw find --klass to find the dependency where the class is coming from. It makes it easier to find and also enables to keep the dependency list small.Please don't add extra deps which will slow down your builds.I have pushed the fix to your branch trp_001commit 5df6c97edf2c61f9e2db57753de735cd60be4504  HEAD -> trp_001 Author: Ravi Agarwal <>Date:   Tue Jun 28 22:22:20 2022 -0700    Fix depsdiff --git a safety insurance-internal-pricing BUCK b safety insurance-internal-pricing BUCKindex f6efd9884ffb..4d7345c02492 100644--- a safety insurance-internal-pricing BUCK+++ b safety insurance-internal-pricing BUCK@@ -8,59 +8,25 @@ uber_scala_library      ] ,     maven_coords =  com.uber.safety:insurance-internal-pricing:unspecified ,     provided_deps = [-           3rdparty jvm com google auto value:auto-value-annotations-1.7.jar ,            3rdparty jvm org apache spark:spark-core_2.11-2.4.3-uber-150.jar ,            3rdparty jvm org apache spark:spark-hive_2.11-2.4.3-uber-150.jar ,            3rdparty jvm org apache spark:spark-mllib_2.11-2.4.3-uber-150.jar ,            3rdparty jvm org apache spark:spark-sql_2.11-2.4.3-uber-150.jar ,-           3rdparty jvm org scala-lang:scala-compiler-2.11.12.jar ,-           3rdparty jvm org scala-lang:scala-library-2.11.12.jar ,-           3rdparty jvm org apache hadoop:hadoop-client-2.7.2.jar ,-           data michelangelo serde:src_main ,-           idl code.uber.internal data michelangelo-rest common proxy:src_main ,-           idl code.uber.internal data michelangelo-rest michelangelo_api proxy:src_main ,-           idl code.uber.internal data michelangelo-rest palette proxy:src_main ,-           data michelangelo core src main proto:proto_main ,-           data michelangelo serde src main proto:proto_main ,-           data udk:src_main ,-           data michelangelo core:src_main ,-           idl code.uber.internal data michelangelo-rest common proxy:src_main ,-           data michelangelo common:src_main ,-           data michelangelo core src main proto:proto_main ,-           data michelangelo core:src_main ,-           data michelangelo monitoring:src_main ,-           data michelangelo online-prediction src main avro:src_avro ,-           data michelangelo online-prediction src main proto:grpc_main ,-           data michelangelo online-prediction src main proto:proto_main ,-           data michelangelo online-prediction:src_main ,-           data michelangelo operators:src_main ,-           data michelangelo palette-lib src main proto:proto_main ,-           data michelangelo palette-lib testing:src_main ,-           data michelangelo palette-lib:src_main ,-           data michelangelo resources:manifest ,-           data michelangelo serde src main proto:grpc_main ,-           data michelangelo serde src main proto:proto_main ,-           data michelangelo serde src main proto:proto_main ,-           data michelangelo serde:src_main ,commit 5df6c97edf2c61f9e2db57753de735cd60be4504  HEAD -> trp_001 Author: Ravi Agarwal <>Date:   Tue Jun 28 22:22:20 2022 -0700    Fix depsdiff --git a safety insurance-internal-pricing BUCK b safety insurance-internal-pricing BUCKindex f6efd9884ffb..4d7345c02492 100644--- a safety insurance-internal-pricing BUCK+++ b safety insurance-internal-pricing BUCK@@ -8,59 +8,25 @@ uber_scala_library      ] ,     maven_coords =  com.uber.safety:insurance-internal-pricing:unspecified ,     provided_deps = [-           3rdparty jvm com google auto value:auto-value-annotations-1.7.jar ,            3rdparty jvm org apache spark:spark-core_2.11-2.4.3-uber-150.jar ,            3rdparty jvm org apache spark:spark-hive_2.11-2.4.3-uber-150.jar ,            3rdparty jvm org apache spark:spark-mllib_2.11-2.4.3-uber-150.jar ,            3rdparty jvm org apache spark:spark-sql_2.11-2.4.3-uber-150.jar ,-           3rdparty jvm org scala-lang:scala-compiler-2.11.12.jar ,-           3rdparty jvm org scala-lang:scala-library-2.11.12.jar ,-           3rdparty jvm org apache hadoop:hadoop-client-2.7.2.jar ,-           data michelangelo serde:src_main ,-           idl code.uber.internal data michelangelo-rest common proxy:src_main ,-           idl code.uber.internal data michelangelo-rest michelangelo_api proxy:src_main ,-           idl code.uber.internal data michelangelo-rest palette proxy:src_main ,-           data michelangelo core src main proto:proto_main ,-           data michelangelo serde src main proto:proto_main ,-           data udk:src_main ,-           data michelangelo core:src_main ,-           idl code.uber.internal data michelangelo-rest common proxy:src_main ,-           data michelangelo common:src_main ,-           data michelangelo core src main proto:proto_main ,-           data michelangelo core:src_main ,-           data michelangelo monitoring:src_main ,-           data michelangelo online-prediction src main avro:src_avro ,-           data michelangelo online-prediction src main proto:grpc_main ,-           data michelangelo online-prediction src main proto:proto_main ,-           data michelangelo online-prediction:src_main ,-           data michelangelo operators:src_main ,-           data michelangelo palette-lib src main proto:proto_main ,-           data michelangelo palette-lib testing:src_main ,-           data michelangelo palette-lib:src_main ,-           data michelangelo resources:manifest ,-           data michelangelo serde src main proto:grpc_main ,-           data michelangelo serde src main proto:proto_main ,-           data michelangelo serde src main proto:proto_main ,-           data michelangelo serde:src_main ,-           data michelangelo test-data:operators-test-resources ,-           data michelangelo test-data:serde-test-resources ,-           data michelangelo test-data:test-resources ,-           data michelangelo utils src main proto:grpc_main ,-           data michelangelo utils src main proto:proto_main ,-           data michelangelo utils:src_main ,-           data michelangelo workflow-definitions:src_main ,-           data michelangelo workspace:src_main ,     ],     visibility = [          PUBLIC ,     ],     deps = [            data metadata-platform umetadata-java-client:src_main ,+           data michelangelo core:src_main ,+           data michelangelo serde:src_main ,            data michelangelo utils:src_main ,            data michelangelo workspace:src_main ,+           data udk:src_main ,            idl code.uber.internal data michelangelo-rest common proxy:src_main ,            idl code.uber.internal data michelangelo-rest michelangelo_api proxy:src_main ,            idl code.uber.internal data michelangelo-rest workflow proxy:src_main ,+           idl code.uber.internal data michelangelo proxy:src_main ,            idl code.uber.internal data umetadata proxy:src_main ,     ],  Ran these commands to find the missing deps. depw find --klass com.uber.michelangelo.lib.PySparkUtil. depw find --klass com.uber.michelangelo.modeling.transformers.MichelangeloResultPacker. depw find --klass com.uber.udk.api.UDKLoggerFor the missing idl dep    idl code.uber.internal data michelangelo proxy:src_main  I had to open the project in IDE and find the corresponding missing class. From that I was able to find the library."}
{"prompt": "Why the name Michelangelo? Why did we name our ML platform Michelangelo? Wikipedia says Michelangelo was an Italian sculptor.", "completion": "Michelangelo created the masterpiece David.  David was one of the founding staff of Michelangelo. As a tribute, he named it Michelangelo."}
{"prompt": "michelangelo job failed", "completion": "Michelangelo created the masterpiece David.  David was one of the founding staff of Michelangelo. As a tribute, he named it Michelangelo."}
{"prompt": "Accessing Michelangelo palette Cassandra", "completion": "This is because it is not running with the default port. Also, the version required 3.4.0.:$ home jwang apache-cassandra-3.0.10 bin cqlsh --cqlversion= 3.4.0  compute645-sjc1 10069"}
{"prompt": "How can I access the Michelangelo gateway through Cerberus?", "completion": "This is the important error message:ErrCodeDeclined: sharder peer list had no peers available for:  It seems like the sk transport header value isn't being set on the request in your java code calling the gateway, I believe this is the cause of the error."}
{"prompt": "How is feature importance calculated? Can someone tell me how feature importance is calculated in Michelangelo?", "completion": "This is the important error message:ErrCodeDeclined: sharder peer list had no peers available for:  It seems like the sk transport header value isn't being set on the request in your java code calling the gateway, I believe this is the cause of the error."}
{"prompt": "Does FeatureStore automatically create table? Follow up:For basis features we send the values in the API call request so is there a table that gets created automatically  since we have not created any table ?To fetch the value from cassandra for a palette feature do I need to send the join key? E.g. - do I need to send the cityID in API call request for below palette feature? If so what will be the format?aura_city_features_palette_feat_average_eta_median: nFill nVal @palette:city_features_palette:average_eta_median:city_id:1 , 0.0  edited ", "completion": "This is the important error message:ErrCodeDeclined: sharder peer list had no peers available for:  It seems like the sk transport header value isn't being set on the request in your java code calling the gateway, I believe this is the cause of the error."}
{"prompt": "Delete task in MLE flow how can I delete one task from the existing MLE flow? I find one of my task is not useful, and I want to delete it. For example, I want to delete model_search task in my MLE flow here: https:  michelangelo-studio.uberinternal.com mle cvr_two_towers workflow 556921cd-1626-498a-b6fa-d046c3ab8be1 edit", "completion": "This is the important error message:ErrCodeDeclined: sharder peer list had no peers available for:  It seems like the sk transport header value isn't being set on the request in your java code calling the gateway, I believe this is the cause of the error."}
{"prompt": "What is the best practice to set MLE pipeline alerts?", "completion": "This is the important error message:ErrCodeDeclined: sharder peer list had no peers available for:  It seems like the sk transport header value isn't being set on the request in your java code calling the gateway, I believe this is the cause of the error."}
{"prompt": "I have a partitioned Michelangelo model and want to deploy one of the models. Is this possible? I have a partitioned Michelangelo model and  want to deploy one of the models. Is this possible?", "completion": "that is not possible."}
{"prompt": "Michelangelo-API error: *errors.errorString Please set uOwn for your hive table hi team getting this while adding data source.checked also databook.I am part of the uown team.*errors.errorString Please set uOwn for your hive table kirby_external_data.l1triage_jira in the Databooksrc code.uber.internal data michelangelo-api errors error_utils.go:32  0x12fc714 src code.uber.internal data michelangelo-api services datasource.go:68  0x22ea78f src code.uber.internal data michelangelo-api handlers apis data_source.go:60  0x239fd48 bazel-out k8-opt bin idl code.uber.internal data michelangelo-rest michelangelo_api michelangelo_api_michelangeloapiserver_go_thriftrw_ code.uber.internal data michelangelo-rest michelangelo_api michelangelo_api michelangeloapiserver server.go:10228  0x237d966 external org_uber_go_yarpc encoding thrift inbound_nowire.go:147  0x193a198 external org_uber_go_yarpc encoding thrift inbound_nowire.go:79  0x1939785 external org_uber_go_yarpc internal inboundmiddleware chain.go:72  0x14f1eb5 src code.uber.internal data michelangelo-api middleware context.go:87  0x24ddd88 external org_uber_go_yarpc internal inboundmiddleware chain.go:76  0x14f1f94 external internal_uber_code_go_yarpcfx_git internal timeoutclampermiddleware timeoutclampermiddleware.go:103  0x24cafb1 external org_uber_go_yarpc internal inboundmiddleware chain.go:76  0x14f1f94 src code.uber.internal go ratelimitfx.git internal inbound middleware.go:31  0x2474066 external org_uber_go_yarpc internal inboundmiddleware chain.go:76  0x14f1f94 src code.uber.internal go galileofx.git authmiddleware auth_middleware.go:103  0x2543342 external org_uber_go_yarpc internal inboundmiddleware chain.go:76  0x14f1f94 external internal_uber_code_go_yarpcfx_git internal drainmiddleware drainmiddleware.go:40  0x2459a57 external org_uber_go_yarpc internal inboundmiddleware chain.go:76  0x14f1f94 external internal_uber_code_go_yarpcfx_git internal assistedlbmiddleware assistedlbmiddleware.go:85  0x2481084 external org_uber_go_yarpc internal inboundmiddleware chain.go:76  0x14f1f94 external internal_uber_code_go_yarpcfx_git internal pproflabelsmiddleware pproflabelsmiddleware.go:74  0x24b393f external org_uber_go_yarpc internal inboundmiddleware chain.go:76  0x14f1f94 external org_uber_go_yarpc internal observability middleware.go:188  0x14ecec2 external org_uber_go_yarpc internal inboundmiddleware chain.go:76  0x14f1f94 external org_uber_go_yarpc internal inboundmiddleware chain.go:60  0x14f25a5 external org_uber_go_yarpc api middleware inbound.go:71  0x14e16da external org_uber_go_yarpc api transport handler_invoker.go:70  0x13d5af5 external org_uber_go_yarpc transport http handler.go:158  0x24a3978 external org_uber_go_yarpc transport http handler.go:65  0x24a2766 external internal_uber_code_go_yarpcfx_git internal configurator configurator.go:225  0x24b1a91 GOROOT src net http server.go:2109  0x6fcdcf external internal_uber_code_go_yarpcfx_git internal configurator configurator.go:213  0x24b16d3 GOROOT src net http server.go:2109  0x6fcdcf GOROOT src net http server.go:2947  0x7001cc GOROOT src net http server.go:1991  0x6fb8a7 GOROOT src runtime asm_amd64.s:1594  0x4769e1 ", "completion": "that is not possible."}
{"prompt": "How can I debug a model in the evaluator step?", "completion": "that is not possible."}
{"prompt": "What is the syntax of sampling expression in old Michelangelo UX Can you give me an example of data sampling expression?", "completion": "as stated in the diff, it is a spark sql expression without scoping```commit d5b37ebc5e19959fc5807f62e942dc8365aadc9aAuthor: Mingshi Wang <>Date:   Fri Apr 24 20:42:31 2020 +0000    Sample expression should require no MA column scopes    Summary: This is to fix the sample operator so that it can consume sampling expression  Spark SQL expression  without column scopes. The goal is to provide consistent user experience as the train filter expression.    Test Plan: Unit test    Reviewers: mmui    Reviewed By: mmui    Subscribers: wmingshi    Differential Revision: https:  code.uberinternal.com D4302399data michelangelo operators src main scala com uber michelangelo operators featureeng SamplingOperator.scala"}
{"prompt": "bazel build issue for michelangelo jar", "completion": "Please make sureYou have sync'd with master.You are on VPN"}
{"prompt": "Api to query a palette feature I am interested in querying data from these two palette feature groupshttps:  databook.uberinternal.com ml_features hexagon.aggregated_demand definitionhttps:  databook.uberinternal.com ml_features hexagon.aggregated_supply definitionIs there any api to query the palette store? Can I test it from studio?", "completion": "Please make sureYou have sync'd with master.You are on VPN"}
{"prompt": "does canvas support custom batching methods for Keras models specifically, can users specify their own data generators   batching methods instead of having randomized batches during model training?", "completion": "Peng Zhang  35 minutes agoWe do not support customizable data loader yet, but user can choose to shuffle the data or not.If you prepare your data the way you like, and skip data shuffling, it basically means the neighbor rows in original data is also most like in a same batch.I am sure Torch supports it, but not sure about Keras data loader.Chongxiao CaoCustomers are welcome to write their own dataloader in for TF Keras by implementing this DataModule  class, and pass as a parameters to estimators.https:  github.com horovod horovod blob master horovod spark keras datamodule.pyexamples above."}
{"prompt": "Issue with inject michelangelo to fx.Provide", "completion": "Peng Zhang  35 minutes agoWe do not support customizable data loader yet, but user can choose to shuffle the data or not.If you prepare your data the way you like, and skip data shuffling, it basically means the neighbor rows in original data is also most like in a same batch.I am sure Torch supports it, but not sure about Keras data loader.Chongxiao CaoCustomers are welcome to write their own dataloader in for TF Keras by implementing this DataModule  class, and pass as a parameters to estimators.https:  github.com horovod horovod blob master horovod spark keras datamodule.pyexamples above."}
{"prompt": "Error when registering a hive table for data source", "completion": "see What input types are supported by Michelangelo as features? Is Array<Double> supported? and Why are Michelangelo data sources so restrictive in allowed column types?. Note that the timestamp type is not a primitive numeric type.One workaround is to create a view on top of the table."}
{"prompt": "connect: connection refused error while doing a local_run on an ml-model on ml-code   Michelangelo Canvas repo I am working on an ML model using Michelangelo Canvas   ml-code. I followed the codelabs for setting up the repo, and while executing local_run on the models, I am getting the following connection refused error -. tools local_run.sh --project_dir platforms risk chargeback_representment_second_chargeback_model --runnable platforms.risk.chargeback_representment_second_chargeback_model.models.xgboost.v0_xgboost_spark.trainError Trace -+ echo 'Building a local docker for project: platforms risk chargeback_representment_second_chargeback_model'Building a local docker for project: platforms risk chargeback_representment_second_chargeback_model+ docker build -t ml-code:local_run_init --build-arg GIT_REPO=. --build-arg BUILD_LOC=local --build-arg PIP_INDEX_URL_ARG=http:  artifactory.uber.internal:4587 artifactory api pypi pypi simple  -f  home user ml-code platforms risk chargeback_representment_second_chargeback_model Dockerfile .Sending build context to Docker daemon 67.72MBStep 1 170 : FROM 127.0.0.1:5055 uber-ubi debian-10:bkt1-produ-1660570529-0e8dc AS phase1Get http:  127.0.0.1:5055 v2 : dial tcp 127.0.0.1:5055: connect: connection refusedThis happened both on my machine, as well as the ML devpod. What is the problem here?", "completion": "This happened because I was using an older docker image on the local during the setup due to the codelabs which were a bit obsolete at the time. Pulling the latest docker image and tagging it helped to resolve the error.One way to check if this might be the case is if the Dockerfile that is generated has a different docker image  usually, the first uncommented line in the project_path Dockerfile  than the one you pulled during the ml-code repo setup.For me, the docker file had the following imageFROM 127.0.0.1:5055 uber-ubi debian-10:bkt1-produ-1660570529-0e8dc AS phase1while the dockerfile that I was pulling to setup the repo was the followingdocker pull \ docker-all.artifactory.uber.internal:5922 uber-ubi debian-9:phx2-produ-0000000001 . See the difference in the two..In general, you may use the image from the Dockerfile during your repo setup, and things worked out for me that way. Additionally, the MA team seems to update the ml-code readme  linked below  faster than the codelabs, so checking that out might be a good idea as well.ml-code local run readme, codelab"}
{"prompt": "can we set business hour for Michenlangelo feature drift alert? We have several feature drift alerts that are easier to get triggered during weekend compare to weekday due to weekend low traffic volume. Is there a way to set business hour for alerts to exclude weekend on MA UI? or we have to do it on umonitor alert page? thanks", "completion": "This happened because I was using an older docker image on the local during the setup due to the codelabs which were a bit obsolete at the time. Pulling the latest docker image and tagging it helped to resolve the error.One way to check if this might be the case is if the Dockerfile that is generated has a different docker image  usually, the first uncommented line in the project_path Dockerfile  than the one you pulled during the ml-code repo setup.For me, the docker file had the following imageFROM 127.0.0.1:5055 uber-ubi debian-10:bkt1-produ-1660570529-0e8dc AS phase1while the dockerfile that I was pulling to setup the repo was the followingdocker pull \ docker-all.artifactory.uber.internal:5922 uber-ubi debian-9:phx2-produ-0000000001 . See the difference in the two..In general, you may use the image from the Dockerfile during your repo setup, and things worked out for me that way. Additionally, the MA team seems to update the ml-code readme  linked below  faster than the codelabs, so checking that out might be a good idea as well.ml-code local run readme, codelab"}
{"prompt": "How to debug realtime prediction latency issue? We are seeing higher % of requests getting timeout. How do we narrow down the possible cause?", "completion": "Check the CPU utiliization of your service and the corresponding Michelangelo service. If there is an instance with extreme high CPU, restart that instance. If don't have sufficient capacity, scale the number of instances.Check the Michelangelo dashboard for the corresponding Michelangelo service and your project. For example, Bundle Conversion batch request latency.Check the corresponding Cassandra Redis latency metrics on the Michelangelo dashboard if you are using FeatureStore.If your call goes thru michelangelo-gateway, check Muttley from your service to michelangelo-gateway. Also check michelangelo-gateway error dashboard for exceeding deadline errors.Check if there is a  change in batch size since productionization.  Your single prediction P99.99 latency * batch size n should be less than request timeout value.Check if the model complexity has increased, number of features has increased, DSL expression is more complex, fetch more FeatureStore groups, etc.If everything failed, run yab with jaeger trace enabled from the problematic zone."}
{"prompt": "How to generate a sample yab request for realtime prediction service?", "completion": "We have a yab command generation script in Java monorepo. It requires a sample_data.csv file with first line containing headers  feature names  and at least one line the data. It also requires basis_columns_type.yaml, which is generated during model training; it contains feature type meta information.First download or copy generation script to your laptop.Login to S3. Entered you ldap id without @uber.com and password. Use  push  for validation.Click on Uber, developer_michelangelo's Management console.3. Go to  https:  console.aws.amazon.com s3 buckets uber-michelangelo?region=us-east-1prefix=projects  trained_models showversions=false  for example https:  console.aws.amazon.com s3 buckets uber-michelangelo?region=us-east-1prefix=projects EtaFitProduction trained_models showversions=false 4. Type in the first 26 characters of you model-id or your training job id.The basis_columns_type.yaml can be found in the training job folder. In this case If there is no sample_data_csv folder, you can find it in a model folder  associated with a partition or hyperparameter training model .5. Download both files to the same directory as gen_sample_tcurl_local.py.6. Run . gen_sample_tcurl_local.py projectId modelId <True False for Palette>     if you add True for Palette, then we will also include Palette FeatureStore features into the request so that no online FeatureStore feature will be made since FeatureStore features are passed in."}
{"prompt": "Found duplicate column s  Error when training a multi-output DL model in ml-code I am getting duplicate column s  error while training a multi-output deep learning model in ml-code. This was working fine till the time I was using a DummyEvaluator, but started to error out as soon as I started using a MABinaryClassificationEvaluator. The columns on which it complains duplication are the label columns that I have generated in the response_dsl of the transform section.org.apache.spark.sql.AnalysisException: Found duplicate column s  when inserting into file: user vaibhavb canvas workspaces platforms.risk.chargeback_representment_second_chargeback_model.models.neural_nets.v3_multitask_proper.train variables 2e0afd06 value value.parquet: `derived_is_first_rep_won`, `derived_is_second_cb`;", "completion": "Turns out I was indeed duplicating the label columns. The specific problem with the code was that I was using the same label column name as the outputs inside the trainer spec. The labels defined under outputs section should be different from the labels, and from every other columns defined in the spec, since these also get created during trainer transformation  which I was not aware of . So, for the multi-outputs, the trainer was also producing the same column names as the label columns, hence duplicating it, which eventually errored out in future steps.The reason why this started to happen with the MABinaryClassificationEvaluator and was working fine with the DummyEvaluator was that with the MABinaryClassificationEvaluator step, there are some additional steps inside the score_dataframes API that do transformation on the servable model creating duplicate columns which errors out inside the evaluator step."}
{"prompt": "What is preventing me from cloning this shared file in Jupyter Notebooks?", "completion": "Turns out I was indeed duplicating the label columns. The specific problem with the code was that I was using the same label column name as the outputs inside the trainer spec. The labels defined under outputs section should be different from the labels, and from every other columns defined in the spec, since these also get created during trainer transformation  which I was not aware of . So, for the multi-outputs, the trainer was also producing the same column names as the label columns, hence duplicating it, which eventually errored out in future steps.The reason why this started to happen with the MABinaryClassificationEvaluator and was working fine with the DummyEvaluator was that with the MABinaryClassificationEvaluator step, there are some additional steps inside the score_dataframes API that do transformation on the servable model creating duplicate columns which errors out inside the evaluator step."}
{"prompt": "How to exclude a group from Michelangelo auto-generated alerts?", "completion": "Identify the alert group the alert is coming from in uMonitor.The alert group name should be michelangelo_<project_name> michelangel_Surge_forecasting_PoDi in the above case Then you can edit the alert and exclude the email in Action section."}
{"prompt": "How Michelangelo Training Filter works", "completion": "Identify the alert group the alert is coming from in uMonitor.The alert group name should be michelangelo_<project_name> michelangel_Surge_forecasting_PoDi in the above case Then you can edit the alert and exclude the email in Action section."}
{"prompt": "Run into issue when running generate_feature_config script I am trying to run this step:Run . scripts generate_feature_config.py  <feature_group> for your entity and feature group names. It will generate features.json automatically. This maps to features that belong in the feature group.But I keep getting error: urllib2.HTTPError: HTTP Error 404: Not Found", "completion": "Make sure you don't have existing ssh localhost:14167 ssh session. Kill those sessions before running the script.Check if you can ssh hadoopgw02-dca1.Note that when you run this script, a schema is generated from the source hive table. If you don't have a Hive table there, features.json can not be generated. And auto-alert will not be auto updated."}
{"prompt": "How to debug model-not-found issue for realtime prediction service? Getting alert for high model-not-found errors. See something likeThe model is not found: <projectId: EATS_SEDI_TTA_Model>, <modelId: null>, <label: tm20221102-144833-HKXIJCJY-LUQDWY>", "completion": "You have put modelId into the label field. To fix the issue, fix the client code to put modelId into request's modelId field.The model is not found: <projectId: EATS_SEDI_TTA_Model>, <modelId: null>, <label: tm20221102-144833-HKXIJCJY-LUQDWY>Note that one cannot have both label and modelId in a request. If you are using label, there must be at least one model deployed to that label.For debugging other situation of model-not-found error:Go to model view for the project, for example https:  michelangelo.uberinternal.com EATS_SEDI_TTA_Model models and check if the model is deployed. If it is not deployed, deploy it will usually fix the issue. You can also check deployment view https:  michelangelo.uberinternal.com EATS_SEDI_TTA_Model deployments.If the model is deployed, check if you are hitting the right endpoint. Go to DEPLOYMENT SETTINGS section of the project view. https:  michelangelo.uberinternal.com EATS_SEDI_TTA_Model settings shows it is deployed to group5 which is alias for michelangelo-prediction-group5. Make sure you are calling this service.If the model shows deployment status lost, check if there is on going restart for the realtime prediction service. If yes, wait till restart is completed. If no, ping oncall in the #michelangelo-helpdesk slack.Verfiy there is no extra space and case match for projected and modelId label in your request."}
{"prompt": "How to find my ubuild service for my ml-code project ubuild service is automatically created after checkin project.yaml into ml-code. The answer is about how to find my ubuild service.", "completion": "If you project is onboarded to MA Studio https:  michelangelo-studio.uberinternal.com maYou can find it in the  Builds  link on the project page.You can also use the CLI  mactl project get -n <MA Studio Project Name>  to see it."}
{"prompt": "How do I download the feature importance from Michelangelo? How to download the feature importance for trained model?", "completion": "If you project is onboarded to MA Studio https:  michelangelo-studio.uberinternal.com maYou can find it in the  Builds  link on the project page.You can also use the CLI  mactl project get -n <MA Studio Project Name>  to see it."}
{"prompt": "Any workaround for Canvas remote_ingest_hive_data now that hadoopgtw is gone? Encountered Exception: Failed to copy ingest script to hadoopgw02-phx2```probably because hadoop gateway is decommissioned. Any workaround.", "completion": "Till https:  code.uberinternal.com D8781391#bot-comments-tab-view[workaround] https:  code.uberinternal.com D8781391 https:  code.uberinternal.com D8781391#bot-comments-tab-view is merged to master, you can try using beeline with data flavor or ml flavor devpod.For example, to get csv datadump for michelangelo.dispatch_rider_cancel_v3_daily_v1 needed for. tools local_run.sh --project_dir data michelangelo examples ma_workspace --runnable data.michelangelo.examples.ma_workspace.dispatch_rider_cancels_v3.v0.trainI run the following scriptbeeline-phx -n jwang --hiveconf mapreduce.job.queuename=michelangelo-batch --outputformat=csv2 -f query.sql > dispatch.old # remove beeline echo and remove tablename from csv header grep -v  >   dispatch.old | sed -e 's dispatch_rider_cancel_v3_daily_v1.  g' > dispatch_phx.csv where query.sql hasuse michelangelo;select *from dispatch_rider_cancel_v3_daily_v1where datestr >= '2022-06-20' and datestr < '2022-06-22'limit 10000;Note that the utc_datetime column in the original table has wrong format. I'd wrote another script to fix format before running ingest_hive_data command.See ml flavor with hadoop access comms - Winter 2022 for ml-flavor devpod."}
{"prompt": "How to increase sampling rate for realtime prediction service? We want to increase the prediction request logging rate so that we can analyze the data for limited launch.", "completion": "By default the sampling rate is 0.005. See flipr property. We also don't enable logging for projects with PII features, NLP and CV use cases due to large payload  privacy concerns.  [If you are using any PII features, please make sure get approval from Legal and Compliance.]If you need to have larger sampling rate, we recommend that you mirror hp-michelangelo-prediction.  See hp-michelangelo-freight and hp-michelangelo-prediction-group9-safety.  Please make sure to set to secure topic if you want to restrict access or log may contain PII or sensitive information.  After the new topic is created, ping oncall to make change to fliper property and restart the service. Afterward, make the sampling rate flipr change for flipr property.For NRT monitoring, we also need to make change to config similar to https:  code.uberinternal.com D4827321."}
{"prompt": "RAW: EXIT with status 7: Failed to os::execvpe on path ' usr local libexec mesos mesos-containerizer': 7 tried to run michelangelo canvas job, but driver log shows:RAW: EXIT with status 7: Failed to os::execvpe on path ' usr local libexec mesos mesos-containerizer': 7", "completion": "By default the sampling rate is 0.005. See flipr property. We also don't enable logging for projects with PII features, NLP and CV use cases due to large payload  privacy concerns.  [If you are using any PII features, please make sure get approval from Legal and Compliance.]If you need to have larger sampling rate, we recommend that you mirror hp-michelangelo-prediction.  See hp-michelangelo-freight and hp-michelangelo-prediction-group9-safety.  Please make sure to set to secure topic if you want to restrict access or log may contain PII or sensitive information.  After the new topic is created, ping oncall to make change to fliper property and restart the service. Afterward, make the sampling rate flipr change for flipr property.For NRT monitoring, we also need to make change to config similar to https:  code.uberinternal.com D4827321."}
{"prompt": "How stats functions work in Michelangelo DSL", "completion": "Here is how they are functioning in V2  Canvas  MA studio  training flows.You can use them in the DSL in the transform step, not assembler step. These stats are computed from the input columns to the transform step on the training dataset  not val or test , with all null fields excluded, and these stats will be stored with the transformersDuring serving time, the stats used transformers will be used.Please note that these values are computed based on some streaming algorithms. That is not the precise values.For example, if your values are just integers, and you are using percentiles. You may see the percentiles with some decimal numbers. That should be a good approximation to the percentiles in the real number space.There are some inconsistency issues if you are using V1 flows.In the v1 flow, the one applied on the training dataset is the same as above, but the one on the serving side is based on a stats from a sample of data.Please move to canvas   ma-studio, if you are facing this issue."}
{"prompt": "how to resolve pyml dependency package issue getting error like No matching distribution found for pytorch-lightning==1.6.4 during ma-endpoint build. how do i figure out if my pyML package version.", "completion": "First note that due to the lack of eng resource, pyML  dev-guide, engdoc, 3rd Party Packages Guide and pyml online restriction  support is very limited and there is no SLA guarantee associated with pyML. Also you are not allowed to make RPC calls including hitting queryrunner from the service. pyML cannot be used as a workaround for discontinuation of python service. It is pyML users responsibility to make sure packages met the license and compliance requirements. You should strife to minimize the number of packages.create a devpodssh into devpodsudo apt-get install build-essentialsudo apt-get install cython python-pip unzipcreate a pyml directory with virtulenv- mkir -p pyml- cd pyml- pip3 install virtualenv- virtualenv --python=python3 venv- source venv bin activate - pip3 install cython- create requirements.txt with all the packages needed- pip3 install -r requirements.txt"}
{"prompt": "Can't access table of results via Workbench from one-off prediction in Michelangelo", "completion": "First note that due to the lack of eng resource, pyML  dev-guide, engdoc, 3rd Party Packages Guide and pyml online restriction  support is very limited and there is no SLA guarantee associated with pyML. Also you are not allowed to make RPC calls including hitting queryrunner from the service. pyML cannot be used as a workaround for discontinuation of python service. It is pyML users responsibility to make sure packages met the license and compliance requirements. You should strife to minimize the number of packages.create a devpodssh into devpodsudo apt-get install build-essentialsudo apt-get install cython python-pip unzipcreate a pyml directory with virtulenv- mkir -p pyml- cd pyml- pip3 install virtualenv- virtualenv --python=python3 venv- source venv bin activate - pip3 install cython- create requirements.txt with all the packages needed- pip3 install -r requirements.txt"}
{"prompt": "Why is my Michelangelo training job running out of memory and failing? I'm getting this training error:Your training job failed due to out of memory errors in the Sparkexecutors during the learning phase. XGBoostModel training failed.Reason: Job aborted due to stage failure: ResultStage 258 foreachPartition at XGBoost.scala:282  has failed the maximumallowable number of times:4. Most recent failure reason:org.apache.spark.shuffle.MetadataFetchFailedException: Missing anoutput location for shuffle 125 at...Here's the linkMy data only has 700K rows, 60 features, 1 day of data, and I've also increased the # of spark executors to 30.. I was wondering why I am still getting the error, and what I can do to resolve it? Thanks!", "completion": "First note that due to the lack of eng resource, pyML  dev-guide, engdoc, 3rd Party Packages Guide and pyml online restriction  support is very limited and there is no SLA guarantee associated with pyML. Also you are not allowed to make RPC calls including hitting queryrunner from the service. pyML cannot be used as a workaround for discontinuation of python service. It is pyML users responsibility to make sure packages met the license and compliance requirements. You should strife to minimize the number of packages.create a devpodssh into devpodsudo apt-get install build-essentialsudo apt-get install cython python-pip unzipcreate a pyml directory with virtulenv- mkir -p pyml- cd pyml- pip3 install virtualenv- virtualenv --python=python3 venv- source venv bin activate - pip3 install cython- create requirements.txt with all the packages needed- pip3 install -r requirements.txt"}
{"prompt": "ThriftRequestException for michelangelo task", "completion": "First note that due to the lack of eng resource, pyML  dev-guide, engdoc, 3rd Party Packages Guide and pyml online restriction  support is very limited and there is no SLA guarantee associated with pyML. Also you are not allowed to make RPC calls including hitting queryrunner from the service. pyML cannot be used as a workaround for discontinuation of python service. It is pyML users responsibility to make sure packages met the license and compliance requirements. You should strife to minimize the number of packages.create a devpodssh into devpodsudo apt-get install build-essentialsudo apt-get install cython python-pip unzipcreate a pyml directory with virtulenv- mkir -p pyml- cd pyml- pip3 install virtualenv- virtualenv --python=python3 venv- source venv bin activate - pip3 install cython- create requirements.txt with all the packages needed- pip3 install -r requirements.txt"}
{"prompt": "Michelangelo - issue when uploading CSV to Hive using DSW I am trying to upload a CSV file into a Hive table  in order to use it on Michelangelo , using Data Science Workbench. I am following the procedure described on https:  engdocs.uberinternal.com michelangelo user-guides csv-data-ingestion.html#upload-csv-dsw but I am encountering the following error when I try to connect to my Yarn queue:Exception: Java gateway process exited before sending its port number.Has someone already experienced this issue? Thank you very much in advance for your help!", "completion": "First note that due to the lack of eng resource, pyML  dev-guide, engdoc, 3rd Party Packages Guide and pyml online restriction  support is very limited and there is no SLA guarantee associated with pyML. Also you are not allowed to make RPC calls including hitting queryrunner from the service. pyML cannot be used as a workaround for discontinuation of python service. It is pyML users responsibility to make sure packages met the license and compliance requirements. You should strife to minimize the number of packages.create a devpodssh into devpodsudo apt-get install build-essentialsudo apt-get install cython python-pip unzipcreate a pyml directory with virtulenv- mkir -p pyml- cd pyml- pip3 install virtualenv- virtualenv --python=python3 venv- source venv bin activate - pip3 install cython- create requirements.txt with all the packages needed- pip3 install -r requirements.txt"}
{"prompt": "Error The NameSpace quota  directories and files  of directory is exceeded during training I try to train the exact same model template which has been successfully trained before. But this time it has errorThe diskspace quota on HDFS for an app * directory has been exceeded. Cannot create staging directory 'hdfs:  ns-neon-prod-dca1 user hive warehouse ispend_stage.db michelangelo_tmp_2018_12_4_0_oneoff_workingset_drm_regression_test__1451578271_table .hive-staging_hive_2018-12-04_22-49-56_554_5416456318184442833-1': The NameSpace quota  directories and files  of directory  user hive warehouse ispend_stage.db is exceeded: quota=62000 file count=62001But we checked the usage for ispend_stage.db and it doesn't reach the quota yet.", "completion": "First note that due to the lack of eng resource, pyML  dev-guide, engdoc, 3rd Party Packages Guide and pyml online restriction  support is very limited and there is no SLA guarantee associated with pyML. Also you are not allowed to make RPC calls including hitting queryrunner from the service. pyML cannot be used as a workaround for discontinuation of python service. It is pyML users responsibility to make sure packages met the license and compliance requirements. You should strife to minimize the number of packages.create a devpodssh into devpodsudo apt-get install build-essentialsudo apt-get install cython python-pip unzipcreate a pyml directory with virtulenv- mkir -p pyml- cd pyml- pip3 install virtualenv- virtualenv --python=python3 venv- source venv bin activate - pip3 install cython- create requirements.txt with all the packages needed- pip3 install -r requirements.txt"}
{"prompt": "Michelangelo online prediction error -  unconfigured table ", "completion": "From project settings view, we see this project is deployed for michelangelo-prediction-group1. Looking at your model spec, can see you are using various feature store tables not dispersed to the corresponding cassandra. Look like this is a Safety Risk model? If so, please ping oncall to change to michelangelo-prediction-group7."}
{"prompt": "HTTP Error 404 in generating feature config", "completion": "From project settings view, we see this project is deployed for michelangelo-prediction-group1. Looking at your model spec, can see you are using various feature store tables not dispersed to the corresponding cassandra. Look like this is a Safety Risk model? If so, please ping oncall to change to michelangelo-prediction-group7."}
{"prompt": " Failed to register your dataframe to Hive  training error with 100 executors My model is failing with the above error; the attis record https:  attis.uberinternal.com spark application_1544830140014_354781 suggests I should increase the number of executors but I'm already using 100  the same number as the project I copied my model from .The previous questions asked on this error suggest that I should change my number of input partitions, but the suggested numbers to change them to are themselves based on the number of executors, and would thus be extremely large  either 300 or 900! . Given that my training data is only 450k trips, that seems excessive.What should I try setting my project settings to for these models to successfully train?", "completion": "From project settings view, we see this project is deployed for michelangelo-prediction-group1. Looking at your model spec, can see you are using various feature store tables not dispersed to the corresponding cassandra. Look like this is a Safety Risk model? If so, please ping oncall to change to michelangelo-prediction-group7."}
{"prompt": "Syntax for Training Filter what is the syntax for the field  Training Filter  to remove instances with null values? It doesn't seem to be using the regular DSL that is used in the  Features  field. For example, the this syntax works order_job_created_at_epoch_seconds != 0. But order_job_created_at_epoch_seconds != null doesn't. I also tried Null, NULL, but they don't work either.", "completion": "Have you tried IS NOT NULL syntax?Here is an example from a production model's training filter.projects eats_rating_model 2017-06-01-17-45-33-523-UTC trained_model.yaml: rating IS NOT NULL OR NOT outcome OR churned_28d = 1  AND  NOT...."}
{"prompt": "Why don't prediction jobs run automatically after switching data source from SQL to Hive? I switched the data source for one of my models  Rider_LTV_GLOBAL_FB  from SQL to HIVE. Now my prediction job doesn't run daily as scheduled and I need to rerun it manually everyday. How can I get the prediction job back to running automatically everyday as scheduled?", "completion": "Have you tried IS NOT NULL syntax?Here is an example from a production model's training filter.projects eats_rating_model 2017-06-01-17-45-33-523-UTC trained_model.yaml: rating IS NOT NULL OR NOT outcome OR churned_28d = 1  AND  NOT...."}
{"prompt": "How can I join realtime and offline features together for prediction?", "completion": "Have you tried IS NOT NULL syntax?Here is an example from a production model's training filter.projects eats_rating_model 2017-06-01-17-45-33-523-UTC trained_model.yaml: rating IS NOT NULL OR NOT outcome OR churned_28d = 1  AND  NOT...."}
{"prompt": "In Michelangelo, the prediction query for Hive data source appears to be incorrect", "completion": "Have you tried IS NOT NULL syntax?Here is an example from a production model's training filter.projects eats_rating_model 2017-06-01-17-45-33-523-UTC trained_model.yaml: rating IS NOT NULL OR NOT outcome OR churned_28d = 1  AND  NOT...."}
{"prompt": "How do I get Michelangelo training test data from hive?", "completion": "Have you tried IS NOT NULL syntax?Here is an example from a production model's training filter.projects eats_rating_model 2017-06-01-17-45-33-523-UTC trained_model.yaml: rating IS NOT NULL OR NOT outcome OR churned_28d = 1  AND  NOT...."}
{"prompt": "Training jobs failing with non-specific errors", "completion": "Have you tried IS NOT NULL syntax?Here is an example from a production model's training filter.projects eats_rating_model 2017-06-01-17-45-33-523-UTC trained_model.yaml: rating IS NOT NULL OR NOT outcome OR churned_28d = 1  AND  NOT...."}
{"prompt": "Fail to train with Xgboost", "completion": "Have you tried IS NOT NULL syntax?Here is an example from a production model's training filter.projects eats_rating_model 2017-06-01-17-45-33-523-UTC trained_model.yaml: rating IS NOT NULL OR NOT outcome OR churned_28d = 1  AND  NOT...."}
{"prompt": " invalid memory address  error from MA API when calling MichelangeloAPI::searchModelsJoin I'm making an MA Gallery client Java  calling MichelangeloAPI::searchModelsJoin via tchannel for our application.I was testing it locally while keeping getting error responseUnexpectedError: panic: runtime error: invalid memory address or nilpointer dereference.But the studio call with the same parameters doesn't have the issue.https:  studio.uberinternal.com requests a1413e73-3d9f-409d-8c47-665815ed0385Wonder if anything missed causing the issueSample Java code used:https:  code.uberinternal.com P250607https:  code.uberinternal.com P250609Cerberus command used:cerberus --tchannel-services michelangelo-api", "completion": "Have you tried IS NOT NULL syntax?Here is an example from a production model's training filter.projects eats_rating_model 2017-06-01-17-45-33-523-UTC trained_model.yaml: rating IS NOT NULL OR NOT outcome OR churned_28d = 1  AND  NOT...."}
{"prompt": "Timestamp conversion for Michelangelo seems Michelangelo is not happy to take hive table with timestamp as field type and what exact format should i convert my timestamp fields to?i tried to dofrom_unixtime unix_timestamp request_timestamp_local  and this gets into format like 2019-03-01 01:10:10. michelangelo does not like this either. what's the best way to convert a timestamp field to something that michelangelo likes?", "completion": "Have you tried IS NOT NULL syntax?Here is an example from a production model's training filter.projects eats_rating_model 2017-06-01-17-45-33-523-UTC trained_model.yaml: rating IS NOT NULL OR NOT outcome OR churned_28d = 1  AND  NOT...."}
{"prompt": "AthenaX jobs that require large amounts of memory I'm trying to compute real-time features for Michelangelo using AthenaX. These features are to be aggregated over the last hour so this means that the AthenaX job needs to buffer a lot of data before computing a value. I've tried my job with the max limit of 10GB memory provided through the UI, but the job keeps dying because of OOM.What is the best way to circumvent this issue? Is it possible to use more memory or do I need to aggregate over a smaller window? Is there a solution that allows aggregating over such a large window?", "completion": "Have you tried IS NOT NULL syntax?Here is an example from a production model's training filter.projects eats_rating_model 2017-06-01-17-45-33-523-UTC trained_model.yaml: rating IS NOT NULL OR NOT outcome OR churned_28d = 1  AND  NOT...."}
{"prompt": "Can we build a one-off prediction pipeline in Piper?", "completion": "Have you tried IS NOT NULL syntax?Here is an example from a production model's training filter.projects eats_rating_model 2017-06-01-17-45-33-523-UTC trained_model.yaml: rating IS NOT NULL OR NOT outcome OR churned_28d = 1  AND  NOT...."}
{"prompt": "How to exclude outlier data based on column in Michelangelo", "completion": "Have you tried IS NOT NULL syntax?Here is an example from a production model's training filter.projects eats_rating_model 2017-06-01-17-45-33-523-UTC trained_model.yaml: rating IS NOT NULL OR NOT outcome OR churned_28d = 1  AND  NOT...."}
{"prompt": "DSW pyspark, upload to hive, fails saveAsTable Path does not exist method 1following  upload to hive notebook  example, Im running my notebook code in DSW kernel Pyspark client mode it fails at Sdf.write.mode  overwrite  .saveAsTable  secure_recommended_reviewers.peers    error:Py4JJavaErrorTraceback  most recent call last <ipython-input-12-81e33d62c838> in <module>        1 # Save the Spark dataframe as a Hive table  use the naming convention HiveDBName.CSVfilename       2 hive_table = 'secure_recommended_reviewers.testa'----> 3 Sdf.write.mode  overwrite  .saveAsTable hive_table       4 ihtable = hc.table hive_table       5 ihtable.show 1  opt spark spark-2.0.0 python pyspark sql readwriter.py in saveAsTable self, name, format, mode, partitionBy, **options     568         if format is not None:    569             self.format format --> 570         self._jwrite.saveAsTable name     571     572     @since 1.4  opt spark spark-2.0.0 python lib py4j-0.10.1-src.zip py4j java_gateway.py in __call__ self, *args     931         answer = self.gateway_client.send_command command     932         return_value = get_return_value --> 933             answer, self.gateway_client, self.target_id, self.name     934     935         for temp_arg in temp_args: opt spark spark-2.0.0 python pyspark sql utils.py in deco *a, **kw      61     def deco *a, **kw :     62         try:---> 63             return f *a, **kw      64         except py4j.protocol.Py4JJavaError as e:     65             s = e.java_exception.toString   opt spark spark-2.0.0 python lib py4j-0.10.1-src.zip py4j protocol.py in get_return_value answer, gateway_client, target_id, name     310                 raise Py4JJavaError     311                      An error occurred while calling  0  1  2 .\n .--> 312                     format target_id,  . , name , value     313             else:    314                 raise Py4JError Py4JJavaError: An error occurred while calling o201.saveAsTable.: java.io.FileNotFoundException:  secure    at org.apache.hadoop.fs.viewfs.InodeTree.resolve InodeTree.java:403     at org.apache.hadoop.fs.viewfs.ViewFileSystem.mkdirs ViewFileSystem.java:448     at org.apache.hadoop.fs.FileSystem.mkdirs FileSystem.java:1817     at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob FileOutputCommitter.java:291     at org.apache.spark.sql.execution.datasources.BaseWriterContainer.driverSideSetup WriterContainer.scala:110     at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1.apply$mcV$sp InsertIntoHadoopFsRelationCommand.scala:140     at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1.apply InsertIntoHadoopFsRelationCommand.scala:115     at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1.apply InsertIntoHadoopFsRelationCommand.scala:115     at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId SQLExecution.scala:57     at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run InsertIntoHadoopFsRelationCommand.scala:115     at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute commands.scala:60     at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult commands.scala:58     at org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute commands.scala:74     at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply SparkPlan.scala:115     at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply SparkPlan.scala:115     at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply SparkPlan.scala:136     at org.apache.spark.rdd.RDDOperationScope$.withScope RDDOperationScope.scala:151     at org.apache.spark.sql.execution.SparkPlan.executeQuery SparkPlan.scala:133     at org.apache.spark.sql.execution.SparkPlan.execute SparkPlan.scala:114     at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute QueryExecution.scala:86     at org.apache.spark.sql.execution.QueryExecution.toRdd QueryExecution.scala:86     at org.apache.spark.sql.execution.datasources.DataSource.write DataSource.scala:487     at org.apache.spark.sql.execution.command.CreateDataSourceTableAsSelectCommand.run createDataSourceTables.scala:246     at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute commands.scala:60     at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult commands.scala:58     at org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute commands.scala:74     at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply SparkPlan.scala:115     at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply SparkPlan.scala:115     at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply SparkPlan.scala:136     at org.apache.spark.rdd.RDDOperationScope$.withScope RDDOperationScope.scala:151     at org.apache.spark.sql.execution.SparkPlan.executeQuery SparkPlan.scala:133     at org.apache.spark.sql.execution.SparkPlan.execute SparkPlan.scala:114     at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute QueryExecution.scala:86     at org.apache.spark.sql.execution.QueryExecution.toRdd QueryExecution.scala:86     at org.apache.spark.sql.DataFrameWriter.saveAsTable DataFrameWriter.scala:378     at org.apache.spark.sql.DataFrameWriter.saveAsTable DataFrameWriter.scala:354     at sun.reflect.NativeMethodAccessorImpl.invoke0 Native Method     at sun.reflect.NativeMethodAccessorImpl.invoke NativeMethodAccessorImpl.java:62     at sun.reflect.DelegatingMethodAccessorImpl.invoke DelegatingMethodAccessorImpl.java:43     at java.lang.reflect.Method.invoke Method.java:498     at py4j.reflection.MethodInvoker.invoke MethodInvoker.java:237     at py4j.reflection.ReflectionEngine.invoke ReflectionEngine.java:357     at py4j.Gateway.invoke Gateway.java:280     at py4j.commands.AbstractCommand.invokeMethod AbstractCommand.java:128     at py4j.commands.CallCommand.execute CallCommand.java:79     at py4j.GatewayConnection.run GatewayConnection.java:211     at java.lang.Thread.run Thread.java:748 my session loghc = HiveContext sc  runs cleanthis db secure_recommended_reviewers table peers was generated via sparkmagic in DSW.my jupyter session is in DCA1.in the error, why is it looking for a file? and how do fix this?why is it trying to run java.io.IOException: Cannot run program   opt hadoop topology.py ?method 2got a DS colleague whose code used to work, and used this method. Here's the codewhen i run spark.sql  insert into  i get an error:Py4JJavaError: An error occurred while calling o49.sql.: org.spark_project.guava.util.concurrent.UncheckedExecutionException: org.apache.spark.sql.AnalysisException: Path does not exist: viewfs:  ns-default secure user hive warehouse secure_recommended_reviewers.db peers;in dsw pyspark, how do i set path to my database?EDIT 1seem like my code is correct, it just doesnt work. possible pyspark maintenance.Edit 2Edit 3@taikun said:dsw Pyspark DCA non-secure -> Neon clusterwhen neon becomes secure, and pyspark runs on secure, then i can write to secure hive db?", "completion": "Have you tried IS NOT NULL syntax?Here is an example from a production model's training filter.projects eats_rating_model 2017-06-01-17-45-33-523-UTC trained_model.yaml: rating IS NOT NULL OR NOT outcome OR churned_28d = 1  AND  NOT...."}
{"prompt": "In ml-code repo, is the spark_conf specified in the spark section of job_specs.yaml inherited by ray? Ben Marchi3 hours agoIs the spark_conf specified in the spark section of job_specs.yaml inherited by ray?", "completion": "Have you tried IS NOT NULL syntax?Here is an example from a production model's training filter.projects eats_rating_model 2017-06-01-17-45-33-523-UTC trained_model.yaml: rating IS NOT NULL OR NOT outcome OR churned_28d = 1  AND  NOT...."}
{"prompt": "How do we handle unseen categorical values in batch prediction and online prediction? For hot encoding if serving has the values that is not trained, then how does it treat the value?", "completion": "Have you tried IS NOT NULL syntax?Here is an example from a production model's training filter.projects eats_rating_model 2017-06-01-17-45-33-523-UTC trained_model.yaml: rating IS NOT NULL OR NOT outcome OR churned_28d = 1  AND  NOT...."}
{"prompt": " no table name found for ...  Data source created but won't show in model", "completion": "Have you tried IS NOT NULL syntax?Here is an example from a production model's training filter.projects eats_rating_model 2017-06-01-17-45-33-523-UTC trained_model.yaml: rating IS NOT NULL OR NOT outcome OR churned_28d = 1  AND  NOT...."}
{"prompt": "Job failed while running getHiveDataSourceOperator", "completion": "Have you tried IS NOT NULL syntax?Here is an example from a production model's training filter.projects eats_rating_model 2017-06-01-17-45-33-523-UTC trained_model.yaml: rating IS NOT NULL OR NOT outcome OR churned_28d = 1  AND  NOT...."}
{"prompt": "How can I use Michelangelo's 'hold-out-custom' to do out-of-time train test split? allI'm trying to use 'hold-out-custom' to do a out-of-time train test split. I created a variable called feature_datestr which has the same value as datestr  since training Hive table is partitioned by datestr, I'm not sure if I can use datestr directly . I'm trying to use data from '2017-10-30' as test and the rest as train. I set up the 'hold-time-custom' as below. See full template here. However, when I train the model, I got the error saying 'Data loading in the data prep stage failed due to a data issue. cannot resolve 'feature_datestr' given input columns'. Is this because I didn't add feature_datestr as a feature in the 'feature scoping' section? If I add it as a feature in the 'Feature scoping' section, will it be used as a prediction feature though it shouldn't be?", "completion": "See one of Eats models  for example. The column must exist in your training data."}
{"prompt": "Got incorrect DSL syntax. What is the correct syntax for the below? nv_null: if and sFill sVal nv_mature ,  false   ==  false , sFill sVal nv_elc ,  false   ==  false , sFill sVal nv_soft_churn ,  false   ==  false , sFill sVal nv_hard_churn ,  false   ==  false , sFill sVal nv_mature ,  false   ==  false   ==  true    1.0 else 0.0", "completion": "Eric Chen  18 minutes agoif sFill sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false   sFill sVal nv_soft_churn ,  false   ==  false   sFill sVal nv_hard_churn ,  false   ==  false   sFill sVal nv_mature ,  false   ==  false     1.0  else   0.0 Eric Chen  18 minutes agothis should be the correct syntaxEric Chen  18 minutes agoif you are interested in how i figured this outEric Chen  18 minutes agothis what what i didEric Chen  18 minutes agoscala> val nv_mature =  a val nv_mature: String = ascala> val nv_elc =  b val nv_elc: String = bscala> val nv_soft_churn =  a val nv_soft_churn: String = ascala> val nv_hard_churn =  b val nv_hard_churn: String = bscala> val sVal = Map  a  ->  true ,  b  ->    val sVal: scala.collection.immutable.Map[String,String] = Map a -> true, b ->    scala> def sFill s, value  := if  s !=      s  else  value          ^    error: ':' expected but ',' found.scala> def sFill s: String, value: String  := if  s !=      s  else  value                       ^    error: '=' expected but identifier found.scala> def sFill s: String, value: String : String =  if  s !=      s  else  value  def sFill s: String, value: String : Stringscala> sFill  a ,  b  val res0: String = ascala> sFill   ,  b  val res1: String = bscala> if and sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false   sFill sVal nv_soft_churn ,  false   ==  false   sFill sVal nv_hard_churn ,  false   ==  false   sFill sVal nv_mature ,  false   ==  false   ==  true     1.0  else   0.0                                                                                                                            ^    error: ';' expected but string literal found.scala> if sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false   sFill sVal nv_soft_churn ,  false   ==  false   sFill sVal nv_hard_churn ,  false   ==  false   sFill sVal nv_mature ,  false   ==  false   ==  true     1.0  else   0.0              ^    error: ' ' expected but ',' found.                                  ^    error: illegal start of simple expressionscala> if sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false   sFill sVal nv_soft_churn ,  false   ==  false   sFill sVal nv_hard_churn ,  false   ==  false   sFill sVal nv_mature ,  false   ==  false   ==  true    1.0  else   0.0              ^    error: ' ' expected but ',' found.                                  ^    error: illegal start of simple expressionscala> if sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false   sFill sVal nv_soft_churn ,  false   ==  false   sFill sVal nv_hard_churn ,  false   ==  false   sFill sVal nv_mature ,  false   ==  false   ==  true    1.0  else   0.0              ^    error: ' ' expected but ',' found.                                  ^    error: illegal start of simple expressionscala> sVal nv_mature val res2: String = truescala> sVal nv_mature ,  false   ==  false            ^    error: ';' expected but ',' found.scala> if sFill sVal nv_mature ,  false    ==  false   sFill sVal nv_elc ,  false   ==  false   sFill sVal nv_soft_churn ,  false   ==  false   sFill sVal nv_hard_churn ,  false   ==  false   sFill sVal nv_mature ,  false   ==  false   ==  true    1.0  else   0.0                        ^    error: ';' expected but string literal found.scala> if sFill sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false   sFill sVal nv_soft_churn ,  false   ==  false   sFill sVal nv_hard_churn ,  false   ==  false   sFill sVal nv_mature ,  false   ==  false   ==  true    1.0  else   0.0                                                                                                                             ^    error: ';' expected but string literal found.scala> if sFill sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false   sFill sVal nv_soft_churn ,  false   ==  false   sFill sVal nv_hard_churn ,  false   ==  false   sFill sVal nv_mature ,  false   ==  false     1.0  else   0.0                                                                                                                           ^    error: illegal start of simple expressionscala> if sFill sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false   sFill sVal nv_soft_churn ,  false   ==  false   sFill sVal nv_hard_churn ,  false   ==  false   sFill sVal nv_mature ,  false   ==  false     1.0  else   0.0                                                                                                                           ^    error: illegal start of simple expressionscala> if sFill sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false   sFill sVal nv_soft_churn ,  false   ==  false   sFill sVal nv_hard_churn ,  false   ==  false   sFill sVal nv_mature ,  false   ==  false     1.0  else   0.0                                                                                                                           ^    error: illegal start of simple expressionscala> if sFill sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false   sFill sVal nv_soft_churn ,  false   ==  false   sFill sVal nv_hard_churn ,  false   ==  false   sFill sVal nv_mature ,  false   ==  false      1.0  else   0.0                                                                                                                           ^    error: illegal start of simple expressionscala> sFill sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false                                           ^    error: unclosed string literalscala> sFill sVal nv_mature ,  false   ==  false val res3: Boolean = falsescala> sFill sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false val res4: Boolean = falsescala> sFill sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false   sFill sVal nv_soft_churn ,  false   ==  false   sFill sVal nv_hard_churn ,  false   ==  false val res5: Boolean = falsescala> if sFill sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false   sFill sVal nv_soft_churn ,  false   ==  false   sFill sVal nv_hard_churn ,  false   ==  false   sFill sVal nv_mature ,  false   ==  false     1.0  else   0.0 val res6: Double = 0.0Eric Chen  18 minutes agoyou can start a scala consoleEric Chen  18 minutes agothen try this out interactively"}
{"prompt": "canvas on devpod, scaffold, raises error: tchannel.errors.BadRequestError: no handler for service  umetadata  and method  UMetadata::lookupInstance ", "completion": "Eric Chen  18 minutes agoif sFill sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false   sFill sVal nv_soft_churn ,  false   ==  false   sFill sVal nv_hard_churn ,  false   ==  false   sFill sVal nv_mature ,  false   ==  false     1.0  else   0.0 Eric Chen  18 minutes agothis should be the correct syntaxEric Chen  18 minutes agoif you are interested in how i figured this outEric Chen  18 minutes agothis what what i didEric Chen  18 minutes agoscala> val nv_mature =  a val nv_mature: String = ascala> val nv_elc =  b val nv_elc: String = bscala> val nv_soft_churn =  a val nv_soft_churn: String = ascala> val nv_hard_churn =  b val nv_hard_churn: String = bscala> val sVal = Map  a  ->  true ,  b  ->    val sVal: scala.collection.immutable.Map[String,String] = Map a -> true, b ->    scala> def sFill s, value  := if  s !=      s  else  value          ^    error: ':' expected but ',' found.scala> def sFill s: String, value: String  := if  s !=      s  else  value                       ^    error: '=' expected but identifier found.scala> def sFill s: String, value: String : String =  if  s !=      s  else  value  def sFill s: String, value: String : Stringscala> sFill  a ,  b  val res0: String = ascala> sFill   ,  b  val res1: String = bscala> if and sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false   sFill sVal nv_soft_churn ,  false   ==  false   sFill sVal nv_hard_churn ,  false   ==  false   sFill sVal nv_mature ,  false   ==  false   ==  true     1.0  else   0.0                                                                                                                            ^    error: ';' expected but string literal found.scala> if sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false   sFill sVal nv_soft_churn ,  false   ==  false   sFill sVal nv_hard_churn ,  false   ==  false   sFill sVal nv_mature ,  false   ==  false   ==  true     1.0  else   0.0              ^    error: ' ' expected but ',' found.                                  ^    error: illegal start of simple expressionscala> if sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false   sFill sVal nv_soft_churn ,  false   ==  false   sFill sVal nv_hard_churn ,  false   ==  false   sFill sVal nv_mature ,  false   ==  false   ==  true    1.0  else   0.0              ^    error: ' ' expected but ',' found.                                  ^    error: illegal start of simple expressionscala> if sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false   sFill sVal nv_soft_churn ,  false   ==  false   sFill sVal nv_hard_churn ,  false   ==  false   sFill sVal nv_mature ,  false   ==  false   ==  true    1.0  else   0.0              ^    error: ' ' expected but ',' found.                                  ^    error: illegal start of simple expressionscala> sVal nv_mature val res2: String = truescala> sVal nv_mature ,  false   ==  false            ^    error: ';' expected but ',' found.scala> if sFill sVal nv_mature ,  false    ==  false   sFill sVal nv_elc ,  false   ==  false   sFill sVal nv_soft_churn ,  false   ==  false   sFill sVal nv_hard_churn ,  false   ==  false   sFill sVal nv_mature ,  false   ==  false   ==  true    1.0  else   0.0                        ^    error: ';' expected but string literal found.scala> if sFill sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false   sFill sVal nv_soft_churn ,  false   ==  false   sFill sVal nv_hard_churn ,  false   ==  false   sFill sVal nv_mature ,  false   ==  false   ==  true    1.0  else   0.0                                                                                                                             ^    error: ';' expected but string literal found.scala> if sFill sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false   sFill sVal nv_soft_churn ,  false   ==  false   sFill sVal nv_hard_churn ,  false   ==  false   sFill sVal nv_mature ,  false   ==  false     1.0  else   0.0                                                                                                                           ^    error: illegal start of simple expressionscala> if sFill sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false   sFill sVal nv_soft_churn ,  false   ==  false   sFill sVal nv_hard_churn ,  false   ==  false   sFill sVal nv_mature ,  false   ==  false     1.0  else   0.0                                                                                                                           ^    error: illegal start of simple expressionscala> if sFill sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false   sFill sVal nv_soft_churn ,  false   ==  false   sFill sVal nv_hard_churn ,  false   ==  false   sFill sVal nv_mature ,  false   ==  false     1.0  else   0.0                                                                                                                           ^    error: illegal start of simple expressionscala> if sFill sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false   sFill sVal nv_soft_churn ,  false   ==  false   sFill sVal nv_hard_churn ,  false   ==  false   sFill sVal nv_mature ,  false   ==  false      1.0  else   0.0                                                                                                                           ^    error: illegal start of simple expressionscala> sFill sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false                                           ^    error: unclosed string literalscala> sFill sVal nv_mature ,  false   ==  false val res3: Boolean = falsescala> sFill sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false val res4: Boolean = falsescala> sFill sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false   sFill sVal nv_soft_churn ,  false   ==  false   sFill sVal nv_hard_churn ,  false   ==  false val res5: Boolean = falsescala> if sFill sVal nv_mature ,  false   ==  false   sFill sVal nv_elc ,  false   ==  false   sFill sVal nv_soft_churn ,  false   ==  false   sFill sVal nv_hard_churn ,  false   ==  false   sFill sVal nv_mature ,  false   ==  false     1.0  else   0.0 val res6: Double = 0.0Eric Chen  18 minutes agoyou can start a scala consoleEric Chen  18 minutes agothen try this out interactively"}
{"prompt": "How can I override palette values in a Michelangelo model? is there a way to pass in feature values for Palette features in a model?  So I don't want the model to use the Palette returned value for the feature, but instead use something I pass in I am querying the model with some old data, for which palette values will be incorrect.", "completion": "From @JosephWangyou can pass the featurestore valuesplease use the full palette expression as feature name  doubleValue : 0.0,  key :  @palette:city:waypoint_type:trip_count:palette_feature_join_key:prediction_ts:0  Source: https:  uber.slack.com archives CTY9SF7RN p1677607375724779"}
{"prompt": "Why are Michelangelo data sources so restrictive in allowed column types?", "completion": "From @JosephWangyou can pass the featurestore valuesplease use the full palette expression as feature name  doubleValue : 0.0,  key :  @palette:city:waypoint_type:trip_count:palette_feature_join_key:prediction_ts:0  Source: https:  uber.slack.com archives CTY9SF7RN p1677607375724779"}
{"prompt": "ML Explorer  MLE  LDAP group owner Is it possible to set a LDAP group as the owner of an MLE project to avoid having to add individual user emails?", "completion": "MA team built MA Studio that is covering the use case of Michelangelo and MLExplorer. MA Studio has better ACL with uOwn integration. Please get more information about MAStudio here.With this, we no longer build new feature in the current MLExplorer."}
{"prompt": "How can I find the registered docker image for a specific MLE workflow?", "completion": "MA team built MA Studio that is covering the use case of Michelangelo and MLExplorer. MA Studio has better ACL with uOwn integration. Please get more information about MAStudio here.With this, we no longer build new feature in the current MLExplorer."}
{"prompt": "What input types are supported by Michelangelo as features? Is Array<Double> supported? I can't find explicit description on which input types are supported as features in Michelangelo Doc.Is array supported  doesn't seem so. my training job keeps failing ? If not, is there workaround like exploding it within michelangelo? Or do I have to explode it beforehand and save it to another input table? Thanks", "completion": "MA team built MA Studio that is covering the use case of Michelangelo and MLExplorer. MA Studio has better ACL with uOwn integration. Please get more information about MAStudio here.With this, we no longer build new feature in the current MLExplorer."}
{"prompt": "GRPC error  _InactiveRpcError  while launching a prod michelangelo job", "completion": "The error in my case was coming from tunneling issues. Running cerberus in another terminal window inside the devpods made the errors related to GRPC go awaycerberus -r ubuild-api,michelangelo-workflow-orchestration -s michelangelo-deeplearning-jobs,umetadata -t umetadataThanks to Shubhanjan for the solution.reference"}
{"prompt": "Unable to upload CSV to Michelangelo Any idea why I'm getting this error?CSV File is all fine  attached .", "completion": "The error in my case was coming from tunneling issues. Running cerberus in another terminal window inside the devpods made the errors related to GRPC go awaycerberus -r ubuild-api,michelangelo-workflow-orchestration -s michelangelo-deeplearning-jobs,umetadata -t umetadataThanks to Shubhanjan for the solution.reference"}
{"prompt": "HTTP Error 401: theUnauthorized errors when trying to download using iPython notebook", "completion": "The error in my case was coming from tunneling issues. Running cerberus in another terminal window inside the devpods made the errors related to GRPC go awaycerberus -r ubuild-api,michelangelo-workflow-orchestration -s michelangelo-deeplearning-jobs,umetadata -t umetadataThanks to Shubhanjan for the solution.reference"}
{"prompt": "How to collaborate on michelangelo jupyter notebook? My teammate and I want to work collaboratively on a jupyter notebook sessoin.  I have created the session in michelangelo and then created a notbook.  Sharing the link to the notebook with my teammate gives the following error:you are not authoized to access this resource.  the owner can grant you accessThis message implies I can share but I cant figure out how.", "completion": "Seems that you can share in this way https:  engwiki.uberinternal.com display DSW DSW+quickstartDoes not allow collaborative working, but can be used to share the results of a notebook by changing the file visibility in the 'Files' section of DSW"}
{"prompt": "Error installing Michelangelo-Python-Client Documenting a customer issue here in stack overflow:After running:pip3 install michelangelo-python-clientI received the following error message:ERROR: Could not find a version that satisfies the requirement michelangelo-python-client  from versions: none  ERROR: No matching distribution found for michelangelo-python-client", "completion": "Seems that you can share in this way https:  engwiki.uberinternal.com display DSW DSW+quickstartDoes not allow collaborative working, but can be used to share the results of a notebook by changing the file visibility in the 'Files' section of DSW"}
{"prompt": "How to forecast weekly or monthly time series? I was trying to do forecasts with Michelangelo. I want these to be weekly or monthly. I see that the time series model types only allows hourly and daily granularity. Does it mean I can't use Michelangelo for my use case?", "completion": "Seems that you can share in this way https:  engwiki.uberinternal.com display DSW DSW+quickstartDoes not allow collaborative working, but can be used to share the results of a notebook by changing the file visibility in the 'Files' section of DSW"}
{"prompt": "How to convert Michelangelo DataFrameVariable wrapper object to the Spark Dataframe, and vice versa? I queried hdfs using malearn.data.sql , widely used in Michelangelo notebooks, but it outputs a wrapper on top of the spark data frame  DataFrameVariable . How do I access the inherent spark data frame from this object? Also, how can I convert the spark dataframe to DataFrameVariable object?I am trying to make some changes to the inherent spark data frame columns.", "completion": "Consider a DataFrameVariable object 'df'Importsfrom michelangelo_py.malearn.low_level.variables import DataFrameVariableimport uuidDataFrameVariable to Spark Data Framespark_df = df.valueSpark Data Frame to DataFrameVariabledataframe_uuid = uuid.uuid4  reconstructed_wrapper_variable = DataFrameVariable      variable_id=str dataframe_uuid ,     alias='DataFrame_  '.format str dataframe_uuid [:8] ,     constant=False,     value=spark_df  Please note that the rest of the params apart from the 'value' param were randomly assigned since I didn't really care about the others for this one-off analysisReference on DataFrameVariable - https:  sourcegraph.uberinternal.com code.uber.internal data michelangelo-opensource - blob python michelangelo-py michelangelo_py malearn low_level variables data_frame_variable.py#L32:7"}
{"prompt": "Why is Pydoop used for HDFS access in Michelangelo's deep learning? I heard that Pydoop is the recommended tool to access to HDFS in WBU  Michelangelo's deep learning environment .Pydoop has multiples challenges.The installation has to happens within an environments with all Hadoop variables.Jenkins does not have those Hadoop variables. Therefore, users have to use  try catch  in import statement to avoid Jenkins failure.  try-catch  is not a good practice.I'm wondering  not confirmed , any changes to Hadoop variables might require re-installation. I got this feeling because the installation, not run-time, hoop up Hadoop variables. I might be wrong on this.It seems, at the time of this writing, Pydoop supports only Python 2.x, not 3.xWhy not other alternative?I did try MRJob. I'm not saying MRJob is the best.MRJob's installation does not hoop up with Hadoop variables. MRJob looks up Hadoop variables during runtime.btw, my use case is to access to HDFS with all  hadoop fs  commands.Any strong reason why Pydoop is the  best ?", "completion": "Consider a DataFrameVariable object 'df'Importsfrom michelangelo_py.malearn.low_level.variables import DataFrameVariableimport uuidDataFrameVariable to Spark Data Framespark_df = df.valueSpark Data Frame to DataFrameVariabledataframe_uuid = uuid.uuid4  reconstructed_wrapper_variable = DataFrameVariable      variable_id=str dataframe_uuid ,     alias='DataFrame_  '.format str dataframe_uuid [:8] ,     constant=False,     value=spark_df  Please note that the rest of the params apart from the 'value' param were randomly assigned since I didn't really care about the others for this one-off analysisReference on DataFrameVariable - https:  sourcegraph.uberinternal.com code.uber.internal data michelangelo-opensource - blob python michelangelo-py michelangelo_py malearn low_level variables data_frame_variable.py#L32:7"}
{"prompt": "Why CPU is getting throttled even though the CPU utilization is low Zihan Zheng5:26 PM!q hi OPS team, could you help investigate this issue? https:  t3.uberinternal.com browse FEEDINTEL-5076", "completion": "See https:  docs.google.com document d 1PE-lB9IrIMdlYUuBiOohDuwABRwx2wUpoeroh-9i2Aw editfor explanation."}
{"prompt": "athenaX job starts and then fails when writing to Cassandra I'm working on an aggregation job to write to Cassandra to take advantage of Michelangelo's RT features. Here is the job.When I run it with just an output to another kafka topic, it runs correctly and I can k8read the output from an adhoc box. However, when I try to output it to a Cassandra table, the job starts but then fails. I'm not sure what I'm doing wrong here.I created the Cassandra keyspace and table in the Cassandra dev cluster and configured it like so:Can someone help me figure out what's going wrong here?", "completion": "See https:  docs.google.com document d 1PE-lB9IrIMdlYUuBiOohDuwABRwx2wUpoeroh-9i2Aw editfor explanation."}
{"prompt": "Does Michelangelo provide any monitoring for features and model performance?", "completion": "For each FeatureStore table, we auto register it with Data Stats Service  DSS . DSS collects certain stats on each table and each column. Some of the stats can be found by clicking on Stats view on a specific table under Palette category on Databook.Palette Pipeline FailureWhen you onboard a new feature group, please make sure to add corresponding engineer oncall ldap group and team's ldap group into owner_ldap_groups. Upon failure, an email notification will be sent and the corresponding teams will be paged.Palette Feature AssertionPalette leverages Trust for basic feature assertion. See data assertions example. The corresponding Trust information can be found here.Palette Numeric Feature OutlinerOne can specify certain outliner algorithms that we've implemented. See here for an example. If you don't specify, we auto run MAD algorithm on each numeric features specified in the description.json. See here for DSS metrics that we are using. We emit M3 stats for feature with outliner.Realtime Prediction Model Performance MonitoringWe emit sampled requests  responses to a heatpiped topic. One can created a project specific config that leverages Hive UDFs for daily model performance monitoring. The metrics are emitted to M3. One can leverage monitoring to trigger training pipeline when performance degraded.Near Realtime Feature & Model Performance MonitoringThis is done via AthenaX. We are working with uWorc team to fully automate feature monitoring jobs when you deployed a model for realtime prediction. Few example jobs can be found here and here. Note that we've added MAD algorithm as an AthenaX UDF.Predicton Service Dashboard In the FeatureStore section of the dashboard, one can see successful failures for realtime feature lookup. It is recommended that you add umonitor alerts when the ratio of failures-to-total is high. Please consult Michelangelo FeatureEngine team or Michelangelo Online Serving team for information.Evaluation FrameworkIdeally, one wants to performance backtesting, simulation, and analysis before deploying a model to production. See [ERD][11].Using realtime prediction sampled data to determine feature issue using ManifoldUsing KL-divergence to detect distribution changeBinary classification evaluationSubscribe to michelangelo-users to receive more information when we launch the product.See [FeatureStore engdoc][16], [FeatureStore Near-realtime engdoc][17], [Realtime Prediction service engdoc][18], [Model Monitoring][19], and [Retraining][20]."}
{"prompt": "Michelangelo: Model Training Error", "completion": "For each FeatureStore table, we auto register it with Data Stats Service  DSS . DSS collects certain stats on each table and each column. Some of the stats can be found by clicking on Stats view on a specific table under Palette category on Databook.Palette Pipeline FailureWhen you onboard a new feature group, please make sure to add corresponding engineer oncall ldap group and team's ldap group into owner_ldap_groups. Upon failure, an email notification will be sent and the corresponding teams will be paged.Palette Feature AssertionPalette leverages Trust for basic feature assertion. See data assertions example. The corresponding Trust information can be found here.Palette Numeric Feature OutlinerOne can specify certain outliner algorithms that we've implemented. See here for an example. If you don't specify, we auto run MAD algorithm on each numeric features specified in the description.json. See here for DSS metrics that we are using. We emit M3 stats for feature with outliner.Realtime Prediction Model Performance MonitoringWe emit sampled requests  responses to a heatpiped topic. One can created a project specific config that leverages Hive UDFs for daily model performance monitoring. The metrics are emitted to M3. One can leverage monitoring to trigger training pipeline when performance degraded.Near Realtime Feature & Model Performance MonitoringThis is done via AthenaX. We are working with uWorc team to fully automate feature monitoring jobs when you deployed a model for realtime prediction. Few example jobs can be found here and here. Note that we've added MAD algorithm as an AthenaX UDF.Predicton Service Dashboard In the FeatureStore section of the dashboard, one can see successful failures for realtime feature lookup. It is recommended that you add umonitor alerts when the ratio of failures-to-total is high. Please consult Michelangelo FeatureEngine team or Michelangelo Online Serving team for information.Evaluation FrameworkIdeally, one wants to performance backtesting, simulation, and analysis before deploying a model to production. See [ERD][11].Using realtime prediction sampled data to determine feature issue using ManifoldUsing KL-divergence to detect distribution changeBinary classification evaluationSubscribe to michelangelo-users to receive more information when we launch the product.See [FeatureStore engdoc][16], [FeatureStore Near-realtime engdoc][17], [Realtime Prediction service engdoc][18], [Model Monitoring][19], and [Retraining][20]."}
{"prompt": "Temporary table schema for Michelangelo one-off prediction What's the table schema I should expect for the temporary table created by Michelangelo one-off prediction job?The reason why I ask is I have seen the usage to query from this temporary table by using column name as @basis:rider_uuid. But when I look at the schema of the table I have ispend_stage.cpr_rxgy_4w_predict_temp_output_1_v0, the column name is actually rider_uuid without referring to @basis.Also in addition to the temporary table itself, another temp table called ispend_stage.cpr_rxgy_4w_predict_temp_output_1_v0_table is created with column names as feature0, feature1, feature2 ....I am running this one-off prediction through ML Explorer where you can find the doc here.", "completion": "For each FeatureStore table, we auto register it with Data Stats Service  DSS . DSS collects certain stats on each table and each column. Some of the stats can be found by clicking on Stats view on a specific table under Palette category on Databook.Palette Pipeline FailureWhen you onboard a new feature group, please make sure to add corresponding engineer oncall ldap group and team's ldap group into owner_ldap_groups. Upon failure, an email notification will be sent and the corresponding teams will be paged.Palette Feature AssertionPalette leverages Trust for basic feature assertion. See data assertions example. The corresponding Trust information can be found here.Palette Numeric Feature OutlinerOne can specify certain outliner algorithms that we've implemented. See here for an example. If you don't specify, we auto run MAD algorithm on each numeric features specified in the description.json. See here for DSS metrics that we are using. We emit M3 stats for feature with outliner.Realtime Prediction Model Performance MonitoringWe emit sampled requests  responses to a heatpiped topic. One can created a project specific config that leverages Hive UDFs for daily model performance monitoring. The metrics are emitted to M3. One can leverage monitoring to trigger training pipeline when performance degraded.Near Realtime Feature & Model Performance MonitoringThis is done via AthenaX. We are working with uWorc team to fully automate feature monitoring jobs when you deployed a model for realtime prediction. Few example jobs can be found here and here. Note that we've added MAD algorithm as an AthenaX UDF.Predicton Service Dashboard In the FeatureStore section of the dashboard, one can see successful failures for realtime feature lookup. It is recommended that you add umonitor alerts when the ratio of failures-to-total is high. Please consult Michelangelo FeatureEngine team or Michelangelo Online Serving team for information.Evaluation FrameworkIdeally, one wants to performance backtesting, simulation, and analysis before deploying a model to production. See [ERD][11].Using realtime prediction sampled data to determine feature issue using ManifoldUsing KL-divergence to detect distribution changeBinary classification evaluationSubscribe to michelangelo-users to receive more information when we launch the product.See [FeatureStore engdoc][16], [FeatureStore Near-realtime engdoc][17], [Realtime Prediction service engdoc][18], [Model Monitoring][19], and [Retraining][20]."}
